{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 30 May 2019\n",
    "\n",
    "\n",
    "# Make videos of tracking moth"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "** show how well moth can follow trajectory with network\n",
    "** make function to predict with nnet and then evaluate immediately with ODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
      "last run on 2019-06-18 14:43:21.155410\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Arc\n",
    "from collections import OrderedDict\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import pandas as pd\n",
    "import importlib\n",
    "print(sys.version)\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.36.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simUtils_DLVersion as simUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'simUtils_DLVersion' from 'C:\\\\Users\\\\calli\\\\Documents\\\\GitRepos\\\\MothMachineLearning\\\\simUtils_DLVersion.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(simUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "tensorflow using CPU\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-06-18 14:43:23.800582\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "\n",
    "# make sure Keras uses CPU instead of GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "else: \n",
    "    print(\"tensorflow using CPU\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    '''\n",
    "    rho: radius\n",
    "    phi: angle (in radians)\n",
    "    '''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 30,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "alpha = np.pi/2\n",
    "tau0 = 20\n",
    "tau_w = 2001\n",
    "\n",
    "FAlphaTau_list = [F, alpha, tau0, tau_w]\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>xd</th>\n",
       "      <th>y</th>\n",
       "      <th>yd</th>\n",
       "      <th>theta</th>\n",
       "      <th>thetad</th>\n",
       "      <th>phi</th>\n",
       "      <th>phid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.895929e-08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.681961</td>\n",
       "      <td>3.141588</td>\n",
       "      <td>-0.006320</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.379059e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-1.357820</td>\n",
       "      <td>3.141584</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.068399e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.002110</td>\n",
       "      <td>-2.033677</td>\n",
       "      <td>3.141580</td>\n",
       "      <td>-0.006315</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.757612e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-2.709530</td>\n",
       "      <td>3.141575</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.005346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x      xd         y        yd     theta    thetad       phi  \\\n",
       "0  0.000000e+00  0.0001  0.000000  0.000100  3.141593  0.000100  0.000000   \n",
       "1  6.895929e-08  0.0001 -0.000237 -0.681961  3.141588 -0.006320  0.000004   \n",
       "2  1.379059e-07  0.0001 -0.000941 -1.357820  3.141584 -0.006318  0.000007   \n",
       "3  2.068399e-07  0.0001 -0.002110 -2.033677  3.141580 -0.006315  0.000011   \n",
       "4  2.757612e-07  0.0001 -0.003746 -2.709530  3.141575 -0.006311  0.000015   \n",
       "\n",
       "       phid  \n",
       "0  0.000100  \n",
       "1  0.005338  \n",
       "2  0.005340  \n",
       "3  0.005342  \n",
       "4  0.005346  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tragDF = pd.DataFrame([x, xd, y, yd, theta, thetad, phi, phid]).transpose()\n",
    "tragDF.columns = \"x, xd, y, yd, theta, thetad, phi, phid\".split(\", \")\n",
    "tragDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b5c8330518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VNXdx/HPLztLWBISiOxLCrIJMoDiLuJucUHFBcENrbZq7WOr9elja7W12talagU30FpFXHEv4EZFwLAIKEvYCQQIBAIIIQk5zx9zg0OcSMJMZibJ9/163dfce+455/5yZzK/ubs55xAREQm3uGgHICIi9ZMSjIiI1AolGBERqRVKMCIiUiuUYEREpFYowYiISK1QghERkVqhBCMiIrVCCUZERGpFQrQDCKdWrVq5Tp06RTsMEZE6Ze7cuVudcxnh7rdeJZhOnTqRk5MT7TBEROoUM1tbG/1qF5mIiNQKJRgREakVSjAiIlIr6tUxGBGRaCktLSUvL4/i4uJoh1KllJQU2rVrR2JiYkSWpwQjIhIGeXl5pKam0qlTJ8ws2uH8gHOObdu2kZeXR+fOnSOyzLDtIjOzM81smZmtMLM7g8xPNrNJ3vzZZtYpYN5dXvkyMzujun2KiMSK4uJi0tPTYzK5AJgZ6enpEd3CCkuCMbN44AngLKAncJmZ9axU7Vpgu3OuG/Aw8BevbU9gJNALOBN40sziq9mniEjMiNXkUiHS8YVrF9kgYIVzbhWAmb0CDAe+DagzHPi9N/4a8Lj5/9rhwCvOuX3AajNb4fVHNfoMi2WbdvHewo0kxseRmBBHYnwcSfFGQrx/PDHeSKoYT4ijcVI8LRol0rxRIs0aJZKSGB/ukERE6rxwJZi2wPqA6TxgcFV1nHNlZlYEpHvlsyq1beuNH6pPzGwsMBagQ4cOhxX8ii27eezjFYfVFiA5IY4Wjf0J5/shiRaNE2nTLIWsFilkNW/EES1SyGiaTEK8Tt4TkfovXAkm2HaXq2adqsqDfQtX7hPn3HhgPIDP5/vB/Oo4p28WZ/c5m/3ljtL9jpL95ZTuL6dsv6N0f/mB6dIy/7w9JWUU7S1lx55SivaWsjNgvGhvKRt3FLMkfxeF35Wwt3T/QcuKjzMyU5PJau5POlnNU8hq0YgOaY3pmtGEDmmNlYBEpF4IV4LJA9oHTLcDNlZRJ8/MEoDmQOEh2h6qz7AxMxLijYR4aER4dnk559hZXEZ+0V7yi4rJ31H8/XjRXpbk72T60s0Ul5YfaJMYb3RMb0LXjCZ0zWhK14ymdMtsSpeMJqSmRObUQhGpe373u9/RqlUrbr31VgDuvvtuWrduzS233BK1mMKVYL4Css2sM7AB/0H7yyvVmQKMBr4ERgAfO+ecmU0B/m1mfweOALKBOfi3bA7VZ0wzswO7zHq0aRa0jnOOHXtKWVu4h5VbdrOyYDcrtviH6Uu2UFb+/UZZ62bJdMtsSq8jmtOnrX/omN445g8sijQ0f3jnG77duDOsffY8ohn3nNeryvnXXnstF154Ibfeeivl5eW88sorzJkzJ6wx1FRYEox3TOXnwEdAPPCcc+4bM7sXyHHOTQGeBV70DuIX4k8YePVexX/wvgy42Tm3HyBYn+GIN5aYGS2bJNGySRL92rc4aF7p/nLWHUg837Fiy25yt+xiwhdrKNnv3+pplpJAn3bN6d22OX3btqBP2+a0T2ukpCPSwHTq1In09HTmz5/P5s2b6d+/P+np6VGNyZw7rMMWMcnn87mGcDflkrJylm/exeINRSzcUMSivCKWbtpJ6X7/e9m8USJ92janf4cWDO6cztEdW9A4SdfUitSmJUuWcOSRR0Y1hkmTJjFz5kw2bdrE6NGjOfvss39QJ1icZjbXOecLdzxKMPXEvrL9LN+0m4UbdrB4QxFfry9i2eZd7C93JMQZfds1Z3CXdAZ3TsPXKY2myUo4IuEUCwmmpKSEPn36UFpaSm5uLvHxPzyeHMkEo2+ZeiI5IZ4+7ZrTp13zA2W795WRs6aQ2asLmb1qG09/vop/frqS+Dij9xHNDko4zRvpBAKRui4pKYlTTjmFFi1aBE0ukaYEU481TU7g5O6ZnNw9E4A9JWXMW7uD2au3MXtVIRO+WMP4z1cRZ9C/Q0tO7ZHJyd0z6JnVTMdwROqg8vJyZs2axeTJk6MdCqAE06A0Tkrg+OxWHJ/dCoDi0v3MX7eDL1du5ZNlBTz00TIe+mgZrZslc0r3TE7pkclx3Vppd5pIHfDtt99y7rnncsEFF5CdnR3tcAAlmAYtJTGeY7umc2zXdG4/vTtbdhXz6bICPl22hfcW5vPKV+tJjDcGd07n5O4ZnNojk86tmmjrRiQG9ezZk1WrVkU7jIMowcgBmakpXOJrzyW+9pTuLydnzXY+WbaFj5du4b73lnDfe0vo0qoJ5/TN4py+WXRvnapkIxLAORfT/xORPqlLZ5FJtawv3MMny7bw4eJNzFq1jXIH3TKbck6fLM7tm0V269RohygSVatXryY1NTVmb9lf8TyYXbt2/eB5MDpNuRqUYCKjYNc+PvxmE+8t3Mjs1YU4Bz9p3ZRz+hzBOX2z6JbZNNohikRcXX6ipRJMNSjBRN6WXcV8uHgT7y7M56s1/mTTo00q5/TJ4vz+bWmf1jjaIYrIISjBVIMSTHRt3lnMB4vyeW9RPl+t2Q7AkK7pXOJrzxm92tAoKfrn5YvIDynBVIMSTOzI276HN+ZtYPLc9awv3EtqcgLn9TuCiwe0o1/7FjG5j1qkoVKCqQYlmNhTXu6YvbqQyTnreX9xPsWl5WRnNuViXzsu6N+OjNTkaIco0uApwVSDEkxs21VcynsL83k1Zz3z1u0gPs44pXsmIwe255QemcTHaatGJBqUYKpBCabuWLFlN6/NzeP1eXkU7NpH+7RGjDqmI5f6OtC8se6LJhJJSjDVoART95TtL+c/325mwsw1zFldSEpiHBf0b8voIZ2qfEibiISXEkw1KMHUbd9u3MkLX67hrQUbKC4tZ3DnNMYM6cSwnq1JiI+Ldngi9VZtJZiQ/mvNLM3MpppZrvfasop6o706uWY22itrbGbvmdlSM/vGzB4IqD/GzArMbIE3XBdKnFI39DyiGQ9c1JdZdw3lrrN6sGHHXn720jxOfPATnvhkBYXflUQ7RBGpgZC2YMzsQaDQOfeAmd0JtHTO/aZSnTQgB/ABDpgLDAD2AYOdc5+YWRIwHfiTc+4DMxsD+JxzP69JPNqCqV/2lzumL9nMxC/X8MWKbSQlxHHxgHaMPbELHdObRDs8kXojVh84Nhw42RufCHwK/KZSnTOAqc65QgAzmwqc6Zx7GfgEwDlXYmbzgHYhxiP1SHyccXqvNpzeqw25m3fx3BermZyTx8tz1nFu3yO48aSu9DxCx2lEYlWoO7ZbO+fyAbzXzCB12gLrA6bzvLIDzKwFcB7+rZgKF5nZQjN7zczaVxWAmY01sxwzyykoKDjcv0NiXHbrVP58YV/++5tTuP6ELkxfspmzH5vBmOfnMGd1YcTvEisih3bIBGNm08xscZBheDWXEezihgPfBmaWALwMPOacq3iYwTtAJ+dcX2Aa/q2joJxz451zPuecLyMjo5ohSV2V2SyFu84+kpl3DuWOM7qzKK+IS8Z9yYinvmTat5spL1eiEYkVoR6DWQac7JzLN7Ms4FPnXPdKdS7z6tzgTY/z6r3sTT8H7HbO3VLFMuLxH+dpHmx+IB2DaXj2luxn8tz1jPtsFRt27KV761RuPLkL5/Y9gkSdeSZSLTF5FhkwBRjtjY8G3g5S5yPgdDNr6Z1ldrpXhpndBzQHbgts4CWrCj8FloQYp9RTjZLiuerYTnx6x8k8fOlROBy/nPQ1Q//2Ga/PzWO/tmhEoibULZh04FWgA7AOuNg5V2hmPuBG59x1Xr1rgN96ze53zj1vZu3wH5tZiv+MMoDHnXPPmNmf8SeWMqAQ+Jlzbumh4tEWjJSXOz5euoWHpy3nm4076ZrRhF8O+wln984iTreiEQlKF1pWgxKMVHDO8dE3m/j71OUs37ybHm1S+dXp3TntyEzdyVmkkljdRSYSk8yMM3tn8cGtJ/LoyH4Ul+7n+hdyOP+JL/hseYHOOhOJACUYqdfi44zh/doy7faTeHBEX7buLmH0c3O4ZNyXzFq1LdrhidRr2kUmDUpJWTmTctbz+Me5bN65j+O7teLOs3rQu+0hT1IUqbd0DKYalGCkuopL9/OvWWt58tOVbN9TwgX923LHGd3Jat4o2qGJRJwSTDUowUhN7Swu5clPVvLcF6uJMxh7QhduOKkrTZJDvYuSSN2hg/witaBZSiJ3ntWD6befxLCebXjs4xWc/NdPmfTVOl1DIxIiJRgRoH1aY/5xWX/euGkI7Vs24jevL+Kcx2YwI1f3txM5XEowIgGO7tCS1382hCcuP5rvSsoY9ewcxjw/h9zNu6IdmkidowQjUomZcU7fLKbdfhK/PbsHc9du58xHZ/C7txZTtKc02uGJ1BlKMCJVSE6IZ+yJXfnsjlO4cnAHXpq9llP/9imTc9brrs0i1aAEI3IIaU2S+MPw3rzzi+PpmN6YO15byCXjvmRJ/s5ohyYS05RgRKqp1xHNee3GITw4oi+rtn7Huf/4L3945xt2FWu3mUgwSjAiNRAXZ1zia8/HvzqJkQPbM2HmGk7922e8vWCD7m8mUokSjMhhaNE4ifsv6MNbNx1HVvMUbn1lAZc/PVtnm4kEUIIRCcFR7Vvw5k3Hcf8Fvfk2fydnPTqDP7+/hD0lZdEOTSTqlGBEQhQfZ1wxuCMf/+okLjy6LeM+X8WZj8xg5oqt0Q5NJKpCTjBmlmZmU80s13ttWUW90V6dXDMbHVD+qZktM7MF3pDplSeb2SQzW2Fms82sU6ixitSm9KbJPDjiKCaNPYb4OOPyZ2Zz5+sLKdqrkwCkYQrHFsydwHTnXDYw3Zs+iJmlAfcAg4FBwD2VEtEVzrl+3rDFK7sW2O6c6wY8DPwlDLGK1LrBXdL54NYTuOGkLryas55hf/+M/3yzKdphiURcOBLMcGCiNz4ROD9InTOAqc65QufcdmAqcGYN+n0NGGp61q3UESmJ8dx11pG8dfNxpDVJYuyLc/n5v+exdfe+aIcmEjHhSDCtnXP5AN5rZpA6bYH1AdN5XlmF573dY78LSCIH2jjnyoAiID0M8YpETN92LXjnF8fzq2E/4T/fbOa0v3/Gm/PzdEqzNAjVSjBmNs3MFgcZhldzOcG2PCr+w65wzvUBTvCGUdVoExjbWDPLMbOcggLd+VZiT2J8HL8Yms17txxP51ZN+OWkr7lmwlds3LE32qGJ1KpqJRjn3GnOud5BhreBzWaWBeC9bgnSRR7QPmC6HbDR63uD97oL+Df+YzQHtTGzBKA5UBgktvHOOZ9zzpeRkVGdP0ckKrJbp/LajUP4v3N7MmtVIac//DkvzV6rrRmpt8Kxi2wKUHFW2Gjg7SB1PgJON7OW3sH904GPzCzBzFoBmFkicC6wOEi/I4CPnf4TpY6LjzOuOb4z//nliRzVvjl3v7mYayZ8xZadxdEOTSTswpFgHgCGmVkuMMybxsx8ZvYMgHOuEPgj8JU33OuVJeNPNAuBBcAG4Gmv32eBdDNbAdxOkLPTROqq9mmNefGawfzhp72YuXIbZzzyOR8syo92WCJhZfVpo8Dn87mcnJxohyFSIyu27OaXkxawaEMRFx7dlt//tBfNUhKjHZY0IGY21znnC3e/upJfJMq6ZTbljZuGcMup3Xhr/gbOemQGs1Zti3ZYIiFTghGJAYnxcdx+ende+9kQEuONy56exZ/eX8K+sv3RDk3ksCnBiMSQozu05P1bT+DyQR0Y//kqhj/+hR5sJnWWEoxIjGmclMD9F/Th+TED2bq7hJ8+/l+e+mwl+/WYZqljlGBEYtQpPTL5zy9PZGiP1jzwwVJGPzeHLbt0OrPUHUowIjEsrUkS/7zyaB64sA85aws5+9EZzMjVHSukblCCEYlxZsbIQR2Y8vPjadk4iauem8ODHy6lbH95tEMT+VFKMCJ1xE9apzLl58dzqa89T366kkvHz2KD7mcmMUwJRqQOaZQUzwMX9eXRkf1Ymr+Tsx+doWfNSMxSghGpg4b3a8t7t5xA+7RGjH1xLr+f8o2umZGYowQjUkd1atWE1382hKuP68SEmWu46J8zWb31u2iHJXKAEoxIHZacEM895/Vi/KgBrC/cy7mPzWDK1xujHZYIoAQjUi+c3qsN7996Aj2ymnHLy/P5wzvfUKqzzCTKlGBE6om2LRrxythjuPq4Tjz/xRqueHq2LsyUqFKCEalHEuPjuOe8Xjw6sh+LNhRx7mP/JWfNDx4EKxIRSjAi9dDwfm158+YhNEqKZ+T4WUz4YrUezSwRF1KCMbM0M5tqZrnea8sq6o326uSa2WivLNXMFgQMW83sEW/eGDMrCJh3XShxijREPdo0Y8rPj+fk7hn8/p1vuf3Vr9lbolOZJXJC3YK5E5junMsGphPkscZmlgbcAwwGBgH3mFlL59wu51y/igFYC7wR0HRSwPxnQoxTpEFq3iiR8aN8/GrYT3hrwQYuePIL1m7TqcwSGaEmmOHARG98InB+kDpnAFOdc4XOue3AVODMwApmlg1kAjNCjEdEKomLM34xNJvnxwwkv6iY8/7xXz5eujnaYUkDEGqCae2cywfwXjOD1GkLrA+YzvPKAl2Gf4slcCfxRWa20MxeM7P2IcYp0uCd3D2Td39xPO3TGnPNhBwenrqccj1jRmrRIROMmU0zs8VBhuHVXIYFKav8qR4JvBww/Q7QyTnXF5jG91tJweIba2Y5ZpZTUKDbmIv8mPZpjXn9Z0MYMaAdj07P5cZ/zeW7fWXRDkvqqUMmGOfcac653kGGt4HNZpYF4L1uCdJFHhC4BdIOOHCpsZkdBSQ45+YGLHObc26fN/k0MOBH4hvvnPM553wZGRmH+nNEGryUxHgeGtGX35/Xk2lLNnPRP2eSt31PtMOSeijUXWRTgNHe+Gjg7SB1PgJON7OW3llmp3tlFS7j4K2XimRV4afAkhDjFJEAZsaY4zoz4epBbNixl+GPf6HrZSTsQk0wDwDDzCwXGOZNY2Y+M3sGwDlXCPwR+Mob7vXKKlxCpQQD3GJm35jZ18AtwJgQ4xSRIE78SQZv3XwczRolctnTs5ics/7QjUSqyerTxVc+n8/l5OREOwyROqdoTyk3/3se/12xletP6MydZx1JfFyww6dSH5nZXOecL9z96kp+EaF540QmXD2QMUM68fSM1Vw38St2FpdGOyyp45RgRASAhPg4fv/TXtx/QW9m5G7lwidn6qJMCYkSjIgc5IrBHXnh2kFs3b2P4U98wZcrt0U7JKmjlGBE5AeGdG3F2zcfR6umyYx6djYvz1kX7ZCkDlKCEZGgOqY34Y2bhnB8divuemMRD364VFf+S40owYhIlZqlJPLMVT4uH9yBJz9dyW2TFrCvTHdklupJiHYAIhLbEuLjuP/83rRv2Zi/fLiUzTuLGT/KR/PGidEOTWKctmBE5JDMjJ+d3JVHR/Zj/rodXPTUTNYX6vYy8uOUYESk2ob3a8sL1w5iy85iLnhyJgvzdkQ7JIlhSjAiUiPHdEnnjZuGkJwQx6XjZjF9iZ4tI8EpwYhIjXXLTOXNm4fQLbMp17+Qw4uz1kY7JIlBSjAiclgyU1N4ZewxnNI9k9+9tZg/f7BEpzHLQZRgROSwNUlOYNyoAVx5TAfGfbaKW16Zr9OY5QCdpiwiIUmIj+OPw3vTrmVjHvhgKdv3lDBulI+myfp6aei0BSMiITMzbjypK3+7+ChmrSrk8qdnsW33vkM3lHpNCUZEwuaiAe0Yd+UAlm3axcXjvmTDjr3RDkmiKOQEY2ZpZjbVzHK915ZV1PvQzHaY2buVyjub2Wyv/SQzS/LKk73pFd78TqHGKiK177SerXnx2sEU7NrHiH/OZMWWXdEOSaIkHFswdwLTnXPZwHRvOpiHgFFByv8CPOy13w5c65VfC2x3znUDHvbqiUgdMKhzGpPGHktZuWPEU18yf932aIckURCOBDMcmOiNTwTOD1bJOTcdOOinjJkZcCrwWpD2gf2+Bgz16otIHdDziGa8duOxNEtJ5IpnZvP58oJohyQRFo4E09o5lw/gvWbWoG06sMM5V+ZN5wFtvfG2wHqv3zKgyKsvInVEx/QmvHbjsXRIa8y1E7/i3YUbox2SRFC1EoyZTTOzxUGG4SEuP9gWiavGvMDYxppZjpnlFBToF5JIrMlslsKkG46lX/sW/OLl+brqvwGp1onqzrnTqppnZpvNLMs5l29mWcCWGix/K9DCzBK8rZR2QMVPnDygPZBnZglAc6AwSGzjgfEAPp9PlxGLxKDmjRJ54ZrB/Pzf8/jdW4sp3F3CLUO7ob3e9Vs4dpFNAUZ746OBt6vb0DnngE+AEUHaB/Y7AvjYqy8idVCjpHieGjWAC49uy8PTlvOHd75F/9L1WzgSzAPAMDPLBYZ505iZz8yeqahkZjOAyfgP1ueZ2RnerN8At5vZCvzHWJ71yp8F0r3y26n67DQRqSMS4+P464ijuOa4zkyYuYbfvrlI9y+rx0K+l4NzbhswNEh5DnBdwPQJVbRfBQwKUl4MXBxqfCISW+LijN+deySNkuJ44pOV7Cst58ERfUmI13Xf9Y1uFiQiEWdm3HFGD1IS4vnb1OXsKyvnkZH9SFSSqVeUYEQkan4xNJuUxHjuf38J+8r28/jlR5OSGB/tsCRM9HNBRKLq+hO78MfhvZi2ZAvXv5DD3hLd7r++UIIRkagbdWwnHryoL/9dsZWrJ8xh976yQzeSmKcEIyIx4ZKB7Xnk0n58tWY7Vz07m6K9pdEOSUKkBCMiMWN4v7Y8cXl/Fm0o4opnZrH9u5JohyQhUIIRkZhyZu8sxo/ysXzzbi57ehYFu/TgsrpKCUZEYs4pPTJ5fsxA1m7bw6Xjv2TLzuJohySHQQlGRGLScd1aMfGaQWwuKmbk07PYsktJpq5RghGRmDWocxoTrhnEpqJiLhuv3WV1jRKMiMS0gZ3SeH7MQDbuKOZyHZOpU5RgRCTmDe6SzvNXDyRv+16ueGYWW3crydQFSjAiUicc0yWdZ8f4WFe4hyufmc02JZmYpwQjInXGkK6teHb0QFZv/Y4rnplNoa6TiWlKMCJSpxzX7eAko4sxY5cSjIjUOcdnt+Lpq3ysLNjNlc/OZsceJZlYpAQjInXSiT/JYPyoAeRu9ieZoj26d1msCSnBmFmamU01s1zvtWUV9T40sx1m9m6l8pfMbJmZLTaz58ws0Ss/2cyKzGyBN/xfKHGKSP10cvdMxo0awPJNXpLRDTJjSqhbMHcC051z2cB0bzqYh4BRQcpfAnoAfYBGBDxiGZjhnOvnDfeGGKeI1FOn9MjkqVFHs3TTTq56Trf6jyWhJpjhwERvfCJwfrBKzrnpwK4g5e87DzAHaBdiPCLSAJ3aozVPXH40izcUcd3Erygu1UPLYkGoCaa1cy4fwHvNPJxOvF1jo4APA4qPNbOvzewDM+v1I23HmlmOmeUUFBQczuJFpB44vVcb/n7JUcxeXciN/5pLSVl5tENq8A6ZYMxsmneMpPIwPIxxPAl87pyb4U3PAzo6544C/gG8VVVD59x455zPOefLyMgIY0giUtcM79eW+8/vw6fLCrht0nzK9ivJRFPCoSo4506rap6ZbTazLOdcvpllAVtqGoCZ3QNkADcELHNnwPj7ZvakmbVyzm2taf8i0rBcPrgDe0rKuO+9JTRKXMRDI/oSF2fRDqtBCnUX2RRgtDc+Gni7Jo3N7DrgDOAy51x5QHkbMzNvfJAX57YQYxWRBuK6E7pw22nZvD4vj9+/8w3+w7wSaYfcgjmEB4BXzexaYB1wMYCZ+YAbnXPXedMz8J8t1tTM8oBrnXMfAU8Ba4EvvXzyhnfG2AjgZ2ZWBuwFRjp9QkSkBm4dms13+8p4esZqmiQn8Jsze0Q7pAYnpATjnNsGDA1SnkPAKcfOuROqaB90+c65x4HHQ4lNRBo2M+O3Zx/JdyX7+eenK2manMDNp3SLdlgNSqhbMCIiMcvMuG94b/bsK+Ohj5bROCmeq4/rHO2wGgwlGBGp1+LijL9efBR7Svbzh3e+pUlSApcMbB/tsBoE3YtMROq9hPg4/nF5f07IbsWdbyzk3YUbox1Sg6AEIyINQnJCPONH+RjQsSW3vbKAT5bV+KoKqSElGBFpMBolxfPsmIH8pHUqN/1rHvPXbY92SPWaEoyINCjNUhKZcM1AMlKTuXrCV6zY8oPbJEqYKMGISIOTmZrCi9cOIiHOuOrZOWzcsTfaIdVLSjAi0iB1TG/ChKsHsbO4jNHPzdFTMWuBEoyINFi92zZn/FUDWLttD9dM+Iq9JbrNfzgpwYhIgzakayseGdmP+et3cNNLcynVHZjDRglGRBq8s/tk8cfhvflkWQG/eX0h5eW69WE46Ep+ERHgymM6sm13CQ9PW06rpsn89uwjox1SnacEIyLiuWVoN7Z9t4/xn6+iVdMkxp7YNdoh1WlKMCIiHjPjnvN6sW13CX96fynpTZK5aEC7aIdVZynBiIgEiI8z/n7pUezYW8KvX19IWpMkTumRGe2w6iQd5BcRqSQ5IZ5xo3wcmZXKTS/NY2HejmiHVCeFlGDMLM3MpppZrvfasop6H5rZDjN7t1L5BDNbbWYLvKGfV25m9piZrTCzhWZ2dChxiojUVNPkBJ4bM5C0JklcMyGH9YV7oh1SnRPqFsydwHTnXDYw3ZsO5iFgVBXz7nDO9fOGBV7ZWUC2N4wF/hlinCIiNZaZmsKEqwdSUrafqyd8RdGe0miHVKeEmmCGAxO98YnA+cEqOeemAzW5o9xw4AXnNwtoYWZZIUUqInIYslunMv4qH+u27WHsiznsK9PV/tUVaoJp7ZzLB/BeD+dI2P3ebrCHzSzZK2sLrA+ok+eV/YCZjTWzHDPLKSgoOIzFi4j8uGO6pPPQxX2ZvbqQOybrQszqOmSCMbNpZrY4yDA8DMu/C+gBDATSgN9ULDZI3aDvqHMznRn7AAARPUlEQVRuvHPO55zzZWRkhCEkEZEfGt6vLXec0Z0pX2/kr/9ZFu1w6oRDnqbsnDutqnlmttnMspxz+d4urBo9Iq5i6wfYZ2bPA//jTecBgQ/NbgfoGaciElU3ndyVvO17efLTlbRr2ZjLB3eIdkgxLdRdZFOA0d74aODtmjSuOK5iZob/+M3igH6v8s4mOwYoCkhGIiJRYWb8cXgvTumewe/eXswnS/XY5R8TaoJ5ABhmZrnAMG8aM/OZ2TMVlcxsBjAZGGpmeWZ2hjfrJTNbBCwCWgH3eeXvA6uAFcDTwE0hxikiEhYJ8XE8fvnRHJmVys3/nsfiDUXRDilmmXP152CVz+dzOTk50Q5DRBqALTuLueDJmZTsL+fNm4bQrmXjaId02MxsrnPOF+5+dSW/iMhhyGzmv0amuHQ/Y57XNTLBKMGIiBym7NapjB/lY+2277jhXzmUlOlhZYGUYEREQnBs13QeGnEUs1YVcvebi6hPhx1Cpbspi4iE6Pz+bVm19Tsem55Lt8ym3HCSniMDSjAiImHxy9OyWVWwmwc+XEqnVk04o1ebaIcUddpFJiISBmbGXy8+ir7tWnDbKwt0+jJKMCIiYZOSGM/TowbQonEi17+Qw5adxdEOKaqUYEREwiizWQrPjPZRtLeU61/IYW9Jw737shKMiEiY9TqiOY+O7M/CDUX8z+SvG+zdl5VgRERqwbCerbnrrB68tyifR6Ytj3Y4UaGzyEREasn1J3RhxZbdPPbxCrpkNOX8/kEfa1VvaQtGRKSWmBn3nd+HwZ3T+PXrC5m7dnu0Q4ooJRgRkVqUlBDHU1cOIKt5Cje8mMP6wj3RDililGBERGpZyyZJPDt6IPvKyrluYg67ihvGjTGVYEREIqBbZlP+ecUAVhTs5rZXFjSIM8uUYEREIuT47Fbcc15Ppi/dwt+n1v8zy0JKMGaWZmZTzSzXe21ZRb0PzWyHmb1bqXyGmS3who1m9pZXfrKZFQXM+79Q4hQRiRWjjunIpb72PP7JCt5bWL+fBB/qFsydwHTnXDYw3ZsO5iFgVOVC59wJzrl+zrl+wJfAGwGzZ1TMc87dG2KcIiIxwcy49/xeHN2hBf8z+Wu+3bgz2iHVmlATzHBgojc+ETg/WCXn3HRgV1WdmFkqcCrwVojxiIjEvOSEeJ66cgDNG/nvWVb4XUm0Q6oVoSaY1s65fADvNfMw+7kA/5ZQYCo/1sy+NrMPzKxXiHGKiMSUzGYpjBs1gILd+7j5pXmU7q9/T8M8ZIIxs2lmtjjIMDyMcVwGvBwwPQ/o6Jw7CvgHP7JlY2ZjzSzHzHIKCgrCGJKISO06qn0L/nxBH75ctY3731sS7XDC7pC3inHOnVbVPDPbbGZZzrl8M8sCttQ0ADNLBwbh34qpWObOgPH3zexJM2vlnNsaJL7xwHgAn89X/8/7E5F65aIB7ViSv5Nn/ruanlnNuGRg+2iHFDah7iKbAoz2xkcDbx9GHxcD7zrnDjw4wczamJl544O8OLeFGKuISEy686wenJDdiv99a3G9up1MqAnmAWCYmeUCw7xpzMxnZs9UVDKzGcBkYKiZ5ZnZGQF9jOTg3WMAI4DFZvY18Bgw0jmnrRMRqZcS4uP4x2X9adM8hRv/NZdNRfXjQWVWn763fT6fy8nJiXYYIiKHZdmmXVzw5Bdkt05l0thjSEmMj8hyzWyuc84X7n51Jb+ISIzo3iaVv1/Sj6/X7+DuNxdT1zcAlGBERGLImb3bcNtp2bw+L4/nvlgT7XBCogQjIhJjbjk1mzN6teZP7y9h5sofnDxbZyjBiIjEmLg442+X9KNTemN+8e/55BftjXZIh0UJRkQkBjVNTmDcqAEUl+7nppfmsa9sf7RDqjElGBGRGNUtM5WHLj6K+et2cN+7de9KfyUYEZEYdnafLMae2IUXZ63l9bl50Q6nRpRgRERi3K/P6M4xXdL47ZuL+GZjUbTDqTYlGBGRGOe/0v9oWjZO4sZ/zaVoT2m0Q6oWJRgRkTogIzWZJ644mk1Fxdw2aT7l5bF/EaYSjIhIHTGgY0v+79yefLKsgMc+zo12OIekBCMiUodceUxHLjy6LY9Oz+WTpTV+QkpEKcGIiNQhZsb95/ehR5tm3PrKfNZt2xPtkKqkBCMiUsc0SornqSuPBuCGf81lb0lsXoSpBCMiUgd1TG/CoyP7syR/J3e/tSgm77ysBCMiUked0iOTW4dm88a8Dfxr9rpoh/MDIScYM0szs6lmluu9tgxSp5+ZfWlm35jZQjO7NGBeZzOb7bWfZGZJXnmyN73Cm98p1FhFROqbW4dmc95RR9A6NTnaofxAOLZg7gSmO+eygenedGV7gKucc72AM4FHzKyFN+8vwMNe++3AtV75tcB251w34GGvnoiIBIiLM/5xWX9O79Um2qH8QDgSzHBgojc+ETi/cgXn3HLnXK43vhHYAmSYmQGnAq8FaR/Y72vAUK++iIjUAeFIMK2dc/kA3mvmj1U2s0FAErASSAd2OOfKvNl5QFtvvC2w3uu3DCjy6ouISB2QUJ1KZjYNCLb9dXdNFmZmWcCLwGjnXHkVWyQVp0L82LzAPscCYwE6dOhQk3BERKQWVSvBOOdOq2qemW02syznXL6XQIJeWmpmzYD3gP91zs3yircCLcwswdtKaQds9OblAe2BPDNLAJoDhUFiGw+MB/D5fLF3np6ISAMVjl1kU4DR3vho4O3KFbwzw94EXnDOTa4od/4Ttz8BRgRpH9jvCOBjF4sneouISFDhSDAPAMPMLBcY5k1jZj4ze8arcwlwIjDGzBZ4Qz9v3m+A281sBf5jLM965c8C6V757QQ/O01ERGKU1aeNAp/P53JycqIdhohInWJmc51zvnD3qyv5RUSkVtSrLRgzKwDWHmbzVvhPOohFsRqb4qoZxVUziqtmQomro3MuI5zBQD1LMKEws5za2EQMh1iNTXHVjOKqGcVVM7EYl3aRiYhIrVCCERGRWqEE873x0Q7gR8RqbIqrZhRXzSiumom5uHQMRkREaoW2YEREpHY452JywP/cmGXACuDOIPOTgUne/NlAp4B5d3nly4AzDtUn0NnrI9frM6mqZQT0sQ3/KYGVl3EesBMoAdZVxOUtY51XvhM4J1Jx4b+n26fecvcBawLi+j3+O1XvA4rx3ysubHEF9FPg/e0FldbXGmAx/mcBFQf8PWnAVO9v2eMtK2LvJdAd+NqLax9QBtwbiXXm9ZHr/d37gMcrffaPAXZ463NTwHpO89qVAN8BF0UqLqAx8AHff8Y2BsQ1BtgdsL4ejvD6+iwgru+AAQF9LfTW1178z6yK1PpK5eDPVynwXCTWl1c+DJgLLPJeTw3oa4BXvgJ4jO/3dFX8T+Z6ry0P+T0e7URSRXKJx387/y74b+3/NdCzUp2bgKe88ZHAJG+8p1c/2VvpK73+quwTeBUY6Y0/BfysimW86vVxuvfBXOi9UYHLKABe8paxFvjAa/+hN53szS+IYFxZwJ+9PlKB/IC4nsD/ZVAb62uS1886YAnQ1HtdB8QHJJg7grR7EPi7t9y7veVE7L0MbOMtbwfwTgTWWUVcvYCT8d/09aVKn/01+O/tZ8AC4DOv/FnvvU3G/4C+7ZGKC3+CecTrI8l7nyvi+i3+BB6t9bUceD3Id8W9AXH9Av+XeiTjCmyzCv/9Fmt7fVX87f2BI7zx3sCGgLjmAMfi/3x9AJzllT+Il9Tw37rrL3U1wRwLfBQwfRdwV6U6HwHHeuMJ3htiletW1KuqT6/NViCh8rKDLGOHV3ZXpSFwGVsD2tyN/xeTea93Byxja6TiCtJmCv5f4AZMA96vpfVV8Tcur3hPvD6WB9RbA3wcpN0y4E9e/SxvOmLvZaV1cTrwBd9/xmpzne2o1Mdk4MuA6Sz8X4QVba7A/+vb8P9o+VNAve8iFVeQNo8Bu7xlVP4bIra+vLJC4Oog3xXLgX8GlJdEY30B2fiffVURV22ur614WyQB/Rj+rfhk73OzNGDeZcA4b3wZkBXw+Vp2qO/yWD0Gc+BhY57AB5H9oI47+IFkVbWtqrwmDz0rxv84goryirqBy4gLWM46/LtWsvFvAlfcZSDPqxepuA60MbNOQD/8H6h0oBkw0MwWmtlzAf2EI64ioIf3t68PqF8W0Mbh/4cYZ2ZjA9q18WJb775/kF0k38vANiOBl/n+M1ab66wirgrbgSYB0xXtAj9j5QFxfev1lY//CyVScR1o4z0O/Vz8X+zpQEugh7e+XvPaRjKuZODXZrYA/xdyxfuYHrC+KvrqEen1hf9LfFJAXLW5voI9uPEiYL5zbh/f/w9UXgbU8OGSELsH+avzsLGq6oSrvKplVC53Aa/2I22CiVRcFfMaA68Dt3nlDv/xj9vxJ518YHAtx1VRv6LNcfh3D4wCbjazE3+k3aFiqI11lgj8FP+vyop5kVhnVamqfuX/j+osP5xxVbSJx5+MH8P/Q8Lh30r9pXOuL/6tvxMjHFce/t2fJ3hD0x9ZTnkE46poU/EDpqK/NdTu+jrwWTGzXvh3p95Qnfo1FasJpuJhYxUCH0T2gzqVHkhWVduqyg889CzIsiovI4Xvf0m3D6gbuIz9AcvpgP9XZC7+L6qOAcsoj2BcABuAF/Af/5kSsL5ygXbOuXLgafybvuGKqzmw1FsH7QPqJ1a0cc5VLKsx/uMKx3jtNuH/tdU+4EF2kXwvK9pcDMzDv8UXiXVWEVeFlvh3dRFQHw7+jMV5ce3Efwyy4umxZRGMq6LN4976eZzv19dKbx2Bf31lRDiuNUB759wu4BX8W3qF3nIq1ldFX8sjGFcecAr+/4+vicz6OvDgRjNrh/9/7irn3MqA+u2CLANgs/e5wn7k4ZIHOdQ+tGgM3gpfhf8AV8XBrF6V6txMpYNq3ngvDj7Ivwr/r6oq+8T/6zTwANlNVSxjstdH4IHh0ystYysHH+T/MGBfaOBB/q0RjMvwn0GyMMj6Oilgff2R7w90hiOuV71+1nPwQf713jKa4D/p4GbgGWAm/pMRXgUe4uCD/OMi+V4GtFkBXB3BdTa5Uh/rgH9X+uyvBd7g+4P8n3vlz3HwQf4dEY7rA69O3I+srxvw7z6KSFzeMn7t9ZEIzAJyvHn3Efwgf6TW183AfOAPEVxfFcto4bW/KDAmb95X+H/oVRzkP9srf4iDD/I/eMjv8mgnkx9JMmfj/zWxku8Pjt8L/NQbT/FW6gr8Zz10CWh7t9duGd4ZEFX16ZV38fpY4fWZXNUyAvrY5g3L8CeMiriG4z+4WXHcoUvAMtZ75bsq6kciLuB4/Ju5O/j+VM1rvL5exL+1sA//P9jl4YwroJ+t3t9eAJzlvZfX4/+QL8S/tbIt4O9JB6Zz8GnKkX4vW3rrZVWlv6dW11lAH6Xe374b/9bJzV6bId76KgU2B8SV7i234jTliyMVF/5fuo6DTweu+DL6sxfnPq/d9RGMqwn+LdCKz/4moFtAX4u8dnvxTgSI4PuY4pWt5eDPV62uL6/8f733aEHAkOnN8+HfDbwS/5aoBXy+puP/X5wOpB3qe1xX8ouISK2I1WMwIiJSxynBiIhIrVCCERGRWqEEIyIitUIJRkREaoUSjIiI1AolGBERqRVKMCK1yMwqboqZYmZNzOwbM+sd7bhEIkEXWorUMjO7D/8V1Y2APOfcn6MckkhEKMGI1DIzS8J/f6diYIhzbn+UQxKJCO0iE6l9afhv9JmKf0tGpEHQFoxILTOzKfhvE98Z/xMBfx7lkEQiIuHQVUTkcJnZVUCZc+7fZhYPzDSzU51zH0c7NpHapi0YERGpFToGIyIitUIJRkREaoUSjIiI1AolGBERqRVKMCIiUiuUYEREpFYowYiISK1QghERkVrx/ytzceLPgQqAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b5c7a3b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tragDF.plot(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot moth at certain timesteps\n",
    "# plot final positions\n",
    "def plotMoth(x,y,theta, phi, F, alpha, tau0, fig, ax):\n",
    "    # plot moth and force\n",
    "\n",
    "    thoraxLen = 0.908 * 2# cm\n",
    "    abLen = 1.747 *2 #cm\n",
    "    bodyWidth = 1.1\n",
    "\n",
    "\n",
    "    # plot trajectory\n",
    "    #fig, ax = plt.subplots( figsize = [10,10])\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    #ax.plot(x,y, label = 'trajectory x vs y')\n",
    "\n",
    "    center = np.array([x, y])\n",
    "    head = center + np.array(pol2cart(thoraxLen, theta))\n",
    "    abTip = center + np.array(pol2cart(abLen, phi))\n",
    "\n",
    "\n",
    "\n",
    "    xx, yy = zip(*[center, head])\n",
    "    xab,yab = zip(*[center, abTip])\n",
    "\n",
    "    el = Ellipse(midpoint(center, head), width = thoraxLen, height = bodyWidth, facecolor='#907760', alpha=0.9, angle = math.degrees(theta))\n",
    "    el2 = Ellipse(midpoint(center, abTip), width = abLen, height = bodyWidth, facecolor='#DEC9B0', alpha=0.9, angle = math.degrees(phi))\n",
    "    \n",
    "#     torqueArc = Arc([x,y], 1, 1, angle=0.0, theta1= np.degrees(theta), theta2=np.degrees(phi), color = \"#B61212\")\n",
    "    \n",
    "    \n",
    "    ax.add_artist(el)\n",
    "    ax.add_artist(el2)\n",
    "#     ax.add_artist(torqueArc)\n",
    "    \n",
    "#     # add torque arrow\n",
    "#     ax.arrow(x = x + 1, y = forceCenter[1], \n",
    "#              dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "#             head_width = 0.2, color = \"#B61212\")\n",
    "\n",
    "\n",
    "\n",
    "    ax.plot(xx, yy, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xx, yy, s= 10, c = 'k', alpha = 0.2)\n",
    "    ax.plot(xab,yab, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xab,yab, s = 10, c = 'k', alpha = 0.2)\n",
    "\n",
    "    # plot force \n",
    "    forceAlpha = alpha\n",
    "    forceCenter = midpoint(center, head)\n",
    "    forceMagnitude = F / 15000 # scale \n",
    "    forceAngle = theta + forceAlpha\n",
    "    forceTip = np.add(pol2cart(forceMagnitude, forceAngle), forceCenter)\n",
    "    ax.arrow(x = forceCenter[0], y = forceCenter[1], \n",
    "             dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "            head_width = 0.2, color = \"#B61212\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tmp dir for images\n",
    "tmpDir2 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs', \"MothVid_Velocity\")\n",
    "if not os.path.exists(tmpDir2):\n",
    "    os.mkdir(tmpDir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize = [10,10])\n",
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "maxFrms = len(x)\n",
    "\n",
    "xlim = [np.min(x[0:maxFrms+1])-5, np.max(x[0:maxFrms+1])+5]\n",
    "ylim =[np.min(y[0:maxFrms+1])-5, np.max(y[0:maxFrms+1])+5]\n",
    "xrng = np.diff(xlim)\n",
    "yrng = np.diff(ylim)\n",
    "maxrng = np.max([xrng, yrng])\n",
    "newxlim = [np.sum(xlim)/2 - maxrng /2, np.sum(xlim)/2 + maxrng /2]\n",
    "newylim = [np.sum(ylim)/2 - maxrng /2, np.sum(ylim)/2 + maxrng /2 ]\n",
    "\n",
    "\n",
    "for ii in np.arange(1, maxFrms, 1):\n",
    "    fig, ax = plt.subplots( figsize = [10,10])\n",
    "\n",
    "    plt.plot(x[0:ii+1], y[0:ii+1], c= 'orange', label = \"Python\")\n",
    "    plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "    \n",
    "\n",
    "    ax.set_ylim(newylim)\n",
    "    ax.set_xlim(newxlim)\n",
    "    ax.set_ylabel(\"vertical position (cm)\")\n",
    "    ax.set_xlabel(\"horizontal position (cm)\")\n",
    "    \n",
    "#     # add torque\n",
    "#     if tau0 < 0:\n",
    "#         marker = r'$\\circlearrowleft$'\n",
    "#     else:\n",
    "#         marker = r'$\\circlearrowright$'\n",
    "#     ax.plot(x[ii],y[ii], marker=marker,ms=tau0/100000,  color = \"#B61212\")\n",
    "    fig.savefig(os.path.join(tmpDir2, str(ii).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "    # plt.legend()\n",
    "    plt.close()\n",
    "    if np.mod(ii, 10) == 0:\n",
    "        print(ii)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000001_output_mothPath2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and scaler\n",
    "modelPath = r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0__Num_512_512_512_16__Wei_0_2019_06_13__02_19_18veloc.h5\"\n",
    "model = load_model(modelPath)\n",
    "\n",
    "# read in scalers\n",
    "scalerX = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerX_veloc.pkl\", \"rb\"))\n",
    "scalerY = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerY_veloc.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               7680      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 541,251\n",
      "Trainable params: 541,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REFREF: check model loss\n",
    "\n",
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [\"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_99\", \"y_99\", \"phi_99\",  \"theta_99\",\n",
    "                   \"x_dot_99\", \"y_dot_99\",\"phi_dot_99\",\"theta_dot_99\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980102, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980102/1980102 [==============================] - 76s 38us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0012489242974622523, 0.0012489242974622523]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate F and alpha from Fx and Fy\n",
    "\n",
    "# calculate alpha\n",
    "def quadrant(Fx, Fy):\n",
    "    if (Fx >= 0) & (Fy >= 0):\n",
    "        q = 1\n",
    "    elif (Fx < 0) & (Fy >= 0):\n",
    "        q = 2\n",
    "    elif (Fx < 0) & (Fy < 0):\n",
    "        q = 3\n",
    "    elif (Fx >= 0) & (Fy < 0):\n",
    "        q = 4\n",
    "    else:\n",
    "        q = 999999\n",
    "    return(q)\n",
    "\n",
    "\n",
    "def angleCalc(Fx, Fy, q):\n",
    "    fx = np.abs(Fx)\n",
    "    fy = np.abs(Fy)\n",
    "    \n",
    "    if q == 1:\n",
    "        alpha = np.arctan(fy/fx)\n",
    "    elif q == 2:\n",
    "        alpha = np.pi - np.arctan(fy/fx)\n",
    "    elif q == 3: \n",
    "        alpha = np.pi + np.arctan(fy/fx)\n",
    "    elif q == 4:\n",
    "        alpha = (2*np.pi) - np.arctan(fy/fx)\n",
    "    return(alpha)\n",
    "\n",
    "def F_alpha_calc (Fx, Fy):\n",
    "    q = quadrant(Fx, Fy)\n",
    "    alpha = angleCalc(Fx, Fy, q)\n",
    "    F = np.sqrt(Fx**2 + Fy**2)\n",
    "    return(F, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputData = # make dataset\n",
    "Xcols = [\"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_99\", \"y_99\", \"phi_99\",  \"theta_99\",\n",
    "                   \"x_dot_99\", \"y_dot_99\",\"phi_dot_99\",\"theta_dot_99\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref calculate new x and y from error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "overallCtr = 1\n",
    "\n",
    "\n",
    "# refref: maybe the derivatives should be in the input, so it doesn't go too fast\n",
    "\n",
    "# define initial position and goal position\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "where_I_am = OrderedDict({\n",
    "                        \"x_0\": [0], \n",
    "                        \"x_dot_0\":[-0.0001], \n",
    "                        \"y_0\":[0], \n",
    "                        \"y_dot_0\": [0.0001]  ,\n",
    "                        \"theta_0\": [np.pi/2]  ,\n",
    "                        \"theta_dot_0\": [0.0001]  , \n",
    "                        \"phi_0\": [3*np.pi/2]   ,\n",
    "                        \"phi_dot_0\":[0.0001] })\n",
    "\n",
    "\n",
    "where_I_want2b = OrderedDict({\"x_99\": [0],\n",
    "                              \"y_99\": [0],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                             \"y_dot_99\": [0.00001], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                              \"theta_dot_99\": [0.00001], \n",
    "                             \"phi_dot_99\": [0.00001]})\n",
    "\n",
    "xList = []\n",
    "yList = []\n",
    "\n",
    "prevXY = [where_I_am[\"x_0\"][0], where_I_am[\"y_0\"][0]]\n",
    "\n",
    "goalXY = [where_I_want2b[\"x_99\"][0], where_I_want2b[\"y_99\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b5c9a7eac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "# don't pay attention to F, alpha, tau0\n",
    "plotMoth(where_I_am[\"x_0\"][0],where_I_am[\"y_0\"][0],where_I_am[\"theta_0\"][0], where_I_am[\"phi_0\"][0], F, alpha, tau0, fig, ax)\n",
    "plotMoth(where_I_want2b[\"x_99\"][0],\n",
    "         where_I_want2b[\"y_99\"][0],\n",
    "         where_I_want2b[\"theta_99\"][0],\n",
    "         where_I_want2b[\"phi_99\"][0], F, alpha, tau0, fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "inputData = inputData.loc[:, Xcols]\n",
    "#print(inputData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4385.01074219,   950.91711426,  5715.46044922], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict force needed to attain \n",
    "## scale data and transform\n",
    "X_scaled = scalerX.transform(inputData)\n",
    "\n",
    "\n",
    "## predict with nnet\n",
    "pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "# inverse transform\n",
    "pred_trans = scalerY.inverse_transform(pred)\n",
    "\n",
    "pred_trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\Figs\\\\MothVid_Velocity'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpDir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 0\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 1\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 2\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 3\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 4\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 5\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 6\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 7\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 8\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 9\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 10\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 11\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 12\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 13\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 14\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 15\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 16\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 17\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 18\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 19\n"
     ]
    }
   ],
   "source": [
    "###### start of loop\n",
    "##### hybrid approach\n",
    "\n",
    "for jj in range(20):\n",
    "\n",
    "    inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "    inputData = inputData.loc[:, Xcols]\n",
    "\n",
    "\n",
    "    # predict force needed to attain \n",
    "    ## scale data and transform\n",
    "    X_scaled = scalerX.transform(inputData)\n",
    "    \n",
    "    \n",
    "    ## predict with nnet\n",
    "    pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "    # inverse transform\n",
    "    pred_trans = scalerY.inverse_transform(pred)\n",
    "    Fx, Fy, tau0  = pred_trans[0]\n",
    "\n",
    "    # convert FX, Fy, back to F, alpha\n",
    "    # F, alpha = cart2pol(Fx, Fy)\n",
    "    F, alpha = F_alpha_calc(Fx, Fy)\n",
    "\n",
    "\n",
    "    # plug predictions into simulation\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    state0_ICs = [ v[0] for v in where_I_am.values() ]\n",
    "\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    # add previous position to x and y\n",
    "    x = x + prevXY[0]\n",
    "    y = y + prevXY[1]\n",
    "    \n",
    "    # plot actual position\n",
    "    xList.extend(x.tolist())\n",
    "    yList.extend(y.tolist())\n",
    "\n",
    "\n",
    "\n",
    "    maxFrms = len(x)\n",
    "\n",
    "\n",
    "\n",
    "    # refref: add x's to each plot\n",
    "    for ii in np.arange(0, maxFrms, 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.plot(xList[:-(maxFrms-ii)], yList[:-(maxFrms-ii)], c= 'orange', label = \"moth trajectory\", alpha = 0.3)\n",
    "        #plt.plot(where_I_want2b[\"x_99\"], where_I_want2b[\"y_99\"], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plt.plot(goalXY[0], goalXY[1], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "#         ax.set_ylim([-30, 30])\n",
    "#         ax.set_xlim([-30, 30])\n",
    "        ax.set_ylim([-80, 80])\n",
    "        ax.set_xlim([-80, 80])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir2, str(overallCtr).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        overallCtr += 1\n",
    "\n",
    "\n",
    "        plt.close()\n",
    "        if np.mod(ii, 3) == 0:\n",
    "            print(ii)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate error and compute new initial position, but keep goal position the same\n",
    "\n",
    "    ### REFREF: may be calculating this incorrectly\n",
    "    ### where I am should always start at x_0, y_0 == (0, 0)\n",
    "    ### where I want to be should be the error....\n",
    "    \n",
    "    # update prevXY\n",
    "    prevXY = [x[-1], y[-1]]\n",
    "    \n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    where_I_am2 = OrderedDict({\n",
    "                            \"x_0\": [0], \n",
    "                            \"x_dot_0\":[xd[-1]], \n",
    "                            \"y_0\":[0], \n",
    "                            \"y_dot_0\": [yd[-1]]  ,\n",
    "                            \"theta_0\": [theta[-1]]  ,\n",
    "                            \"theta_dot_0\": [thetad[-1]] , \n",
    "                            \"phi_0\": [phi[-1]]   ,\n",
    "                            \"phi_dot_0\":[phid[-1]] })\n",
    "\n",
    "\n",
    "    # calculate true position\n",
    "    actual_whereIam = OrderedDict({\n",
    "                            \"x\": [where_I_want2b[\"x_99\"] + x],\n",
    "                            \"y\":[where_I_want2b[\"x_99\"] + y]})\n",
    "    \n",
    "    # refref: i'm not sure this is right\n",
    "    \n",
    "    where_I_want2b2 = OrderedDict({\"x_99\": [ goalXY[0] - prevXY[0] ],\n",
    "                              \"y_99\": [goalXY[1] - prevXY[1]],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2], \n",
    "                                  \"x_dot_99\": [0.00001], \n",
    "                             \"y_dot_99\": [0.00001], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                              \"theta_dot_99\": [0.00001], \n",
    "                             \"phi_dot_99\": [0.00001]})\n",
    "    \n",
    "    # update whereIam\n",
    "    where_I_am = where_I_am2\n",
    "    where_I_want2b = where_I_want2b2\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"loop\", jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 60 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_output_mothPath.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_want2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: do the same thing with a smaller, pruned network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vid of multiple moth trajectoies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 40,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.1, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug predictions into simulation\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, alpha, tau0 = (np.random.rand(3)* 1000).tolist()\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/2 - 0.3,0.0001, -np.pi/2 - 0.3,0.0001]\n",
    "state0_ICs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDir3 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019', \"MPC_Example\")\n",
    "if not os.path.exists(tmpDir3):\n",
    "    os.mkdir(tmpDir3)\n",
    "\n",
    "overallCtr2 = 1\n",
    "\n",
    "\n",
    "xlist = []\n",
    "ylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathNum in range(20):\n",
    "    F, alpha, tau0 = (np.random.rand(3)* 10000).tolist()\n",
    "    tau0 = tau0*10\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    xlist.extend(x)\n",
    "    ylist.extend(y)\n",
    "\n",
    "\n",
    "    for ii in np.arange(0, globalDict[\"nstep\"], 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.scatter(xlist[:-(globalDict[\"nstep\"]-ii-1)], ylist[:-(globalDict[\"nstep\"]-ii-1)], c= 'orange', label = \"moth trajectory\", s = 2)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "        ax.set_ylim([-30, 30])\n",
    "        ax.set_xlim([-30, 30])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir3, str(overallCtr2).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        overallCtr2 += 1\n",
    "\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir3)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2, setpts=0.2*PTS\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_MPCVID.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "xlist[:-(globalDict[\"nstep\"]-ii-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])   \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "              \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RondomWTS_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(100):\n",
    "    \n",
    "        # # fit model without regularization\n",
    "    stt = time.time()\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                            batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "    winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "    endd = time.time() - stt\n",
    "    print(endd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "    ctr += 1\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model):\n",
    "    \n",
    "     wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_and_ODE",
   "language": "python",
   "name": "dl_and_ode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
