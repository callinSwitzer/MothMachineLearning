{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 6 June 2019\n",
    "___\n",
    "### - Train Dense, Feedforward Neural Network with Keras\n",
    "### - Train with fully actuated system\n",
    "### - Put velocity as input to network, with only the four controls as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-06-13 14:18:48.973517\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n",
    "\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set\n",
    "## - using underactuated simulations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)\n",
    "\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [\"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_99\", \"y_99\", \"phi_99\",  \"theta_99\",\n",
    "                   \"x_dot_99\", \"y_dot_99\",\"phi_dot_99\",\"theta_dot_99\"]]\n",
    "\n",
    "# put phi into network \"output\"\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>5.761704</td>\n",
       "      <td>23.367432</td>\n",
       "      <td>-2.222497</td>\n",
       "      <td>4.628560</td>\n",
       "      <td>6.334514</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>166.050842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.308109</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>16.957561</td>\n",
       "      <td>-20.768748</td>\n",
       "      <td>11.106142</td>\n",
       "      <td>4.891662</td>\n",
       "      <td>4.921125</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>146.364185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.548527</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>7.760703</td>\n",
       "      <td>-25.280989</td>\n",
       "      <td>4.318522</td>\n",
       "      <td>-0.137526</td>\n",
       "      <td>-0.270820</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>-563.122968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510978</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>-5.931729</td>\n",
       "      <td>0.748787</td>\n",
       "      <td>1.423037</td>\n",
       "      <td>4.826500</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>72.504068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.609007</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-16.195650</td>\n",
       "      <td>-9.280447</td>\n",
       "      <td>6.707153</td>\n",
       "      <td>-0.231868</td>\n",
       "      <td>4.399997</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>-177.812751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_dot_0     y_dot_0  phi_dot_0  theta_dot_0  \\\n",
       "0  2.909070  4.539917  1240.975696 -321.289498  10.607821     5.761704   \n",
       "1  3.308109  3.243816 -1149.257088  365.093207  22.615302    16.957561   \n",
       "2  5.548527  5.436117 -1496.313673  244.869357   0.328348     7.760703   \n",
       "3  0.510978  4.004344  -560.948725   86.858301  24.197259    -0.067853   \n",
       "4  1.609007  6.129205  -214.455052  225.808462   9.118306   -16.195650   \n",
       "\n",
       "        x_99       y_99    phi_99  theta_99     x_dot_99    y_dot_99  \\\n",
       "0  23.367432  -2.222497  4.628560  6.334514  1047.460389  -38.377027   \n",
       "1 -20.768748  11.106142  4.891662  4.921125 -1075.409015  697.828947   \n",
       "2 -25.280989   4.318522 -0.137526 -0.270820 -1133.713595  748.985152   \n",
       "3  -5.931729   0.748787  1.423037  4.826500   -26.956023   45.961219   \n",
       "4  -9.280447   6.707153 -0.231868  4.399997  -539.671502  488.013492   \n",
       "\n",
       "   phi_dot_99  theta_dot_99  \n",
       "0  162.092739    166.050842  \n",
       "1  141.667777    146.364185  \n",
       "2 -561.725041   -563.122968  \n",
       "3   77.007517     72.504068  \n",
       "4 -183.140660   -177.812751  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-29612.961122</td>\n",
       "      <td>2498.912376</td>\n",
       "      <td>53852.149654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26336.915345</td>\n",
       "      <td>-9994.333651</td>\n",
       "      <td>66579.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4645.636361</td>\n",
       "      <td>41785.500502</td>\n",
       "      <td>-13638.356558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11940.326951</td>\n",
       "      <td>30568.337400</td>\n",
       "      <td>-59677.690610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34842.795622</td>\n",
       "      <td>-4409.744037</td>\n",
       "      <td>77836.665059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fx            Fy           tau\n",
       "0 -29612.961122   2498.912376  53852.149654\n",
       "1 -26336.915345  -9994.333651  66579.923810\n",
       "2   4645.636361  41785.500502 -13638.356558\n",
       "3 -11940.326951  30568.337400 -59677.690610\n",
       "4 -34842.795622  -4409.744037  77836.665059"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.479611</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>-0.491811</td>\n",
       "      <td>-0.220474</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>0.450440</td>\n",
       "      <td>-0.318639</td>\n",
       "      <td>-0.229442</td>\n",
       "      <td>-0.094704</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>-0.202153</td>\n",
       "      <td>-0.214663</td>\n",
       "      <td>0.088688</td>\n",
       "      <td>0.089438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.453551</td>\n",
       "      <td>0.264615</td>\n",
       "      <td>0.469097</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.353807</td>\n",
       "      <td>-0.446865</td>\n",
       "      <td>0.295886</td>\n",
       "      <td>0.197180</td>\n",
       "      <td>-0.188053</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>0.205139</td>\n",
       "      <td>0.206023</td>\n",
       "      <td>-0.053019</td>\n",
       "      <td>-0.052671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102133</td>\n",
       "      <td>-0.139825</td>\n",
       "      <td>0.486725</td>\n",
       "      <td>0.399421</td>\n",
       "      <td>0.036643</td>\n",
       "      <td>-0.265189</td>\n",
       "      <td>0.314624</td>\n",
       "      <td>0.345313</td>\n",
       "      <td>-0.234415</td>\n",
       "      <td>-0.252743</td>\n",
       "      <td>0.349240</td>\n",
       "      <td>0.295930</td>\n",
       "      <td>-0.282329</td>\n",
       "      <td>-0.290446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025410</td>\n",
       "      <td>0.473391</td>\n",
       "      <td>-0.032577</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>-0.037384</td>\n",
       "      <td>-0.004011</td>\n",
       "      <td>-0.026110</td>\n",
       "      <td>0.073530</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.209861</td>\n",
       "      <td>-0.042385</td>\n",
       "      <td>0.132223</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>0.083292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.492691</td>\n",
       "      <td>-0.269698</td>\n",
       "      <td>-0.191459</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>-0.416592</td>\n",
       "      <td>-0.057925</td>\n",
       "      <td>-0.131405</td>\n",
       "      <td>0.348033</td>\n",
       "      <td>0.118454</td>\n",
       "      <td>-0.135028</td>\n",
       "      <td>-0.084081</td>\n",
       "      <td>0.308521</td>\n",
       "      <td>-0.051496</td>\n",
       "      <td>-0.057788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0   x_dot_0   y_dot_0  phi_dot_0  theta_dot_0      x_99  \\\n",
       "0 -0.479611  0.002266 -0.491811 -0.220474   0.168732     0.450440 -0.318639   \n",
       "1 -0.453551  0.264615  0.469097  0.195148   0.353807    -0.446865  0.295886   \n",
       "2 -0.102133 -0.139825  0.486725  0.399421   0.036643    -0.265189  0.314624   \n",
       "3 -0.025410  0.473391 -0.032577 -0.026313  -0.037384    -0.004011 -0.026110   \n",
       "4  0.492691 -0.269698 -0.191459  0.408163  -0.416592    -0.057925 -0.131405   \n",
       "\n",
       "       y_99    phi_99  theta_99  x_dot_99  y_dot_99  phi_dot_99  theta_dot_99  \n",
       "0 -0.229442 -0.094704  0.071486 -0.202153 -0.214663    0.088688      0.089438  \n",
       "1  0.197180 -0.188053  0.054898  0.205139  0.206023   -0.053019     -0.052671  \n",
       "2  0.345313 -0.234415 -0.252743  0.349240  0.295930   -0.282329     -0.290446  \n",
       "3  0.073530  0.050494  0.209861 -0.042385  0.132223    0.092369      0.083292  \n",
       "4  0.348033  0.118454 -0.135028 -0.084081  0.308521   -0.051496     -0.057788  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)\n",
    "\n",
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX_veloc.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY_veloc.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerX_veloc.pkl\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(dataOutput, scalerfileX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune\n",
    "\n",
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0, \n",
    "                    dropout_rate=0):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0__Num_512_512_512_16__Wei_0_2019_06_13__02_19_18veloc\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               7680      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 541,251\n",
      "Trainable params: 541,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [512, 512, 512, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).\\\n",
    "                            replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2] + \"_\" + datetime.now().strftime(\"%Y_%m_%d__%I_%M_%S\") + \"veloc\"\n",
    "print(modelName)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)\n",
    "\n",
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/2000\n",
      " - 8s - loss: 7.6829e-04 - mean_squared_error: 7.6829e-04 - val_loss: 8.6280e-04 - val_mean_squared_error: 8.6280e-04\n",
      "Epoch 2/2000\n",
      " - 8s - loss: 7.7116e-04 - mean_squared_error: 7.7116e-04 - val_loss: 5.9228e-04 - val_mean_squared_error: 5.9228e-04\n",
      "Epoch 3/2000\n",
      " - 8s - loss: 7.6064e-04 - mean_squared_error: 7.6064e-04 - val_loss: 8.9195e-04 - val_mean_squared_error: 8.9195e-04\n",
      "Epoch 4/2000\n",
      " - 7s - loss: 7.6536e-04 - mean_squared_error: 7.6536e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 5/2000\n",
      " - 7s - loss: 7.6683e-04 - mean_squared_error: 7.6683e-04 - val_loss: 7.8071e-04 - val_mean_squared_error: 7.8071e-04\n",
      "Epoch 6/2000\n",
      " - 7s - loss: 7.6226e-04 - mean_squared_error: 7.6226e-04 - val_loss: 7.9583e-04 - val_mean_squared_error: 7.9583e-04\n",
      "Epoch 7/2000\n",
      " - 8s - loss: 7.6257e-04 - mean_squared_error: 7.6257e-04 - val_loss: 5.6070e-04 - val_mean_squared_error: 5.6070e-04\n",
      "Epoch 8/2000\n",
      " - 7s - loss: 7.5664e-04 - mean_squared_error: 7.5664e-04 - val_loss: 6.1491e-04 - val_mean_squared_error: 6.1491e-04\n",
      "Epoch 9/2000\n",
      " - 7s - loss: 7.5397e-04 - mean_squared_error: 7.5397e-04 - val_loss: 4.7308e-04 - val_mean_squared_error: 4.7308e-04\n",
      "Epoch 10/2000\n",
      " - 8s - loss: 7.5238e-04 - mean_squared_error: 7.5238e-04 - val_loss: 5.8263e-04 - val_mean_squared_error: 5.8263e-04\n",
      "Epoch 11/2000\n",
      " - 7s - loss: 7.5172e-04 - mean_squared_error: 7.5172e-04 - val_loss: 7.4056e-04 - val_mean_squared_error: 7.4056e-04\n",
      "Epoch 12/2000\n",
      " - 7s - loss: 7.5682e-04 - mean_squared_error: 7.5682e-04 - val_loss: 6.9386e-04 - val_mean_squared_error: 6.9386e-04\n",
      "Epoch 13/2000\n",
      " - 8s - loss: 7.5587e-04 - mean_squared_error: 7.5587e-04 - val_loss: 8.0640e-04 - val_mean_squared_error: 8.0640e-04\n",
      "Epoch 14/2000\n",
      " - 8s - loss: 7.5470e-04 - mean_squared_error: 7.5470e-04 - val_loss: 6.4110e-04 - val_mean_squared_error: 6.4110e-04\n",
      "Epoch 15/2000\n",
      " - 8s - loss: 7.6236e-04 - mean_squared_error: 7.6236e-04 - val_loss: 4.7525e-04 - val_mean_squared_error: 4.7525e-04\n",
      "Epoch 16/2000\n",
      " - 8s - loss: 7.4773e-04 - mean_squared_error: 7.4773e-04 - val_loss: 6.0221e-04 - val_mean_squared_error: 6.0221e-04\n",
      "Epoch 17/2000\n",
      " - 8s - loss: 7.4706e-04 - mean_squared_error: 7.4706e-04 - val_loss: 6.1828e-04 - val_mean_squared_error: 6.1828e-04\n",
      "Epoch 18/2000\n",
      " - 8s - loss: 7.4585e-04 - mean_squared_error: 7.4585e-04 - val_loss: 5.9460e-04 - val_mean_squared_error: 5.9460e-04\n",
      "Epoch 19/2000\n",
      " - 8s - loss: 7.5118e-04 - mean_squared_error: 7.5118e-04 - val_loss: 9.8077e-04 - val_mean_squared_error: 9.8077e-04\n",
      "Epoch 20/2000\n",
      " - 7s - loss: 7.4817e-04 - mean_squared_error: 7.4817e-04 - val_loss: 9.4193e-04 - val_mean_squared_error: 9.4193e-04\n",
      "Epoch 21/2000\n",
      " - 7s - loss: 7.4637e-04 - mean_squared_error: 7.4637e-04 - val_loss: 7.6379e-04 - val_mean_squared_error: 7.6379e-04\n",
      "Epoch 22/2000\n",
      " - 7s - loss: 7.4452e-04 - mean_squared_error: 7.4452e-04 - val_loss: 6.7671e-04 - val_mean_squared_error: 6.7671e-04\n",
      "Epoch 23/2000\n",
      " - 7s - loss: 7.4303e-04 - mean_squared_error: 7.4303e-04 - val_loss: 6.4582e-04 - val_mean_squared_error: 6.4582e-04\n",
      "Epoch 24/2000\n",
      " - 7s - loss: 7.3858e-04 - mean_squared_error: 7.3858e-04 - val_loss: 7.1233e-04 - val_mean_squared_error: 7.1233e-04\n",
      "Epoch 25/2000\n",
      " - 7s - loss: 7.4563e-04 - mean_squared_error: 7.4563e-04 - val_loss: 6.1155e-04 - val_mean_squared_error: 6.1155e-04\n",
      "Epoch 26/2000\n",
      " - 7s - loss: 7.4346e-04 - mean_squared_error: 7.4346e-04 - val_loss: 9.0171e-04 - val_mean_squared_error: 9.0171e-04\n",
      "Epoch 27/2000\n",
      " - 7s - loss: 7.3588e-04 - mean_squared_error: 7.3588e-04 - val_loss: 6.2988e-04 - val_mean_squared_error: 6.2988e-04\n",
      "Epoch 28/2000\n",
      " - 7s - loss: 7.4136e-04 - mean_squared_error: 7.4136e-04 - val_loss: 7.4450e-04 - val_mean_squared_error: 7.4450e-04\n",
      "Epoch 29/2000\n",
      " - 7s - loss: 7.3480e-04 - mean_squared_error: 7.3480e-04 - val_loss: 7.0212e-04 - val_mean_squared_error: 7.0212e-04\n",
      "Epoch 30/2000\n",
      " - 7s - loss: 7.4270e-04 - mean_squared_error: 7.4270e-04 - val_loss: 5.6565e-04 - val_mean_squared_error: 5.6565e-04\n",
      "Epoch 31/2000\n",
      " - 7s - loss: 7.3393e-04 - mean_squared_error: 7.3393e-04 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 32/2000\n",
      " - 7s - loss: 7.2726e-04 - mean_squared_error: 7.2726e-04 - val_loss: 6.9897e-04 - val_mean_squared_error: 6.9897e-04\n",
      "Epoch 33/2000\n",
      " - 8s - loss: 7.3410e-04 - mean_squared_error: 7.3410e-04 - val_loss: 8.5823e-04 - val_mean_squared_error: 8.5823e-04\n",
      "Epoch 34/2000\n",
      " - 8s - loss: 7.3085e-04 - mean_squared_error: 7.3085e-04 - val_loss: 9.6142e-04 - val_mean_squared_error: 9.6142e-04\n",
      "Epoch 35/2000\n",
      " - 8s - loss: 7.3382e-04 - mean_squared_error: 7.3382e-04 - val_loss: 6.9654e-04 - val_mean_squared_error: 6.9654e-04\n",
      "Epoch 36/2000\n",
      " - 7s - loss: 7.3085e-04 - mean_squared_error: 7.3085e-04 - val_loss: 8.3355e-04 - val_mean_squared_error: 8.3355e-04\n",
      "Epoch 37/2000\n",
      " - 7s - loss: 7.3082e-04 - mean_squared_error: 7.3082e-04 - val_loss: 5.2568e-04 - val_mean_squared_error: 5.2568e-04\n",
      "Epoch 38/2000\n",
      " - 7s - loss: 7.3009e-04 - mean_squared_error: 7.3009e-04 - val_loss: 8.2680e-04 - val_mean_squared_error: 8.2680e-04\n",
      "Epoch 39/2000\n",
      " - 7s - loss: 7.2358e-04 - mean_squared_error: 7.2358e-04 - val_loss: 7.7740e-04 - val_mean_squared_error: 7.7740e-04\n",
      "Epoch 40/2000\n",
      " - 7s - loss: 7.3410e-04 - mean_squared_error: 7.3410e-04 - val_loss: 7.7792e-04 - val_mean_squared_error: 7.7792e-04\n",
      "Epoch 41/2000\n",
      " - 7s - loss: 7.2473e-04 - mean_squared_error: 7.2473e-04 - val_loss: 5.4489e-04 - val_mean_squared_error: 5.4489e-04\n",
      "Epoch 42/2000\n",
      " - 8s - loss: 7.2267e-04 - mean_squared_error: 7.2267e-04 - val_loss: 6.4759e-04 - val_mean_squared_error: 6.4759e-04\n",
      "Epoch 43/2000\n",
      " - 8s - loss: 7.2319e-04 - mean_squared_error: 7.2319e-04 - val_loss: 8.2618e-04 - val_mean_squared_error: 8.2618e-04\n",
      "Epoch 44/2000\n",
      " - 7s - loss: 7.2687e-04 - mean_squared_error: 7.2687e-04 - val_loss: 4.3304e-04 - val_mean_squared_error: 4.3304e-04\n",
      "Epoch 45/2000\n",
      " - 7s - loss: 7.2736e-04 - mean_squared_error: 7.2736e-04 - val_loss: 9.1449e-04 - val_mean_squared_error: 9.1449e-04\n",
      "Epoch 46/2000\n",
      " - 7s - loss: 7.1563e-04 - mean_squared_error: 7.1563e-04 - val_loss: 8.0876e-04 - val_mean_squared_error: 8.0876e-04\n",
      "Epoch 47/2000\n",
      " - 8s - loss: 7.2066e-04 - mean_squared_error: 7.2066e-04 - val_loss: 6.6177e-04 - val_mean_squared_error: 6.6177e-04\n",
      "Epoch 48/2000\n",
      " - 7s - loss: 7.1129e-04 - mean_squared_error: 7.1129e-04 - val_loss: 8.2304e-04 - val_mean_squared_error: 8.2304e-04\n",
      "Epoch 49/2000\n",
      " - 7s - loss: 7.1731e-04 - mean_squared_error: 7.1731e-04 - val_loss: 6.6035e-04 - val_mean_squared_error: 6.6035e-04\n",
      "Epoch 50/2000\n"
     ]
    }
   ],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 2000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks=[earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and history\n",
    "model.save(os.path.join(savedModels,  modelName + '.h5'))\n",
    "pickle.dump(historyDict, open(os.path.join(dataOutput, modelName + \"history.pkl\"), \"wb\"))\n",
    "print(os.path.join(savedModels,  modelName + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "# summarize history for accuracy\n",
    "axs.plot(historyDict[\"val_mean_squared_error\"], label = \"val\", color = \"C1\")\n",
    "axs.plot(historyDict[\"mean_squared_error\"], label = \"train\", color = \"C0\")\n",
    "\n",
    "axs.set_title('Model MSE = '+ str((historyDict['val_mean_squared_error'][-1]))[:8])\n",
    "axs.set_ylabel('Mean squared error')\n",
    "axs.set_xlabel('Epoch')\n",
    "axs.legend( loc='best')\n",
    "plt.yscale('log') #logarithmic scale for y axis\n",
    "fig.savefig(os.path.join(figDir, modelName + '_training.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# modelPath = os.path.join(savedModels, \"Opt_rmsprop__Dro_0__Num_512_512_512_16__Wei_0_2019_06_11__11_27_06_fullActuated.h5\")\n",
    "\n",
    "# model = load_model(modelPath)\n",
    "\n",
    "# # load scalers\n",
    "# scalerX = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput_twoTorque\\scalerX_fullact.pkl\", \"rb\"))\n",
    "# scalerY = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput_twoTorque\\scalerY_fullact.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a smaller dataset\n",
    "Xtest_scaled = Xtest_scaled[:1000,:]\n",
    "Ytest_scaled = Ytest_scaled[:1000,:]\n",
    "\n",
    "\n",
    "# predict\n",
    "Ytest_pred = model.predict(Xtest_scaled)\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = Xtrain.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Ytrain.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Ytrain.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import ticker\n",
    "\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,df_c.shape[1] //2, figsize=np.array([25, 9]), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel(\"C\")\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "# Plot y = actual, x = predicted\n",
    "for ii in np.arange(0, df_c.shape[1] //2):\n",
    "    axs[ii].hexbin(y = df_c.loc[:,YtestDF.columns[ii]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[ii]], \n",
    "                   gridsize = 50, cmap = cmap)\n",
    "    axs[ii].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[ii].yaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "\n",
    "    if(ii == 0):\n",
    "        axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "    else:\n",
    "        axs[ii].set_ylabel(ylabs[ii])\n",
    "\n",
    "    axs[ii].set_title(YtestDF.columns[ii])\n",
    "    axs[ii].plot(df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "\n",
    "    # annotate with R^2\n",
    "    axs[ii].text(np.max(df_c.loc[:,YtestDF.columns[ii]])*-0.2, \n",
    "                 np.min(df_c.loc[:,YtestDF.columns[ii]])*0.9, \n",
    "                 r'$r^2$ =' + \n",
    "                 str(np.round((r2_score(df_c.loc[:,YtestDF.columns[ii]],  \n",
    "                                        df_c.loc[:,YpredDF.columns[ii]])), 3)))\n",
    "    axs[ii].set_xlim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "# jj is column in dataset, plotNum is plot position\n",
    "for jj, plotNum in enumerate(np.arange(df_c.shape[1]//2, df_c.shape[1])):\n",
    "\n",
    "    axs[plotNum].hexbin(y = (df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]]),\n",
    "                   x = df_c.loc[:,YpredDF.columns[jj]], \n",
    "                   gridsize = 50, cmap = cmap) \n",
    "    axs[plotNum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotNum].yaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "    axs[plotNum].set_xlabel(\"Predicted Value\\n\" + ylabs[jj])\n",
    "\n",
    "    if(jj == 0):\n",
    "        axs[plotNum].set_ylabel(\"(Actual - Predicted)\\n\" + ylabs[jj])\n",
    "    else:\n",
    "        axs[plotNum].set_ylabel(ylabs[jj])\n",
    "\n",
    "    axs[plotNum].hlines(y = 0, xmin = np.min( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   xmax = np.max( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   linestyle =  \"--\", linewidth = 1)\n",
    "    axs[plotNum].set_ylim([-np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]]- df_c.loc[:,YpredDF.columns[jj]]))])\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: look at percent residuals so that the scale isn't misleading\n",
    "# refref: convert angles to pairs of values: https://stats.stackexchange.com/questions/218407/encoding-angle-data-for-neural-network\n",
    "\n",
    "# refref:  Make video of hovering, with only the network input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 10.5* np.pi \n",
    "anglePair = (np.sin(theta), np.cos(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arctan2(anglePair[0], anglePair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mod(-2*np.pi, 2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    '''\n",
    "    rho: radius\n",
    "    phi: angle (in radians)\n",
    "    '''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "# plot moth at certain timesteps\n",
    "# plot final positions\n",
    "def plotMoth(x,y,theta, phi, F, alpha, fig, ax):\n",
    "    \n",
    "    thoraxLen = 0.908 * 2# cm\n",
    "    abLen = 1.747 *2 #cm\n",
    "    bodyWidth = 1.1\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    center = np.array([x, y])\n",
    "    head = center + np.array(pol2cart(thoraxLen, theta))\n",
    "    abTip = center + np.array(pol2cart(abLen, phi))\n",
    "    xx, yy = zip(*[center, head])\n",
    "    xab,yab = zip(*[center, abTip])\n",
    "    el = Ellipse(midpoint(center, head), width = thoraxLen, height = bodyWidth, facecolor='#907760', alpha=0.9, angle = math.degrees(theta))\n",
    "    el2 = Ellipse(midpoint(center, abTip), width = abLen, height = bodyWidth, facecolor='#DEC9B0', alpha=0.9, angle = math.degrees(phi))\n",
    "    ax.add_artist(el)\n",
    "    ax.add_artist(el2)\n",
    "    ax.plot(xx, yy, 'k', alpha = 0.2)\n",
    "    ax.plot(xab,yab, 'k', alpha = 0.2)\n",
    "    # plot force \n",
    "    forceAlpha = alpha\n",
    "    forceCenter = midpoint(center, head)\n",
    "    forceMagnitude = F / 15000 # scale \n",
    "    forceAngle = theta + forceAlpha\n",
    "    forceTip = np.add(pol2cart(forceMagnitude, forceAngle), forceCenter)\n",
    "    ax.arrow(x = forceCenter[0], y = forceCenter[1], \n",
    "             dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "            head_width = 0.2, color = \"#B61212\")\n",
    "\n",
    "# plt.figure(figsize = [10,10])\n",
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "maxFrms = len(x)\n",
    "\n",
    "xlim = [np.min(x[0:maxFrms+1])-5, np.max(x[0:maxFrms+1])+5]\n",
    "ylim =[np.min(y[0:maxFrms+1])-5, np.max(y[0:maxFrms+1])+5]\n",
    "xrng = np.diff(xlim)\n",
    "yrng = np.diff(ylim)\n",
    "maxrng = np.max([xrng, yrng])\n",
    "newxlim = [np.sum(xlim)/2 - maxrng /2, np.sum(xlim)/2 + maxrng /2]\n",
    "newylim = [np.sum(ylim)/2 - maxrng /2, np.sum(ylim)/2 + maxrng /2 ]\n",
    "\n",
    "\n",
    "for ii in np.arange(1, maxFrms, 1):\n",
    "    fig, ax = plt.subplots( figsize = [10,10])\n",
    "\n",
    "    plt.plot(x[0:ii+1], y[0:ii+1], c= 'orange', label = \"Python\")\n",
    "    plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "    \n",
    "\n",
    "    ax.set_ylim(newylim)\n",
    "    ax.set_xlim(newxlim)\n",
    "    ax.set_ylabel(\"vertical position (cm)\")\n",
    "    ax.set_xlabel(\"horizontal position (cm)\")\n",
    "    \n",
    "#     # add torque\n",
    "#     if tau0 < 0:\n",
    "#         marker = r'$\\circlearrowleft$'\n",
    "#     else:\n",
    "#         marker = r'$\\circlearrowright$'\n",
    "#     ax.plot(x[ii],y[ii], marker=marker,ms=tau0/100000,  color = \"#B61212\")\n",
    "    fig.savefig(os.path.join(tmpDir2, str(ii).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "    # plt.legend()\n",
    "    plt.close()\n",
    "    if np.mod(ii, 10) == 0:\n",
    "        print(ii)\n",
    "#     plt.show()\n",
    "\n",
    "# ask network to predict \"hovering\", then compare to ODE\n",
    "from collections import OrderedDict\n",
    "\n",
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 2,\n",
    "            \"nrun\" : 100000  # (max) number of  trajectories.\n",
    "            })\n",
    "\n",
    "\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "\n",
    "# ranges for variables\n",
    "rangeDict = {\"Fmin\": 0,\n",
    "             \"Fmax\": 44300,\n",
    "            \"alphaMin\":  0,\n",
    "             \"alphaMax\":2*np.pi, \n",
    "            \"tau0Min\": -100000, \n",
    "             \"tau0Max\": 100000}\n",
    "\n",
    "# # ranges for variables\n",
    "# rangeDict = {\"Fmin\": 0,\n",
    "#              \"Fmax\": 443,\n",
    "#             \"alphaMin\":  0,\n",
    "#              \"alphaMax\":2*np.pi, \n",
    "#             \"tau0Min\": -1000, \n",
    "#              \"tau0Max\": 1000}\n",
    "\n",
    "\n",
    "# ranges for F, alpha, tau\n",
    "ranges = np.array([[rangeDict[\"Fmin\"], rangeDict[\"Fmax\"]], \n",
    "                   [rangeDict[\"alphaMin\"], rangeDict[\"alphaMax\"]], \n",
    "                   [rangeDict[\"tau0Min\"], rangeDict[\"tau0Max\"] ]])\n",
    "\n",
    "\n",
    "\n",
    "# generate initial conditions for state 0\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/4, 0.0001, 5*np.pi  / 4, 0.0001]\n",
    "\n",
    "# vertical bug version\n",
    "#state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/2, 0.0001, 3*np.pi/2, 0.0001]\n",
    "\n",
    "# F, alpha, tau\n",
    "FAlphaTau_list = np.random.uniform(ranges[:, 0], ranges[:, 1], \n",
    "                                   size=(globalDict[\"nrun\"], ranges.shape[0]))\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]\n",
    "\n",
    "# start loop\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "overallCtr = 1\n",
    "\n",
    "XYStart = [0,0]\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "newtorkInput = OrderedDict({\n",
    "                        'phi_0':[np.pi/2], \n",
    "                        'theta_0':[3*np.pi/2], \n",
    "                        'x_dot_0':[0.0001], \n",
    "                        'y_dot_0':[0.0001], \n",
    "                        'phi_dot_0':[0.0001], \n",
    "                        'theta_dot_0':[0.0001], \n",
    "                        'x_99':[0], \n",
    "                        'y_99':[0], \n",
    "                        'theta_99':[0.0001], \n",
    "                        'x_dot_99':[0.0001], \n",
    "                        'y_dot_99':[0.0001], \n",
    "                        'phi_dot_99':[0.0001], \n",
    "                        'theta_dot_99':[0.0001]})\n",
    "\n",
    "\n",
    "xList = []\n",
    "yList = []\n",
    "\n",
    "prevXY = XYStart\n",
    "\n",
    "goalXY = [newtorkInput[\"x_99\"][0], newtorkInput[\"y_99\"][0]]\n",
    "\n",
    "X.columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
