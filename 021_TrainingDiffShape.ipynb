{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 6 June 2019\n",
    "___\n",
    "### - Train Dense, Feedforward Neural Network with Keras\n",
    "### - Use data that was generated in Python\n",
    "### - Put velocity in the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-07-08 13:00:55.327520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs_train.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38700510, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>xf</th>\n",
       "      <th>xd0</th>\n",
       "      <th>xdf</th>\n",
       "      <th>y0</th>\n",
       "      <th>yf</th>\n",
       "      <th>yd0</th>\n",
       "      <th>ydf</th>\n",
       "      <th>theta0</th>\n",
       "      <th>thetaf</th>\n",
       "      <th>thetad0</th>\n",
       "      <th>thetadf</th>\n",
       "      <th>phi0</th>\n",
       "      <th>phif</th>\n",
       "      <th>phid0</th>\n",
       "      <th>phidf</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tau0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.367432</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.222497</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>6.334514</td>\n",
       "      <td>5.761704</td>\n",
       "      <td>166.050842</td>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.628560</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>29718.210402</td>\n",
       "      <td>3.057406</td>\n",
       "      <td>53852.149654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.768748</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.106142</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>4.921125</td>\n",
       "      <td>16.957561</td>\n",
       "      <td>146.364185</td>\n",
       "      <td>3.308109</td>\n",
       "      <td>4.891662</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>28169.483755</td>\n",
       "      <td>3.504285</td>\n",
       "      <td>66579.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.280989</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.318522</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-0.270820</td>\n",
       "      <td>7.760703</td>\n",
       "      <td>-563.122968</td>\n",
       "      <td>5.548527</td>\n",
       "      <td>-0.137526</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>42042.954099</td>\n",
       "      <td>1.460073</td>\n",
       "      <td>-13638.356558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.931729</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748787</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>4.826500</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>72.504068</td>\n",
       "      <td>0.510978</td>\n",
       "      <td>1.423037</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>32817.596791</td>\n",
       "      <td>1.943183</td>\n",
       "      <td>-59677.690610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.280447</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.707153</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>4.399997</td>\n",
       "      <td>-16.195650</td>\n",
       "      <td>-177.812751</td>\n",
       "      <td>1.609007</td>\n",
       "      <td>-0.231868</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>35120.738164</td>\n",
       "      <td>3.267484</td>\n",
       "      <td>77836.665059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0         xf          xd0          xdf   y0         yf         yd0  \\\n",
       "0  0.0  23.367432  1240.975696  1047.460389  0.0  -2.222497 -321.289498   \n",
       "1  0.0 -20.768748 -1149.257088 -1075.409015  0.0  11.106142  365.093207   \n",
       "2  0.0 -25.280989 -1496.313673 -1133.713595  0.0   4.318522  244.869357   \n",
       "3  0.0  -5.931729  -560.948725   -26.956023  0.0   0.748787   86.858301   \n",
       "4  0.0  -9.280447  -214.455052  -539.671502  0.0   6.707153  225.808462   \n",
       "\n",
       "          ydf    theta0    thetaf    thetad0     thetadf      phi0      phif  \\\n",
       "0  -38.377027  4.539917  6.334514   5.761704  166.050842  2.909070  4.628560   \n",
       "1  697.828947  3.243816  4.921125  16.957561  146.364185  3.308109  4.891662   \n",
       "2  748.985152  5.436117 -0.270820   7.760703 -563.122968  5.548527 -0.137526   \n",
       "3   45.961219  4.004344  4.826500  -0.067853   72.504068  0.510978  1.423037   \n",
       "4  488.013492  6.129205  4.399997 -16.195650 -177.812751  1.609007 -0.231868   \n",
       "\n",
       "       phid0       phidf             F     alpha          tau0  \n",
       "0  10.607821  162.092739  29718.210402  3.057406  53852.149654  \n",
       "1  22.615302  141.667777  28169.483755  3.504285  66579.923810  \n",
       "2   0.328348 -561.725041  42042.954099  1.460073 -13638.356558  \n",
       "3  24.197259   77.007517  32817.596791  1.943183 -59677.690610  \n",
       "4   9.118306 -183.140660  35120.738164  3.267484  77836.665059  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>5.761704</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>166.050842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.308109</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>16.957561</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>146.364185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.548527</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>7.760703</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>-563.122968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510978</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>72.504068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.609007</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-16.195650</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>-177.812751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_dot_0     y_dot_0  phi_dot_0  theta_dot_0  \\\n",
       "0  2.909070  4.539917  1240.975696 -321.289498  10.607821     5.761704   \n",
       "1  3.308109  3.243816 -1149.257088  365.093207  22.615302    16.957561   \n",
       "2  5.548527  5.436117 -1496.313673  244.869357   0.328348     7.760703   \n",
       "3  0.510978  4.004344  -560.948725   86.858301  24.197259    -0.067853   \n",
       "4  1.609007  6.129205  -214.455052  225.808462   9.118306   -16.195650   \n",
       "\n",
       "      x_dot_99    y_dot_99  phi_dot_99  theta_dot_99  \n",
       "0  1047.460389  -38.377027  162.092739    166.050842  \n",
       "1 -1075.409015  697.828947  141.667777    146.364185  \n",
       "2 -1133.713595  748.985152 -561.725041   -563.122968  \n",
       "3   -26.956023   45.961219   77.007517     72.504068  \n",
       "4  -539.671502  488.013492 -183.140660   -177.812751  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-29612.961122</td>\n",
       "      <td>2498.912376</td>\n",
       "      <td>53852.149654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26336.915345</td>\n",
       "      <td>-9994.333651</td>\n",
       "      <td>66579.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4645.636361</td>\n",
       "      <td>41785.500502</td>\n",
       "      <td>-13638.356558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11940.326951</td>\n",
       "      <td>30568.337400</td>\n",
       "      <td>-59677.690610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34842.795622</td>\n",
       "      <td>-4409.744037</td>\n",
       "      <td>77836.665059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fx            Fy           tau\n",
       "0 -29612.961122   2498.912376  53852.149654\n",
       "1 -26336.915345  -9994.333651  66579.923810\n",
       "2   4645.636361  41785.500502 -13638.356558\n",
       "3 -11940.326951  30568.337400 -59677.690610\n",
       "4 -34842.795622  -4409.744037  77836.665059"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310819</td>\n",
       "      <td>0.214366</td>\n",
       "      <td>0.479627</td>\n",
       "      <td>0.281509</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.150846</td>\n",
       "      <td>0.302151</td>\n",
       "      <td>0.188054</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.195384</td>\n",
       "      <td>0.317206</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>0.248502</td>\n",
       "      <td>0.377849</td>\n",
       "      <td>0.105073</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.077842</td>\n",
       "      <td>0.078554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.339415</td>\n",
       "      <td>-0.318740</td>\n",
       "      <td>-0.118281</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.216763</td>\n",
       "      <td>-0.414218</td>\n",
       "      <td>-0.109738</td>\n",
       "      <td>0.097694</td>\n",
       "      <td>0.013862</td>\n",
       "      <td>0.011735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.338143</td>\n",
       "      <td>0.100848</td>\n",
       "      <td>0.480690</td>\n",
       "      <td>-0.085019</td>\n",
       "      <td>-0.279146</td>\n",
       "      <td>0.114572</td>\n",
       "      <td>0.363485</td>\n",
       "      <td>0.071363</td>\n",
       "      <td>-0.066551</td>\n",
       "      <td>-0.068830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.390174</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>0.481083</td>\n",
       "      <td>0.460551</td>\n",
       "      <td>0.152466</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.217566</td>\n",
       "      <td>0.260808</td>\n",
       "      <td>0.079463</td>\n",
       "      <td>0.076643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0   x_dot_0   y_dot_0  phi_dot_0  theta_dot_0  x_dot_99  \\\n",
       "0  0.310819  0.214366  0.479627  0.281509   0.321928     0.150846  0.302151   \n",
       "1 -0.195384  0.317206 -0.224877  0.248502   0.377849     0.105073 -0.000893   \n",
       "2  0.339415 -0.318740 -0.118281  0.140292   0.216763    -0.414218 -0.109738   \n",
       "3  0.338143  0.100848  0.480690 -0.085019  -0.279146     0.114572  0.363485   \n",
       "4  0.390174  0.101926  0.481083  0.460551   0.152466     0.137482  0.217566   \n",
       "\n",
       "   y_dot_99  phi_dot_99  theta_dot_99  \n",
       "0  0.188054    0.021435      0.017773  \n",
       "1  0.157563    0.077842      0.078554  \n",
       "2  0.097694    0.013862      0.011735  \n",
       "3  0.071363   -0.066551     -0.068830  \n",
       "4  0.260808    0.079463      0.076643  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX_veloc.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY_veloc.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0.0__Num_512_512_512_16__Wei_0.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 539,203\n",
      "Trainable params: 539,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0.0, \n",
    "               \"numUnits\": [512, 512, 512, 16],\n",
    "               \"weightRegularization\": 0.0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)\n",
    "\n",
    "# note: previous best MSE is 7.1524e-04 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21672285 samples, validate on 9288123 samples\n",
      "Epoch 1/1000\n",
      " - 34s - loss: 4.7822e-04 - mean_squared_error: 4.7822e-04 - val_loss: 4.4826e-04 - val_mean_squared_error: 4.4826e-04\n",
      "Epoch 2/1000\n",
      " - 34s - loss: 4.7719e-04 - mean_squared_error: 4.7719e-04 - val_loss: 3.8320e-04 - val_mean_squared_error: 3.8320e-04\n",
      "Epoch 3/1000\n",
      " - 34s - loss: 4.7631e-04 - mean_squared_error: 4.7631e-04 - val_loss: 3.6636e-04 - val_mean_squared_error: 3.6636e-04\n",
      "Epoch 4/1000\n",
      " - 34s - loss: 4.7613e-04 - mean_squared_error: 4.7613e-04 - val_loss: 5.5294e-04 - val_mean_squared_error: 5.5294e-04\n",
      "Epoch 5/1000\n",
      " - 34s - loss: 4.7523e-04 - mean_squared_error: 4.7523e-04 - val_loss: 5.7313e-04 - val_mean_squared_error: 5.7313e-04\n",
      "Epoch 6/1000\n",
      " - 34s - loss: 4.7460e-04 - mean_squared_error: 4.7460e-04 - val_loss: 6.2492e-04 - val_mean_squared_error: 6.2492e-04\n",
      "Epoch 7/1000\n",
      " - 34s - loss: 4.7365e-04 - mean_squared_error: 4.7365e-04 - val_loss: 3.5165e-04 - val_mean_squared_error: 3.5165e-04\n",
      "Epoch 8/1000\n",
      " - 34s - loss: 4.7291e-04 - mean_squared_error: 4.7291e-04 - val_loss: 4.3549e-04 - val_mean_squared_error: 4.3549e-04\n",
      "Epoch 9/1000\n",
      " - 34s - loss: 4.7133e-04 - mean_squared_error: 4.7133e-04 - val_loss: 3.9235e-04 - val_mean_squared_error: 3.9235e-04\n",
      "Epoch 10/1000\n",
      " - 34s - loss: 4.7057e-04 - mean_squared_error: 4.7057e-04 - val_loss: 9.2922e-04 - val_mean_squared_error: 9.2922e-04\n",
      "Epoch 11/1000\n",
      " - 34s - loss: 4.7071e-04 - mean_squared_error: 4.7071e-04 - val_loss: 4.0503e-04 - val_mean_squared_error: 4.0503e-04\n",
      "Epoch 12/1000\n",
      " - 34s - loss: 4.6936e-04 - mean_squared_error: 4.6936e-04 - val_loss: 6.5949e-04 - val_mean_squared_error: 6.5949e-04\n",
      "Epoch 13/1000\n",
      " - 34s - loss: 4.6832e-04 - mean_squared_error: 4.6832e-04 - val_loss: 3.4191e-04 - val_mean_squared_error: 3.4191e-04\n",
      "Epoch 14/1000\n",
      " - 34s - loss: 4.6766e-04 - mean_squared_error: 4.6766e-04 - val_loss: 3.8227e-04 - val_mean_squared_error: 3.8227e-04\n",
      "Epoch 15/1000\n",
      " - 34s - loss: 4.6684e-04 - mean_squared_error: 4.6684e-04 - val_loss: 3.0985e-04 - val_mean_squared_error: 3.0985e-04\n",
      "Epoch 16/1000\n",
      " - 34s - loss: 4.6688e-04 - mean_squared_error: 4.6688e-04 - val_loss: 4.7604e-04 - val_mean_squared_error: 4.7604e-04\n",
      "Epoch 17/1000\n",
      " - 34s - loss: 4.6503e-04 - mean_squared_error: 4.6503e-04 - val_loss: 6.3252e-04 - val_mean_squared_error: 6.3252e-04\n",
      "Epoch 18/1000\n",
      " - 34s - loss: 4.6408e-04 - mean_squared_error: 4.6408e-04 - val_loss: 3.1095e-04 - val_mean_squared_error: 3.1095e-04\n",
      "Epoch 19/1000\n",
      " - 34s - loss: 4.6405e-04 - mean_squared_error: 4.6405e-04 - val_loss: 7.0650e-04 - val_mean_squared_error: 7.0650e-04\n",
      "Epoch 20/1000\n",
      " - 34s - loss: 4.6361e-04 - mean_squared_error: 4.6361e-04 - val_loss: 2.9473e-04 - val_mean_squared_error: 2.9473e-04\n",
      "Epoch 21/1000\n",
      " - 34s - loss: 4.6260e-04 - mean_squared_error: 4.6260e-04 - val_loss: 3.9122e-04 - val_mean_squared_error: 3.9122e-04\n",
      "Epoch 22/1000\n",
      " - 34s - loss: 4.6045e-04 - mean_squared_error: 4.6045e-04 - val_loss: 9.0871e-04 - val_mean_squared_error: 9.0871e-04\n",
      "Epoch 23/1000\n",
      " - 34s - loss: 4.6022e-04 - mean_squared_error: 4.6022e-04 - val_loss: 2.7075e-04 - val_mean_squared_error: 2.7075e-04\n",
      "Epoch 24/1000\n",
      " - 34s - loss: 4.6031e-04 - mean_squared_error: 4.6031e-04 - val_loss: 2.4337e-04 - val_mean_squared_error: 2.4337e-04\n",
      "Epoch 25/1000\n",
      " - 34s - loss: 4.5972e-04 - mean_squared_error: 4.5972e-04 - val_loss: 4.2128e-04 - val_mean_squared_error: 4.2128e-04\n",
      "Epoch 26/1000\n",
      " - 34s - loss: 4.5901e-04 - mean_squared_error: 4.5901e-04 - val_loss: 4.7116e-04 - val_mean_squared_error: 4.7116e-04\n",
      "Epoch 27/1000\n",
      " - 34s - loss: 4.5796e-04 - mean_squared_error: 4.5796e-04 - val_loss: 4.8915e-04 - val_mean_squared_error: 4.8915e-04\n",
      "Epoch 28/1000\n",
      " - 34s - loss: 4.5705e-04 - mean_squared_error: 4.5705e-04 - val_loss: 3.3103e-04 - val_mean_squared_error: 3.3103e-04\n",
      "Epoch 29/1000\n",
      " - 34s - loss: 4.5623e-04 - mean_squared_error: 4.5623e-04 - val_loss: 3.5415e-04 - val_mean_squared_error: 3.5415e-04\n",
      "Epoch 30/1000\n",
      " - 34s - loss: 4.5569e-04 - mean_squared_error: 4.5569e-04 - val_loss: 4.0337e-04 - val_mean_squared_error: 4.0337e-04\n",
      "Epoch 31/1000\n",
      " - 34s - loss: 4.5480e-04 - mean_squared_error: 4.5480e-04 - val_loss: 5.3408e-04 - val_mean_squared_error: 5.3408e-04\n",
      "Epoch 32/1000\n",
      " - 34s - loss: 4.5520e-04 - mean_squared_error: 4.5520e-04 - val_loss: 4.7784e-04 - val_mean_squared_error: 4.7784e-04\n",
      "Epoch 33/1000\n",
      " - 34s - loss: 4.5316e-04 - mean_squared_error: 4.5316e-04 - val_loss: 2.8856e-04 - val_mean_squared_error: 2.8856e-04\n",
      "Epoch 34/1000\n",
      " - 34s - loss: 4.5455e-04 - mean_squared_error: 4.5455e-04 - val_loss: 4.2747e-04 - val_mean_squared_error: 4.2747e-04\n",
      "Epoch 35/1000\n",
      " - 34s - loss: 4.5171e-04 - mean_squared_error: 4.5171e-04 - val_loss: 3.1111e-04 - val_mean_squared_error: 3.1111e-04\n",
      "Epoch 36/1000\n",
      " - 34s - loss: 4.5119e-04 - mean_squared_error: 4.5119e-04 - val_loss: 6.2583e-04 - val_mean_squared_error: 6.2583e-04\n",
      "Epoch 37/1000\n",
      " - 34s - loss: 4.5153e-04 - mean_squared_error: 4.5153e-04 - val_loss: 3.3154e-04 - val_mean_squared_error: 3.3154e-04\n",
      "Epoch 38/1000\n",
      " - 34s - loss: 4.5000e-04 - mean_squared_error: 4.5000e-04 - val_loss: 2.7906e-04 - val_mean_squared_error: 2.7906e-04\n",
      "Epoch 39/1000\n",
      " - 34s - loss: 4.4993e-04 - mean_squared_error: 4.4993e-04 - val_loss: 2.7557e-04 - val_mean_squared_error: 2.7557e-04\n",
      "Epoch 40/1000\n",
      " - 34s - loss: 4.4858e-04 - mean_squared_error: 4.4858e-04 - val_loss: 4.7013e-04 - val_mean_squared_error: 4.7013e-04\n",
      "Epoch 41/1000\n",
      " - 34s - loss: 4.4819e-04 - mean_squared_error: 4.4819e-04 - val_loss: 3.2652e-04 - val_mean_squared_error: 3.2652e-04\n",
      "Epoch 42/1000\n",
      " - 34s - loss: 4.4738e-04 - mean_squared_error: 4.4738e-04 - val_loss: 3.2136e-04 - val_mean_squared_error: 3.2136e-04\n",
      "Epoch 43/1000\n",
      " - 34s - loss: 4.4678e-04 - mean_squared_error: 4.4678e-04 - val_loss: 5.9300e-04 - val_mean_squared_error: 5.9300e-04\n",
      "Epoch 44/1000\n",
      " - 34s - loss: 4.4722e-04 - mean_squared_error: 4.4722e-04 - val_loss: 3.2849e-04 - val_mean_squared_error: 3.2849e-04\n",
      "Epoch 45/1000\n",
      " - 34s - loss: 4.4551e-04 - mean_squared_error: 4.4551e-04 - val_loss: 5.3889e-04 - val_mean_squared_error: 5.3889e-04\n",
      "Epoch 46/1000\n",
      " - 34s - loss: 4.4414e-04 - mean_squared_error: 4.4414e-04 - val_loss: 3.4445e-04 - val_mean_squared_error: 3.4445e-04\n",
      "Epoch 47/1000\n",
      " - 34s - loss: 4.4388e-04 - mean_squared_error: 4.4388e-04 - val_loss: 3.3187e-04 - val_mean_squared_error: 3.3187e-04\n",
      "Epoch 48/1000\n",
      " - 34s - loss: 4.4303e-04 - mean_squared_error: 4.4303e-04 - val_loss: 4.6253e-04 - val_mean_squared_error: 4.6253e-04\n",
      "Epoch 49/1000\n",
      " - 34s - loss: 4.4378e-04 - mean_squared_error: 4.4378e-04 - val_loss: 5.3183e-04 - val_mean_squared_error: 5.3183e-04\n",
      "Epoch 50/1000\n",
      " - 34s - loss: 4.4206e-04 - mean_squared_error: 4.4206e-04 - val_loss: 6.6108e-04 - val_mean_squared_error: 6.6108e-04\n",
      "Epoch 51/1000\n",
      " - 34s - loss: 4.4141e-04 - mean_squared_error: 4.4141e-04 - val_loss: 4.8663e-04 - val_mean_squared_error: 4.8663e-04\n",
      "Epoch 52/1000\n",
      " - 34s - loss: 4.4048e-04 - mean_squared_error: 4.4048e-04 - val_loss: 5.3817e-04 - val_mean_squared_error: 5.3817e-04\n",
      "Epoch 53/1000\n",
      " - 34s - loss: 4.3986e-04 - mean_squared_error: 4.3986e-04 - val_loss: 4.5024e-04 - val_mean_squared_error: 4.5024e-04\n",
      "Epoch 54/1000\n",
      " - 34s - loss: 4.3874e-04 - mean_squared_error: 4.3874e-04 - val_loss: 4.2073e-04 - val_mean_squared_error: 4.2073e-04\n",
      "Epoch 55/1000\n",
      " - 34s - loss: 4.3871e-04 - mean_squared_error: 4.3871e-04 - val_loss: 5.0521e-04 - val_mean_squared_error: 5.0521e-04\n",
      "Epoch 56/1000\n",
      " - 34s - loss: 4.3831e-04 - mean_squared_error: 4.3831e-04 - val_loss: 6.1676e-04 - val_mean_squared_error: 6.1676e-04\n",
      "Epoch 57/1000\n",
      " - 34s - loss: 4.3761e-04 - mean_squared_error: 4.3761e-04 - val_loss: 4.8171e-04 - val_mean_squared_error: 4.8171e-04\n",
      "Epoch 58/1000\n",
      " - 34s - loss: 4.3639e-04 - mean_squared_error: 4.3639e-04 - val_loss: 8.0263e-04 - val_mean_squared_error: 8.0263e-04\n",
      "Epoch 59/1000\n",
      " - 34s - loss: 4.3593e-04 - mean_squared_error: 4.3593e-04 - val_loss: 5.9016e-04 - val_mean_squared_error: 5.9016e-04\n",
      "Epoch 60/1000\n",
      " - 34s - loss: 4.3528e-04 - mean_squared_error: 4.3528e-04 - val_loss: 3.0737e-04 - val_mean_squared_error: 3.0737e-04\n",
      "Epoch 61/1000\n",
      " - 34s - loss: 4.3437e-04 - mean_squared_error: 4.3437e-04 - val_loss: 4.0062e-04 - val_mean_squared_error: 4.0062e-04\n",
      "Epoch 62/1000\n",
      " - 34s - loss: 4.3470e-04 - mean_squared_error: 4.3470e-04 - val_loss: 3.1744e-04 - val_mean_squared_error: 3.1744e-04\n",
      "Epoch 63/1000\n",
      " - 34s - loss: 4.3358e-04 - mean_squared_error: 4.3358e-04 - val_loss: 2.2581e-04 - val_mean_squared_error: 2.2581e-04\n",
      "Epoch 64/1000\n",
      " - 34s - loss: 4.3272e-04 - mean_squared_error: 4.3272e-04 - val_loss: 5.1274e-04 - val_mean_squared_error: 5.1274e-04\n",
      "Epoch 65/1000\n",
      " - 34s - loss: 4.3230e-04 - mean_squared_error: 4.3230e-04 - val_loss: 2.2711e-04 - val_mean_squared_error: 2.2711e-04\n",
      "Epoch 66/1000\n",
      " - 34s - loss: 4.3069e-04 - mean_squared_error: 4.3069e-04 - val_loss: 5.3363e-04 - val_mean_squared_error: 5.3363e-04\n",
      "Epoch 67/1000\n",
      " - 34s - loss: 4.3029e-04 - mean_squared_error: 4.3029e-04 - val_loss: 4.4234e-04 - val_mean_squared_error: 4.4234e-04\n",
      "Epoch 68/1000\n",
      " - 34s - loss: 4.3056e-04 - mean_squared_error: 4.3056e-04 - val_loss: 4.3846e-04 - val_mean_squared_error: 4.3846e-04\n",
      "Epoch 69/1000\n",
      " - 34s - loss: 4.2960e-04 - mean_squared_error: 4.2960e-04 - val_loss: 4.1779e-04 - val_mean_squared_error: 4.1779e-04\n",
      "Epoch 70/1000\n",
      " - 34s - loss: 4.2875e-04 - mean_squared_error: 4.2875e-04 - val_loss: 3.0352e-04 - val_mean_squared_error: 3.0352e-04\n",
      "Epoch 71/1000\n"
     ]
    }
   ],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**13, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(savedModels,  modelName + \"_velocity\" + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "# summarize history for accuracy\n",
    "axs.plot(historyDict[\"mean_squared_error\"])\n",
    "axs.plot(historyDict[\"val_mean_squared_error\"])\n",
    "axs.set_title('Model MSE = '+ str((historyDict['val_mean_squared_error'][-1]))[:8])\n",
    "axs.set_ylabel('Mean squared error')\n",
    "axs.set_xlabel('Epoch')\n",
    "axs.legend(['train', 'val'], loc='best')\n",
    "plt.yscale('log') #logarithmic scale for y axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: Can I overfit, if I turn off all regularization? With a small dataset -- YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: visualize poossible state space from certain starting spaces using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005126771729797057"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_loss'][-1]# MSE for final epoch testing\n",
    "# why are val MSE vs. loss different????  answer : I think loss incorporates regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005126771729797057"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_mean_squared_error'][-1] # it is the same when there is no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00047896809953662463"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]# MSE for final epoch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAFcCAYAAABMYFNOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd83WX5//HXldGMZjRt2rR0l7a0FEqh7CXLMisIyFSGAupXFBEHLgQFUfEnioKICggKiAJK2QKlpWwotKW7dO8kbbN37t8f9+fTnKRZJ8nJaZL38/E4jzM+6zqnp8mV617mnENEREREep6EeAcgIiIiIh2jRE5ERESkh1IiJyIiItJDKZETERER6aGUyImIiIj0UErkRERERHooJXIi0iFmNsbMnJkltWPfK8xsXnfEJSLSlyiRE+kDzGytmVWbWW6T1z8KkrEx8YmsUUI4v8nruUHMayNeO9bM3jSzIjPbYWZvmNlhwbYrzKzOzEqb3Pbp4nidmZVFnP8vrex7rZm9b2ZVZvZgk21Hmtn/gveRb2b/MrNhTfY5xMzmBtfZZmbXBa+PauZ9OjO7Idj+gybbKsysPvz3N7Nfm9lKMysxs2VmdlnENcN/j6bnv7CV93lycJ5yM5ttZqOb2Wdg8D6V0It0ISVyIn3HGuDi8ImZHQikxS+cPfQ3swMinl+CjxkAM8sCngF+DwwEhgO3AFURx7zlnMtoctscg1gPijj/Va3stxm4Fbi/mW05wH3AGGA0UAI8EG4Mkq4XgD8Bg4DxwEsAzrn1ke8ROBCoB54Itv+8yfZfAq855wqC05cBM4Fs4HLgd2Z2dJP4BjT5HP/Z3BsM4nwS+DH+3+V9oLl9fwksbf5jEpGOUiIn0nc8DFwW8fxy4KHIHcws28weCion68zsR2aWEGxLDCo5BWa2GjizmWP/amZbzGyTmd1qZolRxnd5xPPLmsQ3EcA596hzrs45V+Gce8k5tzCKa3Qr59yTzrn/AIXNbHveOfcv51yxc64c+ANwTMQu3wJedM79wzlX5Zwrcc61lAhdBsx1zq1tusHMDPgC8LeIa//EObfMOVfvnHsHeB04qoNv81xgcfBeKoGbgYPMbFJEDEcBBxCRqIpI11AiJ9J3vA1kmdnkIMG6EPh7k31+j6/SjAM+hU8Qrgy2XQ2cBRwMHAqc3+TYvwG1+MrRwcAMoLVqVVN/By4KEsbJQCbwTsT2FUCdmf3NzE43s5wozr0HM1toZrtauN3TxuFzzWyrmT3Zhc3SxwOLI54fCewImpK3m9ksMxvVwrGXEZGoNXEckEdQrWvKzNKAw5pcOxpTgAXhE+dcGfBJ8DrBd+1u4FpAa0KKdDElciJ9S1iV+zSwDNgUbohI7r4fVH/WAv8PX80BuAD4rXNug3NuB3B7xLF5wOnAN51zZc657cCdwEVRxLYRWA6cQjPVQudcMXAsPhn4M5BvZk8H1w4d2SQh+6SliznnpjrnBrRw+79W4vwUvjl0Er7p9Blrx4CP1pjZVOAm4DsRL4/Afw7XAaPwzcyPNnNsmKj9u4XTXw782zlX2sL2e/GJ2ItNXi9o8llObuH4DKCoyWtF+EQc4BvAO865D1o4XkQ6oVM/fESkx3kYmAuMpUmiBOQC/YB1Ea+tw/dFA9gH2NBkW2g0kAxs8S15gP9DMXL/9ngIuAI4Gl+hmhC5MWhavAIgaLr7O/BbGvr+ve2cOzbKa0bFOTc3eFgdDD4oBiYDizpyPjMbDzwPXOecez1iUwXwlHPuvWC/W/DJVbZzLjJxuhx4orlELai2fQ44u4Vr34Fv8jzROde0WpbrnKttsv8oYEn4POh/VwpkNTk2CygxP9DkG8D0Zt+8iHSaKnIifYhzbh2+snMGvoN6pAKgBp+UhUbRULXbAoxssi20AT/oIDeiqpXlnJsSZYhP4PverQ5ibe29LAMexCciUTOzxc2MzAxv90ZxKgdYm3s1H8No4GXgZ865h5tsXkjjpsjw8e5rRSRqLTWrngvsAF5r5tq34KuoM4JqZ5uaGWQBvkn2oIjz9gf2DV4/HBgGLDGzrcDvgMODZulo+k+KSAuUyIn0PV8CTgr6Mu3mnKsDHgduM7PMIMn4Fg396B4HvmFmI4L+aTdGHLsFP6Ly/5lZlpklmNm+ZvapaAILYjqJZvrWmdkkM7vBzEYEz0fiK3FvR3ONiGtNaWaEa3j7SnPHmNkUM5sW9OPLwDc9b6KF0ZhmlmRmqUAikGhmqWEzrJkNB14F7nbONZc4PgB8NrheMn5U6Dzn3K6IfT4L7AJmt/A2LwcealptM7Pv40cFf9o5t8dAjCg9BRxgZucF7/UmYGGQaD+Pb4aeFtxuAj4EpgXfNxHpJCVyIn2Mc+4T59z7LWz+On5qitXAPOARGqbO+DO+H9UCYD57VvQuwzfNLgF24vtsDSNKzrn3nXPN9W0rAY4A3jGzMnwC9zFwQ8Q+RzVTXTss2hhakYefWqMY/xmNAc5yztXA7vnbno/Y/0f4JtIbgc8Hj38UbLsKP6jkJ5Hxhgc6514FfgA8C2zHDyK5pEk8zSZqQSzD8Ulx0yZ0gJ/jK6orI679gyb77GryOX6ruQ/EOZcPnAfchv93P4Kgb2Qw2nZreMP3nasJHotIF7Bm/v+LiIiISA+gipyIiIhID6VETkRERKSHUiInIiIi0kMpkRMRERHpoZTIiYj0EWZ2r5n9uJ37Pmhmt8Y6JhHpHCVyIn2cmb1mZpUR00wsj9h2opktCpZoKjSzp4JpLcLtw83sv2a2w8w2mtlXIrZNDLblB9tfNLP9mlz7+mBy2CIzu9/MUiK2zQ6OLTazBWbW7OoE0n7Oua84537WFecyMxesSiEicaRETkQAro2YDDcy2VoCnOqcG4Bfomsl8MeI7X/HrxSRh1+R4edmdmKwbQDwNLBfsP1d4L/hgWZ2Kn5+tZPx87GNA26JOPd1wDDnXBZwDfB3M4t6Xrq9UWfXZhURCSmRE5EWOee2Oec2R7xUh5+YlmBlgxOA25xzNc65BfhJgL8YHPuuc+6vzrkdwYS5dwL7mdmg4FyXA391zi12zu0Efkawjmpw/MKItT4dfi3XyCXCdjOzm83scTN7yMxKguW3Do3YPjmoPO4Ktn0mYtuDZna3mT0bHPuOme3bwnX2aTJJbrmZuYjtXzSzpWa2M6hAjo7Y5szsa2a2Ep8QY2ZHm9l7QUXyPTM7uoXrXmlmsyKerzKzxyOebzCzacHjSWb2v6AKutzMLmjyXm+NeP5dM9tiZpvN7Kpmqmw5zX0uZhauN7sg+BwuNLNcM3sm+Ix3mNnrZqbfMSIxpv9kIgJwu5kVmNkbZnZC5AYzG2Vmu/CrEnwb+FW4qcl9+LiltU+PB7ZGLAk1Bb9KRGgBkBeR6BEkBpXAO/j1QltakQLgM8BjNFQC/xCcIxmYhV9CbAh+9Yp/NGnmvRhfDcwBVuFXKdiDc25zk7VGnwquiZmdg1+J4VxgMPA68GiTU5yDX/lgfzMbiF+14S5gEPAb4NnI9x9hDnCc+aXPhuGT2mOC644DMoCF5tc5/R9+RY4hwfu6x8z2WPPWzE7DL8F2Cj45b245tWY/F+fc8cH2g4LP4p/4FTY2Bu89L/gsNOO8SIwpkROR7+GbNYcD9wGzIitSwULpA4Bc/PJSy4LXS4A3gB+bX0P0EPxSTelNL2B+fdS78YlDKAO/ZFMofJwZce2zgudnAC865+pbeR/znHPPBWt4PkzDQu5HBtf6hXOuOlj66hl8khJ6Mqgg1gL/wK8L2ioz+x4wiaACCXwZuN05tzQ4z8+BaZFVuWD7DudcBb4peqVz7mHnXK1z7lH8Zzuz6bWcc6vxS5RNwydcLwKbzGxS8Pz14LM5C1jrnHsgOOd84Ang/GbewgXAA0FFtJzGzdod+Vxq8EuyjQ4qtK83t3SYiHQtJXIifZxz7h3nXEmwLubf8MnZGc3stwP4G/DfiD5elwJjgQ34vnP/wFdldjOzwfhq2D1BshIqBbIinoePS5pct8Y59zxwamSTaDMi1+8sB8IF6vcBNjRJAtfhE9eWjs0IYv9BRDPq7oXtzex0fB++c4KkDGA08LugaXEXsANfoYy8zoaIx/sEcURqGlekOfim7OODx6/hk7hPBc/DGI4IYwjiuBQY2sz59mkSz4Zm9mn2c2nBHfiq3UtmttrMbmxlXxHpIkrkRKQpR+Pm0khJ+Ca7LADn3Drn3FnOucHOuSPwTYTvhjubWQ4+iXvaOde0uXIxDVUzgsfbIppem7t2s33X2rAZGNmkv9YoYFNbBzrnfh7RlPoVgKBJ9m/ABc65ponQl51zAyJuac65NyNP2SSuyGpdW3GFidxxweM57JnIbQDmNIkhwzn31WbOtwUYEfG82f6H7RX8MXCDc24cvqr4LTM7uTPnFJG2KZET6cPMbICZnRo0jSaZ2aX4is+LwfZzzWy/oG/WYHw/rg+D6lw4iCDTzPqZ2eeBGcE+mFlWcJ43nHPNVWceAr5kZvsHCd+PgAeDYyeZ2elmlmZmycG5w0pUtN4ByoDvBuc6AZ9oPBbtiYL39F/gR865eU023wt8P+yPZmbZZva5Vk73HDDRzC4JPvsLgf3xzb7NmQOcCKQ55zbi++Cdhk+ePwz2eSY45xeC95psZoeZ2eRmzvc4cGXwb5gO3NTW+29iG75JHgAzO8vMxpuZAcX4gTF1UZ5TRKKkRE6kb0sGbgXygQL8QIBznHPhXHLDgRfwzZ2LgHrgsxHHnwqsBnYCXwFOc87lB9s+CxyGTxYiR3qOAnDOvYAfODEb36S4DvhJcKwBNwPbg9iuAy4M+nxFxTlXjR8IcXrwHu8BLnPOLYv2XMAh+OlUfhP5noLrPAX8EnjMzIqBj4NrthRXIb5P2w1AIfBd4CznXEEL+6/AN0e/Hjwvxn/2bwT9AsN+izOAi/AVv61BTCnNnO95/ECL2fgm0beCTVXt/CxuBv4WNOFeAEwAXg5ifAvflP5aO88lIh1k6osqIiJB1e5jICVi2hcR2cupIici0keZ2WeDZvEcfOVulpI4kZ5FiZyISN/1ZXzT9Sf4/mzNDYoQkb2YmlZFREREeihV5ERERER6KCVyIiIiIj1UUtu79Ey5ubluzJgx8Q5DREREpE0ffPBBgXNucLTH9dpEbsyYMbz/fmvra4uIiIjsHcys6ZJ97aKmVREREZEeSomciIiISA+lRE5ERESkh+q1feRERESkZ6ipqWHjxo1UVlbGO5SYS01NZcSIESQnJ3fJ+ZTIiYiISFxt3LiRzMxMxowZg5nFO5yYcc5RWFjIxo0bGTt2bJecU02rIiIiEleVlZUMGjSoVydxAGbGoEGDurTyqERORERE4q63J3Ghrn6fSuRERESkz9u1axf33HNP1MedccYZ7Nq1KwYRtY8SOREREenzWkrk6urqWj3uueeeY8CAAbEKq029LpEzs5lmdl9RUVFMr/PGqgKeWbg5ptcQERGR7nHjjTfyySefMG3aNA477DBOPPFELrnkEg488EAAzjnnHKZPn86UKVO47777dh83ZswYCgoKWLt2LZMnT+bqq69mypQpzJgxg4qKipjH3esSOefcLOfcNdnZ2TG9ziPvrufO/62I6TVERESke/ziF79g33335aOPPuKOO+7g3Xff5bbbbmPJkiUA3H///XzwwQe8//773HXXXRQWFu5xjpUrV/K1r32NxYsXM2DAAJ544omYx63pRzooNSmRypr6eIchIiLSq9wyazFLNhd36Tn33yeLn8ycEtUxhx9+eKMpQu666y6eeuopADZs2MDKlSsZNGhQo2PGjh3LtGnTAJg+fTpr167tXODtoESug1KTE6iqbb3dXERERHqm/v3773782muv8fLLL/PWW2+Rnp7OCSec0OwUIikpKbsfJyYmdkvTqhK5DkpNVkVORESkq0VbOesqmZmZlJSUNLutqKiInJwc0tPTWbZsGW+//XY3R9cyJXIdlJqcQGWNKnIiIiK9waBBgzjmmGM44IADSEtLIy8vb/e20047jXvvvZepU6ey3377ceSRR8Yx0saUyHVQalIitfWOmrp6khN73ZgRERGRPueRRx5p9vWUlBSef/75ZreF/eByc3P5+OOPd7/+7W9/u8vja44ykA5KTU4EUFVORERE4kaJXAelJvuPTv3kREREJF6UyHVQiipyIiIiEmdK5DoobFrVFCQiIiISL0rkOig1SU2rIiIiEl9K5DpIgx1EREQk3pTIdVBDIqeKnIiISF+TkZER7xAAJXId1jBqVRU5ERERiQ9NCNxBuytyGuwgIiLS433ve99j9OjR/N///R8AN998M2bG3Llz2blzJzU1Ndx6662cffbZcY60MVXkOig1SU2rIiIivcVFF13EP//5z93PH3/8ca688kqeeuop5s+fz+zZs7nhhhtwzsUxyj2pItdBaloVERGJgedvhK2LuvacQw+E03/R6i4HH3ww27dvZ/PmzeTn55OTk8OwYcO4/vrrmTt3LgkJCWzatIlt27YxdOjQro2vE5TIdZAmBBYREeldzj//fP7973+zdetWLrroIv7xj3+Qn5/PBx98QHJyMmPGjKGysjLeYTaiRK6DwopcVa2aVkVERLpMG5WzWLrooou4+uqrKSgoYM6cOTz++OMMGTKE5ORkZs+ezbp16+IWW0uUyHVQv8QEzFSRExER6S2mTJlCSUkJw4cPZ9iwYVx66aXMnDmTQw89lGnTpjFp0qR4h7gHJXIdZGakJiUqkRMREelFFi1q6J+Xm5vLW2+91ex+paWl3RVSq3rdqFUzm2lm9xUVFcX8WqnJCRq1KiIiInHT6xI559ws59w12dnZMb9WarIqciIiIhI/vS6R606pyYlUarCDiIiIxIkSuU5ISUpQRU5ERKQL7G0T7cZKV79PJXKdkNZPTasiIiKdlZqaSmFhYa9P5pxzFBYWkpqa2mXn1KjVTkhNSqRKgx1EREQ6ZcSIEWzcuJH8/Px4hxJzqampjBgxosvOp0SuE1KTEygsq453GCIiIj1acnIyY8eOjXcYPZKaVjtBo1ZFREQknpTIdYJP5NS0KiIiIvGhRK4T/ITAqsiJiIhIfCiR64QULdElIiIicaRErhM0IbCIiIjEkxK5TkhNTqC6tp76+t49742IiIjsnZTIdUJqciIAVarKiYiISBwokeuE1CT/8VWon5yIiIjEgRK5TggrchrwICIiIvGgRK4TlMiJiIhIPCmR64TUZP/xaVJgERERiQclcp2QElbkalWRExERke6nRK4TUpPUtCoiIiLxo0SuE8Km1So1rYqIiEgcKJHrBA12EBERkXhSItcJqeojJyIiInGkRK4TNGpVRERE4kmJXCdosIOIiIjEkxK5TmjoI6eKnIiIiHS/pHgH0GPNuo7U/BXAtarIiYiISFyoItdRtVVY0Ub6JSVosIOIiIjEhRK5jkrNhsoiUpMSNI+ciIiIxIUSuY5KyYKqYtKSTE2rIiIiEhdK5DoqNRtwDEyuViInIiIicaFErqNSswEYlFShUasiIiISF0rkOio1C4CBiZUa7CAiIiJxoUSuo4KKXE5ChZpWRUREJC56RCJnZueY2Z/N7L9mNiPe8QB+sAOQnVCuplURERGJi5gncmZ2v5ltN7OPm7x+mpktN7NVZnZja+dwzv3HOXc1cAVwYQzDbb+gIpdtqsiJiIhIfHTHyg4PAn8AHgpfMLNE4G7g08BG4D0zexpIBG5vcvwXnXPbg8c/Co6Lv9QBAGRZOVW1qsiJiIhI94t5Iuecm2tmY5q8fDiwyjm3GsDMHgPOds7dDpzV9BxmZsAvgOedc/NbupaZXQNcAzBq1Kguib9FwWCHTMpUkRMREZG4iFcfueHAhojnG4PXWvJ14BTgfDP7Sks7Oefuc84d6pw7dPDgwV0TaUsSkyE5nQxXrkRORERE4qI7mlabY8285lra2Tl3F3BX7MLpoJQs+lNGhRI5ERERiYN4VeQ2AiMjno8ANscplo5LzSYLP2q1tKo23tGIiIhIHxOvRO49YIKZjTWzfsBFwNNxiqXjUrPIpAyAbcWVcQ5GRERE+prumH7kUeAtYD8z22hmX3LO1QLXAi8CS4HHnXOLYx1Ll0vNJr0+SOSKlMiJiIhI9+qOUasXt/D6c8BzXX09M5sJzBw/fnxXn3pPqdn0q/0EgK2qyImIiEg36xErO0TDOTfLOXdNdnZ27C+WkkVyTSmgRE5ERES6X69L5LpVajZWVURmaiLbi6viHY2IiIj0MUrkOiM1C+qqGZmZwFb1kRMREZFupkSuM4L1Vsdm1KlpVURERLqdErnOSPGJ3Kj0GrYrkRMREZFu1usSOTObaWb3FRUVxf5iQUVun9RqtpdUUV/f4uIUIiIiIl2u1yVy3TpqNUjkhqVWUVvvKCjTgAcRERHpPr0uketWqVkADE72CZxGroqIiEh3UiLXGUFFbmCi7x+nkasiIiLSndqVyJlZopldH+tgepwUX5EbYOWAJgUWERGR7tWuRM45VwecHeNYep5+/cES6e/KSDDYpkROREREulE0a62+YWZ/AP4JlIUvOufmd3lUPYUZpGaRUF1MbkaKEjkRERHpVtEkckcH9z+NeM0BJ3VdOD1QajZUFjE0O5WtGuwgIiIi3ajdiZxz7sRYBtJVzGwmMHP8+PHdc8HUbKgsJi8rlfWF5d1zTRERERGiGLVqZtlm9hszez+4/T8z64bJ2qLTrfPIgR/wUFlEXlYK20rUtCoiIiLdJ5rpR+4HSoALglsx8EAsgupRUrOhqpihWansKq+hsqYu3hGJiIhIHxFNH7l9nXPnRTy/xcw+6uqAepygj9zwnDQANuwoZ0JeZpyDEhERkb4gmopchZkdGz4xs2OAiq4PqYdJzYaKXYzPzQBg1fbSOAckIiIifUU0FbmvAA9F9IvbCVze9SH1MDljoKaM8enFAKzcXsrp8Y1IRERE+oh2JXJmlgDs55w7yMyyAJxzxTGNrKcYOhWAtIIljMhJY6UqciIiItJN2ruyQz1wbfC4WElchKEHAAZbFzIxL5OV20riHZGIiIj0EdH0kfufmX3bzEaa2cDwFrPIOsjMZprZfUVFRd1zwZRMGDgOtixgwpAMVheUUVtX3z3XFhERkT4tmkTui8DXgLnAB8Ht/VgE1RndPo8cwLCpsHUh44dkUF1bz4adGgMiIiIisdeuRC7oI/d559zYJrdxMY6vZxg6FXatZ9IAX4lT86qIiIh0h2j6yP06xrH0XMP8gIfx9asBNOBBREREukU0Tasvmdl5ZmYxi6anGnoQAGkFi9knO1VzyYmIiEi3iGYeuW8B/YE6M6sADHDOuayYRNaTZAyGzGG+n1ze4azcrqZVERERib12V+Scc5nOuQTnXLJzLit4riQuNHQqbFnIhCEZrNpeSn29i3dEIiIi0su1O5Ez7/Nm9uPg+UgzOzx2ofUww6ZCwQomDUqksqaeTbs0clVERERiK5o+cvcARwGXBM9Lgbu7PKKeasyx4Oo4tOodABZv7qZ57ERERKTPiiaRO8I59zWgEsA5txPoF5OoeqIxx0PWCEZv+A/9EhOYv35XvCMSERGRXi6aRK7GzBIBB2Bmg4G9bgmDbl/ZIZSQANMuJmH1bI4fWs0H63ZC6XZw6isnIiIisRFNIncX8BQwxMxuA+YBP49JVJ0Ql5UdQgddDK6eS9LeYv/NT8CvJ8CyZ7s/DhEREekT2j39iHPuH2b2AXAyfuqRc5xzS8PtZpYTNLf2XYP2hVFHcdyWv3NSYjAFSf5SmHxWfOMSERGRXimaihzOuWXOubudc3+ITOICr3RhXD3XtEtJrinhpbrpVCYPgKKN8Y5IREREeqloJgRui1Z8AJh2KWQO47Z/17EfP2b0rg3xjkhERER6qagqcm1Qr37wgx4mnMKBowezuiYHipTIiYiISGx0ZSInEQ4ZlcOq6oG4XRs0clVERERioisTOTWtRjhkdA6bXC5WWwHlhfEOR0RERHqhNvvImdnA1rY753YED0/ukoh6iSn7ZHF/0hD/ZNd66J8b34BERESk12nPYIcP8P3fDBgF7AweDwDWA2OhUUInQHJiAoOGj4fN+H5yww+Jd0giIiLSy7TZtOqcG+ucGwe8CMx0zuU65wYBZwFPxjrAnmzifvsDsGPz6jhHIiIiIr1RNH3kDnPOPRc+cc49D3yq60PqPQ6fPI5Sl8q2DSvjHYqIiIj0QtEkcgVm9iMzG2Nmo83sh8Be14s/bmutNmPc4Ay2JwymqmBtvEMRERGRXiiaRO5iYDB+vdWngscXxyKozojrWqtNmBlV/YeTUraZunpNQSIiIiJdK5q1VncA15lZhnOuNIYx9Sppg0eTXfIxizYVMW3kgHiHIyIiIr1IuytyZna0mS0BlgTPDzKze2IWWS8xeMQEcqyUt5aui3coIiIi0stE07R6J3AqQb8459wC4PhYBNWb9B8yFoBFixfFORIRERHpbaJa2cE513Th0LoujKV3yh4JQHn+OjbuLI9zMCIiItKbRJPIbTCzowFnZv3M7NvA0hjF1XsM8InccCvgxcXb4hyMiIiI9CbRJHJfAb4GDAc2AtOC59KajKGQlMoh/Xfw4uKt8Y5GREREepF2jVo1s0TgC865S2McT++TkAC5E5leuZXvrN1BYWkVgzJS4h2ViIiI9ALtqsg55+qAs2McS++VN4Xh1Wuod/DyUjWvioiISNeIpmn1DTP7g5kdZ2aHhLeYRdabDJlMcvk2puTUMWvBFvj4SVj073hHJSIiIj1cuycEBo4O7n8a8ZoDTuq6cHqpIVMAuGJ8Od99P5/aoh+RhIMDzgOzOAcnIiIiPVU0KzucGMtAerUhkwE4ZWAhw6kgqWSTf71wFeROiGNgIiIi0pNFU5HDzM4EpgCp4WvOuZ+2fIQAkLUPpGaTU7aKL+QNgF3B66tfUyInIiIiHRbNEl33AhcCXwcM+BwwOkZx9S5mMGR/2LaE0zJWke+yqOo/3CdyIiIiIh0UzWCHo51zlwE7nXO3AEcBI2MTVseZ2Uwzu6+oqCjeoTQ2ZH/YvpSRRe/zAVP4KHkarH0d6rU4hoiIiHSkbNFGAAAgAElEQVRMNIlcRXBfbmb7ADXA2K4PqXOcc7Occ9dkZ2fHO5TGhkyGqiISSjZTNeJoHiscB5VFsOWjeEcmIiIiPVQ0idwzZjYAuAOYD6wFHotFUL1S3pTdD6ef8Bnm1e7vn6h5VURERDqo3Ymcc+5nzrldzrkn8H3jJjnnfhy70HqZYOQqGXmMGH8Qh+w/kRWMom7V7PjGJSIiIj1Wu0etmtllzbyGc+6hrg2pl0rLgYHjYOSRYMY1x+/LK8sPYvz656B4C2QNi3eEIiIi0sNE07R6WMTtOOBm4DMxiKn3uuI5OP2XAEwfncPHeeeAq6fuvQfiHJiIiIj0RNE0rX494nY1cDDQL3ah9UJZwyA1a/fTz804njl1U6l6936oq4ljYCIiItITRVORa6oc0Gy2nfCpiYN5c+A5pFflU7NkVrzDERERkR4mmgmBZ5nZ08HtGWA58N/Yhdb7mRnHnX4JG+oHUzj7nniHIyIiIj1MNEt0/TricS2wzjm3sYvj6XOO2y+Pf2aeykU7/k5F8Q7SsgbGOyQRERHpIaLpIzcn4vaGkriuYWYcfPjxAPzn5dfiG4yIiIj0KNE0rZaYWXEztxIzK45lkL3dflOmA/DRh++yYUd5nKMRERGRniKawQ53AjcCw4ERwPeAW51zmc65rFaPlNbljMYlJDPOtnDbs0vjHY2IiIj0ENEkcqc65+5xzpU454qdc38EzotVYH1KYjI2cCynDCnihcVbmb1se7wjEhERkR4gmkSuzswuNbNEM0sws0uBulgF1ufkTmQsm5gwJIMfPrWI0qraxttXvgxF6pYoIiIiDaJJ5C4BLgC2BbfPBa9JV8idQMKONfzis5PZUlzJr19c3rCtsggeuQDm/Cp+8YmIiMhep93Tjzjn1gJnxy6UPi53ItTXMD2zmMuPGsPf3lrLmVOHcdiYgbD2DXB1sGl+vKMUERGRvUg0o1Z/ZWZZZpZsZq+YWYGZfT6WwfUpuRP9feFKvnPqfozMSef6f35EcWUNrH7Nb9u+BKo1qlVERES8aJpWZzjnioGzgI3AROA7MYmqLxo03t8XrKB/ShJ3XjiNLUWV3Pz0YlgzB5L7+6rc1oXxjVNERET2GtEkcsnB/RnAo865HTGIp+9KGwD9h0DBCgCmj87h2hPHM2/+x5C/DKZf4fdT86qIiIgEoknkZpnZMuBQ4BUzGwxUxiasPip3IhSs3P306yeN5wt5awFYNewMyNwHNiuRExERES+aJbpuBI4CDnXO1QDlRAx+MLNPd314fUzuhEaJXFJiAleP2EARGVz+bAVVeQe1XJFzDspVJBUREelLoqnI4Zzb6ZyrCx6XOee2Rmz+ZZdG1kFmNtPM7isqKop3KNHLnQgVO+Dxy+H578HcO0hdNxvGHEdBeS1PbsuDHZ9AxS7IXwFbFzUc+/79cOcUKNVkwiIiIn1FVIlcG6wLz9VhzrlZzrlrsrOz4x1K9CaeCmOO8wnaR4/Aq7dC6Tayp53Nr86fyrOFw/x+7/0F/nwiPHwu1AUTBy/6N9SUw4oX4he/iIiIdKt2zyPXDq4Lz9U3DdoXrnim4XlNJVSVQP9czjbjk/Unwvzb4dWfQb8MKNsOa1+HvANgw9v+mGXPwSGXxSd+ERER6VZdWZGTrpacChmDwXyx87qzDmdT8ii2uIG8evw/ISXLV+JWvACuHkYfC6tnQ3VZnAMXERGR7tCVidzaLjyXNCMxwRh01X+4Ke9urn6umE3DToGlT8PHT0D2KPjUd6G2Ej55Nd6hioiISDeIKpEzs6PN7BIzuyy8hducc+d2fXjSVGrevtz5pRlMHZHND1dNgqpiX4WbdCaMPhpSs33zqoiIiPR60SzR9TDwa+BY4LDgdmiM4pJWZKQk8eCVh1M4+AjyXTCoY9KZkJgME071Ta3hIIjWLHwcXvlpbIMVERGRmImmIncocIxz7v+cc18Pbt+IVWDSuuy0ZP521dG8knoKm90g5lQFS3ztd7qfwmTTB22fZPFTftoSERER6ZGiSeQ+BobGKhCJ3sD+/Tjla3/gazl/4qqHP+TZhVtg7PF+47o39jxgy0Io2dbwvLwQKnZCTUX3BCwiIiJdKppELhdYYmYvmtnT4S1WgUn75Gal87evnMC0kQO49tH53PdBES53P1j/VuMdayrhgTNgTsS8zeFKEMWbuy9gERER6TLRzCN3c6yCkM7JSk3m4S8dwQ2PL+Dnzy1j6rD9OGL9bKy+DhIS/U7r5kF1CZRsaTiwIiKRG7Rv9wcuIiIindLuRM45NyeWgUjnpCYn8vuLD2bfwf155LWRHNmvhOK1H5I1LhiPsjxY8aEs39/X1/tmVWic3ImIiEiPEc2o1SPN7D0zKzWzajOrM7PiWAYn0UlIML41Yz/OPMvPBPPgY4+wfGsJONewdFdZgb+v3OUnEQYo3hSHaEVERKSzoukj9wfgYmAlkAZcFbwme5lTjz6UqoyRHFDzMWffPY+XX3sVijZAWo4f4AAN/eMAilWRExER6YmimhDYObcKSHTO1TnnHgBOiElU0mkp+x7HCamrOGh4Nh++/BgAVZPO9RMI11Y19I8DVeRERER6qGgSuXIz6wd8ZGa/MrPrgf4xiks6a8wxJFQU8sgB73FF9nwW1O/LnQuDLpFlBQ2VudQB6iMnIiLSQ0WTyH0h2P9aoAwYCZwXi6CkC4w7AZLTSXz5JgaXr2LIEedT2W8gAHfNeouKomDQw9ADNf2IiIhIDxXNqNV1ZpYGDHPO3RLDmKQrZI+A767xo1QrdzFs8CS+P/ldeOh23l+yEtZs5huAG7I/tu4Nv6RXYjSz0YiIiEi8RTNqdSbwEfBC8HyaJgTeyyWnwoCRvuqWmExK1hAAfvrpoeQll1PjEnlwZaofvVq6DYo2wau3+T50Lamrgfq6bnoDIiIi0ppomlZvBg4HdgE45z4CxnR9SBIz/XMBGJNazucmp1OTMoB3C1MB+Ocr71Dzzl9h7q/g1VtbPscDZ8Dz32t5e+l2eO47fiUJERERialoErla51xRzCKR2EsdAAlJUFZAQsUO0rOH8LPLTgVg9vsLWPXWf3AY7s3fw9p5ex5fUwGb3oflz/u56Zqz7Fl49z7Y8HYM34iIiIhAdIncx2Z2CZBoZhPM7PfAmzGKS2LBDNIHQXmBX9UhfSC5w8YA8OPp1Ux2n3Bv7VlsSRhG1b+ublj5IZS/3DfDFm+EnWv9a841Tup2rvH32xbH/O2IiIj0ddEkcl8HpgBVwCNAEXBdLIKSGOo/GMoK/fQj6QP9LTGF4Wv/A8Ckkz7PTYlfx0q3sfK3Z7J0/baGYyOTs7Bi9+qt8OcTG17foURORESku0STyO0f3JKAVOBs4L1YBCUxlD7Ij2Qt3wFpA32VLmsfKNkM6bmceMIM/vDdLzN7yu3sW7WELX++gG8+8h5rC8pg+xJISvXJ4Np5vqn1vT/D5g+hMlitLazUbfs4bm9RRESkr4gmkfsHcD9wLnBWcJsZi6Akhvrn+kSuYoevxoFP5ADGnwwJCaQmJ3LqBV+masYdnJT4EdnLHuPk38xhxcK3qcqZCGOO9Ync0llQGXSbLFjpm1jDRG77Mj+lSV9VWwXzftv6CGAREZFOiiaRy3fOzXLOrXHOrQtvMYtMYqP/YL/uan2tr85BRCJ3SqNd0466CgaO4wf7ruHzR4xiQOkqZm0dwL8Kx/h+cnN+CSnZfuf8Zb7KV1UMQ6dCXRXs+ATq62HenbCzj31V1r0BL/8EVv4v3pGIiEgvFk0i9xMz+4uZXWxm54a3mEUmsZGe65M48E2rANkjAYNxJzbe1wwmnkbK+nnccnwmQ2wX2WOm8eCmEX574Sq2H3gVJKb4RC4c6DA5KNRu+zhIaG6GRY/H+p3tXcKm5vyl8Y1DRER6tWgSuSuBacBp+CbVmfjmVelJ+g9qeBxW5I78KnzhScgYvOf+E0/11bW3/wjAp084iYe/9wXKkgdS54yz5o1jQ8JwCtcupL5wtT9mwgywRD/gYcFj/rXiPraea3WZv9+uRE5ERGInmjWZDnLOHRizSKR79I9I1sI+chlDIOOk5vcfdTT0y4QPHvTP86YwMCMFjr6GqtKdfD79CJbMG8bkjYv5T/5svgTs6j+WAbkTYeP7sGm+P66kryVypf5++7L4xtETbf4QXr4FLn4UktPiHY2IyF4tmorc22a2f8wike6RnhvxeFDL+4WS+sH4k6C2wh+b4Zf54sTvkzLzV3zj5AmcfPynGJlQwOTEjWx1ORxxx5t8WD0c1syB6hJ/neJNsXk/834LD57V8gTFXa10O1SXt71fVYm/L1jhlzXriYq3wL3HwpYF3XvdZc/C6tm+uV5ERFoVTSJ3LPCRmS03s4VmtsjMFsYqMImR/hGJXFpO+46ZeJq/z5vS7OakvEkYjqNZQOawCZx7yAhe3ekrf9sTBrMm9wRc8eaOxbv+bdi6qOUlvza8A2tf933xYq2uFu49Dl67ve19w4pcfQ3sWB3buGJl22L/2T9zvR+00l3C5uhwTkIREWlRNIncacAEYAYN/eM0/UhPEyZyluCX7GqP8Z/2+w9toWU9dz9/X1lE/7zx3H7ugXzlgs8A8FLSCTz1iWFl+dzx7EI27GhHNSu0ZQHcf6qvCv18H3j0Yj/tSWT1rSzf37/31/aft6M2vgelW6Hwk7b3rSpteLx9SexiiqXKXf5+0wfw4cPdd92wEhdOZSMiIi1qdyIXOeWIph/pwcL1VtNyIKGd//wZg+Gyp+GYbza/feA4f06AgWMB6D/xBDj0S1x67c+YedyhADw9bz7H3zGbLz34HrOXb6d+10a/buuG9/zUJU0tf94nkOf80Q/IWP82PHgmvHlXwz6l2/390lkNj2NlxQvBNbe2vW91qe+PaAk9t59cmMgNnuRHHjf3b9TVaiobKpg7+0hF7tVb4dlvxzsKEemhoqnISW8QrrcaTj3SXmOPa35UK/h+dAP39Y9zfCJHv3Q46zdY1jAmjJ8IwFOfH8O1J45nwcYivvTAO6z53Rnw6EXw11PgD4ft2Xy3/HkYcThMuwROvQ2+tQQGTYB1bzXsU1bgR8nW18D8h6J7T9Fa8aK/L9nW+n7g+8il5/rPo8dW5ILJns+6008gvXRW7K9ZuNKv5wt9p2l17Ru+T6CISAf0iETOzCab2b1m9m8z+2q84+nx+g9u30CHaAwOmleDilwjwYTDufUF3DBjP9688SSePPIT9nXruLnmMu6p/QyUF/Dsa/MoqggGBhRvgS0f+elPQslpkDO6YQRsdRnUlMGoo2Ds8fDunxvWgO1qO9f5OeFSsqF0W9uDK6rLICUDhkzuuZ32K3b5OQLDvpHhAI5YCquXQw/sO5NIV5X4P0hERDog5omcmd1vZtvN7OMmr58WDJxYZWY3tnYO59xS59xXgAuAQ2MZb59w5FfhsKu69pxDJvv7nJYTuTAB61dXxrSVd8PII7nim7cz4NALAHj+5Zc49Nb/cfn97/LOS8H8c+FAi1DmUJ9IQUP/uIwhcNJNvtr44Jnw9/Ma91HrCitf8vdTL/DVv7aaGatLoV+QyBV+0nipruXPw+aPuja+WKgsgtRsSE73z2sqYn/N/KW+mX78KX71kNrq2F8z3qqKfDN2Tx3dLCJx1R0VuQfxAyV2M7NE4G7gdGB/4GIz29/MDjSzZ5rchgTHfAaYB7zSDTH3bgd/HqZ+rmvPefg1cOHfG084HErJ8klNOHJ13m+hbDucehtjBmdwyVmn4hKSuWl6DVccPYY1BWUULZjFRpfL+U/s5M9zV7O+MBgkkTnMJ3L1dVAaJHL9B8PIw+AbH8KnfwqrXoa5v+ra97fiBd98PPpo/7ytfnJVpb4iN3gSuDq/Fm3ometh7h1dG18sVO6CtAGQmOyTq5ooBqp01PZl/nPOneibWHetj/014y1cBaQ7+iCKSK8T80TOOTcXaPoT6nBglXNutXOuGngMONs5t8g5d1aT2/bgPE87544GLo11zNIB/XMbluZqyswnYMWbfJPkh3+H/c6EEUFxNakfNmQyQ8qW88Mz92fO9UdySsoSCvY5kbKaem57binH3zGb0347l1c2Grh6XFl+Q0UunOQ4OQ2OuQ4O/gK8dTds66K+aZVFsOZ138ybOdS/VtJGIldd6idSDiuVYfNqXa1PRIs2dk1ssVSxq2Fkc3L/1hM557pmipL8pf4zCyu7vX3kqnMNTdblal4VkejFq4/ccGBDxPONwWvNMrMTzOwuM/sT8Fwr+11jZu+b2fv5+fldF610XtY+viJX+ImvZk04pfH2YVNh60JwDlszl4TaCqaddBHPX3ccc79zIj86czJZqcn8c7lvfrr67meY9aafqLYypUkV8JRbICUTnr2hoS+bc74SuPnD6GP/6FG/TNnUCyAjz79W2saAh6oS6NcfBoz2z4uCr3tZvq809YRELmxaBZ8kt5bIzbsT/nRc565XXe4HOAyZ3NDXsrePXK0p9xVbUD85EemQeCVy1sxrLfYed8695pz7hnPuy865u1vZ7z7n3KHOuUMHD25hhKXER9ZwP4BhXTAYYfSxjbcPPQjKC32yt+jfvhI09ngARg1K56rjxvH4V47iV1fMAOCAzHJWrfG/5A//3Udc+cC7/O3NtawtKPPNu6fcAuvfhPl/8+dfOgte/gm8c190cTsH7/0Fhh8K+xzckMi1VpFzzlfkUjKCW3ZDs3LYJFte0D19zjojbFoFPwq5tRUt8pf70bmdqcoVrACcb47OyIOktN4/cjVyAIkqciLSAdGstdqVNgIjI56PADo49b/0CFn7+MEOa+ZC/yGQO6Hx9mFT/f2Gd/wSTQee76c1aWLAkFEAfPPILGq3ZFO7IINzDxnPnBX5/OTpxQCMGZTOiRMP4Rt5RzHgxR9iIw6HF77vT7A1ysVIVr/mp8T47J/885QM39+vtTnraqugvtbvF773MJGLTACLNkHu+Oji6U6NKnLprSeeVcW+0lhVtOeKIaX5LU9dEylsfh4y2TfH54zp/U2rYf84gLLC+MXRW2z9GAqWwwHnxTsSkW4Tr0TuPWCCmY0FNgEXAZfEKRbpDlnDfBPS8hdg4gz/izpS3gGAwdxf+ylFDjy/+fNEVMSSKgogM4+bP+Onx1hXWMZry/N5bfl2Hn1/Iy/WXMyLKR+RdO9JpLkKyocfQ9rmt7GaSkhOhU3z/TQhY1tpEnzvL36qlv3PaRxDa4MdwuW5UjKD975Pw1qz4dQp4Jtb99ZErr4+SOTCPnLp/t+lJZEd9iMTuZ1r4a6D4Qv/gXGfav2aBSv8oIqB4/zzgWN7f9NqZytyT3/Dfz9P+UnXxdSTvfUHWPacEjnpU7pj+pFHgbeA/cxso5l9yTlXC1wLvAgsBR53zi2OdSwSR1lBF8iaMhh9zJ7bUzJg0L6wfbEfGNHcPuBHUKbn+spWWX7DQAdg9KD+XH70GB648nA+umkGv/jiGbw65gbSXAVP1B3Lt9Ychrk6fvbAv/nL66up+u918K8r/ACE5hRthOXPwSGX+cQvlDm09UmBw0SuzYpcG/3kqkrhyS/HfsWK5lSX+gpb2LSanNZ6RS6cPLi8SVVp13p/nvZUQos2QeY+/t8Y/ICHnWvbnrOvLZs/6vw5YqWqqOFxR/rIrX8bNrzbdfH0dMWb/WeqqVykD4l5Rc45d3ELrz9HKwMXOsrMZgIzx4/fSysdfVU4lxzAmGOb32foVChcBVPOhYTEls+VOawhkRvU/L9zanIix08cDBO+DZ8czBEZB5G4ZAXM/S3phYu5+9lEvpiyCMxx70MPkT3lFKaPzmH84AwSEoJq4fsP+ARg+pWNT56R5ycrbkk4h11KmMgN98lYbbWvyKUNhIqdbSdyWxbAwsf8aNkDzvWvhQlJ04pmVwuX5wqbVvv1b316jDAhabpP+Lw9k/uWbPaV29DAsX4wQOl2yMxrX9xNbf4Q7jsBLn1izwE2e4PdFTnrWEWuqgSSUro0pB4trHhX7PTzS4r0AT1iZYdoOOdmOeeuyc7OjncoEikzSOTSB/nO7M3ZZ5q/P7CNZpHMoGmzLL/tH9ZmMP4URgwdzDknHg0p2dxwYCX/OxsSzCdFg9Y9x/efXMSMO+dy0E9f4rL73+X3L31M9XsPUDN+hl9NotH1O1CRw/mYS7bCgJE+GSxuI5Gr2Nn4HuCeIxuvNRsrYYUtNbIi18pgh5YqchVhIre27WsWb26c8OeMaf+xLclf7u+3Ler4OWIpbJLOHtmxPnLVpb5/onhhxTuWc/I5By/8ADZ+ELtriEQhXn3kpK9JHwSJ/XyTaUvVpOlX+slgh09v/VyZQ321qnxHo6bVNpn5QRVbFpJbV+NHk447nvPXv830rx7L/I0lzF+/k/nrdrJqzn/ol1zI5UumsfXOuRwyegAHj8ph+ugcxmXkYTVlvhoS9oOLVNW0j1zQrFy82VcMsoZDQnLbFbmmiVxdrR8Q0B1NaRVNKnKtNa3W10fMhdY0kQti39VGRc45P6p5QsSSbLtXBOnEOKhw1Gv+io6fI5bCJGzgmOib0MPR0WFTdF9XFZHUNv0edqXKInj7bqithBFt/KySjqup8D8vwz6z0iIlctI9EhLg7LuDQQ0tSM2CyWe1fa7MYXtOBtxeQ6fC+3/1f7mPPQ4OOA9bOotx5QsZNxDOz38Ozj6Dupffo6J4NIdMPY/5G4p4duEWHn3XzwV3aVo+twH3v/AWOaP2Z8KQTCbmZdIvKShwVwdJTaOKHH7AQ8lWn6gmpcK2j2lV00QuvC/8JLr33BFh02pa5ITALQx2CPvTQUMFLhTZtFpf778HzV6vyJ8/siKXEU6+3MacfeDPXVfduC8jNFTzCvbWRC74ruSMiX4C65ryYKRwN6yB2xNE9j9t+j3sSuHPnu1LY3cN8Wtnz/kl3Li+9a42okROutHUC7rmPBkR/aWiTeSGHeT/ki7eCMddDxNm+PnKnrne98/Dwdv3kAiknfpzrjtqPwDq6x2f5Jcyf/1Oihdvg7Xw0jsLefst36m6X2ICk4ZlcsDwbM6uX88RQE1SOsnQkJzsXOd/CWQO80neihd8VaWlCmX4y2h3IhcmRWtaT4q6wu6m1XZU5CKb9vaoyAUJYV2Vn0Q5sg9cpLBvU+T29IG+ctnWcmgAr/4Mlj4NX3u38Q/9cNRrwYrWP+t4qSz234WMPP/vW18PtRWwdRGMOrL1Y8MErq7aT3nTF/rKbV/m+8UmNvOrK7JyG8um1bByun3x3vmd6i2KNgRdB0oa/qCUZvW6PnLSB2RG/LKPtkNzOF8dwLgTfSf+iaf6ueKmXQrfWQ3n/BEOudwv9RVISDAm5GVy4WGjuPqMowB4+MJR/O/64/n9xQdz5TFj6N8viVkLNvPCfL+u6jG/eZfTfjuXa5/8hOqENLYsfQuA2vQ83yeqtrL1JqCmlbjwl1NtZcMvrRUvwUePRPcZtMfuptVwQuD+PmFoboRv5FxoTX+BRlZGWuvrFk7PkhWxwItZ0B+xHYnc1oU+EV8zp/HrO9b4KU2qittejSMeqop9E3x6rq+uVeyEt++BB05v3Dey2WNLGx5X9oF+cgWrfB/RxU82vz3yexLLptWyIJGrLGoYjS5dL/z+d6biXFfTuAtLxU7466nd06rRjZTISc8TrncK0VfkBk3wFbjsUQ19L07/FVw+C865268KMe0S+Mxdvqm3OUFFMLk8nwl5mcw8aB++f8ZkHr3mSBbcNINvHOsTzfOOnsTwAWks3FTMhtoB1G/ynaO//N9N3PSa/yH18Avz+M+Hm/h4UxEV1XWNr7NH02pEUhT+IJrzS5h9e3SfQXtUFgEGKcFnkJzm75sb8BBW77Dm+8iFA11a6ydXHFTkMptU7DLy2pfI7QqWQFvwWMNr1WX+l+7oo/3zvbF5tarYf8b9c/3z8gLY+L5P6sKRvhU74aFzGgZuhKpLGp+nt1v5EuBa/iUcVnUtseH/Slkh/O+mrp2OpDRi+Uc1r8bO7kSuE9/tBY/C7w9t+ENnywLY8HbHlmrci/W6plVNP9IHdCaRS0zyiVrO6IYmkcy86Ka3SMvxAzeaqfAkJBg5SdWQ2I/vndlQ/at7cCKJa3216FPTp7JhRylshDfnL+D593xndTMYmZPO+CEZTBiSwRe3bSUPqCktxNXW0y8ySdqx2icoWxf5VSTq67q2H0nlLp/Ihs23yen+vqZ8zwQ3/EGbPaL56UeGTfW/ZFutyAWVjaaJXObQtv96di74q9v8UmzhIJTwehNO9SuK5C/fvexbIzWVPnHql976dWIhjDU9WC+4rKDhl8yu9X4k96YPYPVsmHsHnPeXxsc293hvVF/n1+M97KqON5Otetnfh9Xbpoq3QL9M/3mWB0nAiufhjd/5KY3CUfGdVbYdv8qk882re+O0Nr1B+LOkue/2xg8gb8qefWKbKt7iuyrsWgdDD2z4g6+6tPXjepheV5HT9CN9QNhHLrFfQx+uaJz1Gzjmuo5f3yyoFLXQVFdd2jDQIZCY3dBkeNmMI/nhxX7N2N+fOYSXrj+eey49hG+ePJGpI7LZvKuCB95YS0G+r0TtLNzOxB89zx+ffw+AehJZvXwhm1bM933PXF37qlbRiFzVARoncs3tC77DfnPTj2Tk+X6Crc0lV7LZJ+VNl2XLHNp2H7mKnX6gxP5n+/iWPO1fD0esjj7K/4IvWNn88bOug0cvbP0asVJZ7BPjsCK3dVHDHwi71vv78H0sfqpxU15k0+reXpHbutD3Y/z4ifYfU1ns112ur/f9M9e94V+PXB0lUskW/31JH9jwPQw/r/b84p7zK3jqq23vV7rdf1czh0U/QEXar6Wm1Z3r4C8nt9zEHikcoBX+XyoKE7lWplLqgXpdRU76gHB1h6SU+HU0zh7R8vJRVaUNkwGHwgEPluhjN4OkVJJKNjIxz4965cCG3ZBEPoAAACAASURBVGvr6uHOb0EpDEoo5Zsnj2ffJdVU70xmXf0QVi9byCtLEvlVMPPET//xIkW50xk1MJ1Rg9IYNTCdkQPTGZyRgnXkM6rY1ThJDqtVzQ14CBO5gWP9L9twIIZz/odx+sC2101tOodcKGOoP0drnfnDH84HnOsToQWPwsGXNlwvZ6xf27elptU1c2P7PWot9qoSyB7uvxMQNB8GIhO5hGSfsL97H5xys389Mjnpyoqccz7mtqod0QhXrQjX022PRf+CZ7/lq3npg3zf0NTslvullWxpGCwTNq2G1buqdiRyK15s3x9E4YoymUNhuxK5mAkTucqixq9v+gBw7esHWd00kQv6y7W23GAPpEROeqbMYbEdtdmWEYfCO3/yzXJNf+FVl/oKUKQwSckc2hB39ogW55JLSkzwqyVYAomulm8ePxzKk6A2l3FDpzKy4BP2zSyC4OdTesVWnltVwJMllY1Wo0pLTtyd1I0amM6ogWmMGpTOqIH9GZGTRmpyC82xlbsaN4GFFbnm/pINq0E5Y4PpMIp883NViW/2TRsIA0bD6tcaH7fqFZ/gjDnWN4Fkj9jz3GEzesnWPSdmDoWfYfZIOOhimH2r/8G9c43/xZ8+EHInwtrX9zy2ZKuvBialNX/ulvzjc7DvSXBkGxWczR/BX06BL70Eww/Zc3vYRy5sWl07zw/OGDC64ZfPzjU+ER003q82cvx3/OCTrmpaXfWyT94mfNo/n/8QvPJT+NbSPSukHdWRKTt2rPb3r9ziY0tKhUkzYdkzze9fsgVGHeWT0G3Bio/RVOR2fOJXX2lL6XbIGAxDJsO78/wAoOZG0XbUrg3+37y5bgB9RX1dQwLX9Lu9ZYG/r25HMhb+vAr/L4X3qsiJ7AUO/nx8rz/qKHjz97B5vu+rFrl0VlVJyxW5yKlTske2PACgtsr/1ThgtN+nYqfv95M2kMTcfUlcM5vxqemwzyGweT7fPiKdbx97MpU1dWzaVcH6HeWsLyxn/Y5y/n975x0fR3nn//ezq93V7qoXy5Yt27g33MCmGEKvOQKhBAgppJFCQi5HevkdyXGXcncJl3pHIJBCCXD0hABnHDoGG4wr7k0uqlZd7a7K/P74zqOZXe1KK1nVft6vl15arXZnnplnyme+taq2lh1HIry6o5a29sSEivF52UwuCjGxMMi4vADjcrMZlxvg/OZ6ssbNprvUbF+uVW/AyTiN1IuQ00/UwUKxyDUfShS+z35bhN8X3xLLScXynsvWQq6lKr2Q03EvBZOlxM2q2+HdP4slq/AE+V/pLGl3llzE+cDb9v5uE2ujLwNB19khItSf01PIdcTkRl9QIX9vegy62qXUTCohF7WFXJZfClTHGiWWJ7/CcUXX75bEnNNulhIrmx4Xi6P7Bnc0Wasv/kTGrYVc1SZJujiyR/bbYDAQIdewV/Zx0wFYey9MP0+svtEGuRG7YxotS0R57nixvmlrTaO2yPUhdCP1zvHaVymX1mqZj7L5EtqghfZg8ep/SdLOt/Yfv6VNoo2AfU3tIeTs9ogZCTlbwCe7VnvrUjMGMULOMDY59XMju/7JUoKEva+JkHvj12Khu2WdXDyykwK6uy1yrmD+kpmw7oHUtah0+Y/i6Y6Qa6sX61LRNHEzHVonsX71u7qtUtk+L9NLc5heagvJ5sNwx1lw/QNY0y+itiXOvvoI++sj7LWF3v76CG/urqemOUa8Uwr7rg7UsKp2Ir/88QtMyM9madZevgU8tWYHXU0zmD0+lylFYYJ+rxPnFSqSdUbqZNzavRUqsrsPWHIhLZkp23xkrwio6i3y2VQ15rTwTY6LaqyUm3ywQJaZFRSrVrgEpp4p7lUsKQANYpEDKVFSvsRZjjt7re1IZkKu6YC4OVMVnX3pP0Tgf2WjjGXbs/L+7pfhnKTPdnWKWNfJI+FiEXLlS2Ucu18WN/WR3TDjPJi0DFCO+I8PUoxcpD5xWTpGr37nIAo527UaqZWsz5wMkpSO7JXzzBcUATvjfHkoADkeiqcnbkNnXDKkvbUi9rq6HNdqXxa5eleYRNuRxIQqN5Zlj3+cWORAhO9gCrnmQ5KRHG9J3TnmeMBdesct5Cyrfxa5dpdFrqvLEfaZfHcMYYScwTAQQkXSM3bf63KBWP3fjjsv1pJYDw2cv903iJJZcsFuPtQzPkxfyIqmwc4XbItcndw83DewCYsh/4X07b4a9ssNbu/rqBnnU5oboDQ3wElTCnt81LIsGiLt1LTEKLkzyuyKCpaEC6luirK9XurHPbtuN0+/va77O7mBLP7Lt525lp/7X6nlVuD5NVuIH6lgZss+ZgHt/nx82nV4ZK/c9FprRMSBWFvc+8iNFr7JiSX3XSOWqyvvFCGXP8kRw4uugydultfzLnf2NUjmaoKQe9t5HalPHaeXjH66T1XnbdvfZLvW3SfrrtkiruXKt3pakbT40jfrUImI8vIlcgOKN8v3O6Ji0fR4Rbh2Z/O1iDWvI3p0rtW2enlw0JnPWsgNZq0tLeRAtilTIVdxCpz+JTmG538Qau0SLE0HE88DXVcxd7xYea0ueU93KOkrRq7eta29Cbl4i8xvuNTuGa0kTm7+FX1vT6Zo62Vz1dAKuUPvisU6XZmlkcSd/e5+SGnY55x3GVnkXDFyLVViHQdjkRvtmPIjhmFj8mmShbf7RefmXrVJLh7JF+BQsVhadE0zSBQXPYScfSHTte7a6m2XZVFi78HyJb3G2nXfyDIIylZKURj2UxiwoDPKkllT+MX7bNHTMBHugJ9dOZMvTjqTrYebOdDQRnVTjLL34rTEw6y27//PrtnEI6tLuMzzJr/wwyW/3URWqIC/AX965u9s3ljGQnZwnb3ezncewAtYuRPo4UgKFUvMWHLmatMBuaDr0iPu+Lp5l8Nfvio3XO1aLZouFrzKt0TogXz34DtOIkambZ30XEeShFxrrWRngohTr+2eO/ub8MzXpX7V9HOdz2vxpWv16czViUsdd/Euu8CxnvOgKyMz3izb5PUN3CLXZRchtrpkuTnjEi1yffHgDTK2C/+l98+11kjiSsth6c7QV/xX2xGxThZOkZ8P/1ne1/ss2UKrkxTyysU1CnDY1QKvL4ucW7T21hVCd3XIGSeWwtI5sH9178vuL3odLVVQMkT3sa4uKYy7/NNw4e1Ds46jIZ1FTlvjlDezhAUt5KINUiqm+30j5EY1lmU9BTx18sknf2akx2I4xplyOqy9B57/niQ3tLfaQq65R/kRlIKbViW+Vyrtv6jdBtOT/G5uixzITbbtiAibvEkiEnxBESH5k8QyCHLR2/0yzLk0cTn9ya7rbs/VM9nB1xljzvg85ox3PcVXW+Av56Fr/wF+CD84fwKfmnMm3jVbYS186MyF7G4L0bYxSE7rHv628TBNbWu5zg8vdi7krLiIn0vv2UkkH8rysinLy2Z8XoCyvGxuCJTQemgvbfURyvKy8XsQd260UdyMjZXSnUMTyIW5l8GGh2T/gASjV5wCe151PtewT/br/A/CW3dl3tYpnUVOJ3Oc8jmx0L7yU0lQWHyDxAPufjlRyEWTLHLhUpnX0rmgJa1eZpEtSEPFjuDUsZidgf5Z5N77q4jF3PEiAHWf3ObDIlCa+2GR2786s3W31sD4BVDZltmxqOMDC5LiIrX7PbmWXJPLIqeP36oNzv/7GqNOrIDeO2p093i2O8rMPB/e+O+esZdHg7ZeZtKaLhVdXfDqHXJdueI3qePs2lvlQWfvawMf51Cij/Gs7MSHlEPr5MGudG7mFjmv3/ZK2NuanW/qyBkMBhsdJ3d4A5x4lVh9qjamLj+SipwyCXBPrtgPPYXckb0SlxUqkqzXkpmSOauUCLlog9xMXv81PHi9czPWyzmyp2/3Ut1OCc5Pbs8FfSQ7NMnF0Z8DHh+hjgbmTshjVp64Y2+68CR+eNUighPmcMXEZt7+3gXccZG4dssvvKV7MecuX8TCSbLO9ZUN/OH1vdz+ly1sbQ2xaes2zvzJKmZ99xnOuv1JdCD0o4/8CVqqWNeUy982HmLt3nr21rUSPekzEh/nbsk2dYW49Vpti5Z2q04/z95X9s2j8YAEnLvTf910Z741J2Y57lwl++y8/yexXC1VMOtiORbKl0qZEzdaXGjX1um3wLV/lMSHgsny3t5XxfqQbydPhIqSXKt2AdxMhVxHDP58gwhX9zaDjDfW4lg6tLjp6oR3/tRT6Ha2i7DRVt/eiNSJ+Bk3L30JkuYqqLFLxHSXjpma+JlArlgwm9JY5HLGi9US5LwEuZH3KeR2iuiG3oVct0XOdg3PvEjcdTtXpf9Of2hvczp26HX1h0g93H+NZPq++4AjPJPR++PQu0dnnXrp3xMfjgYLPQcFkxMTeQ69KyIuVJQo5BornfPaTXvE8XxoIVcy27hWDQaDTUGF3GAb94vVpa1BLBRWZ0+LXCqUSl/fTF/IcidIIL++qeqb1If+4GTWabdiY6XE04FcwHPLEm9KNe+J+EvGsqRf61+/JjfxBVfb63IJuSw70zTVBVCX0FAq0WIUqRdLpS5hUTK7W8xkNe2HUDEzT78CXrkVrC6+9oFlScOyaGxrx/vQPaiG/fx4xYkcbowRq9sDdvLjpIPPAPDHzZ3878a3E74f8n+Hkl+sozQ3QEmOn6VqAp8FXnz+cbrmXsaSHW+S7/XD1BVi/9JCZcND8H+3wexLUwexayEHImJyxsk+3LUKpp0lpUEWfRje+JUIOYATzoRX7ki03HTHyNn1+kpmOK60YIGTxVo41U4WQfavdhnqwtNdnZlnrUYbxQLXkiT0QcSQfr/wBBFT7W2SofvEzSJ0bnjYebjQQqOtDyFnWXbttWI5Zjc9ljrB55mvwb7VcOt7TkJHqkzl3Ak9LXLNB+3akn4n6UYLuaJpmblWZ10syTC9udh1n1VtkZt8qszT9mdh3gd6X0cmuMXbQHoDP/c9cccvvE6ytGu3pe5HrYVcV4eEF0xd0f91dcRg1b/JsT6Q7yfTUiPHRLjEPi7th1R9fFmWlPOZdbEdM+yapwdvkIeED/4mcZnxVpiyQh6wD6yVB87cMunbewxhLHIGw9Ew62Kx/ExaBmULnNidTN0spbPTCzlPliwnWOi4uXTSQPF0R8Bpa031ZokBAyeOyn2TrXLFiLh55afwxBck3m7WxbDxEXnfXRDY4xGrXLryI/qzoWLnAtt2xMkyBMmAbD4ooqNhnzxte30w7zIp5ZCEUoqCkJ/ckgpy4jVcu2wyXz5/Jl8/y3aveXwst2SbvnvDhTz9pTO49xPL+PerF/KNi+dw/fLJLK4oIJDlYVdNK3ftzKfN8rNrzbN84p632LZ2Je+2T2L2v7xGGwEeeWU9H/rv1/n7W5LM8ZeVq3jwzX383+Yq3t3fwIGGNmIdnTJ2LWz1ttZuE3GhXadn3goX/0huIiCZtFYnbH/e2cDuGLk0x4q2yrljIoOFSa7VXLHoZWqR08eD7hfqjvNrcQm5KSsAS7I5d/1dHiYidVITT3fI0FawVBa57c/DL5fbFqYWScgIl8rNNtrQs/CuZYmIazksWcxH9sq2purckleeOkZOJ8ZoIVe/W47HUEnv1uhIvYxp/IlSeLlXi5x2rdrxjF6fZBRve05cmkeL24KWrnNMR1zmYdtzPf93+F2Ydjac+135O10RbPf+2P/GQEYq54HVlb5lWn95/HPwqB0RFamXuc8ucI7tpoOS9Vy+WJKG3OK8+ZCT8KKxLBFyBZPl+O2MS49tX9gUBDYYDC4u+YncoJVKFCOZWORAzP7r7pMbrNsCpkWQUraQs58g9U3KjRZ07z4oYwGXkDsiQi9Sn7qGV1enlE2Zfi7c8Ig8Zd97qTylB5MyW33Bnm6Yzna7/6oWcq5g/LZ6CLmF3Bz5XbtdLC56f73/Z06cVipyxssyO+JicdExUFNXdMeQFU6YRmFR3+3aun5/Gh9pqeT0JV3Mfm4rb0y7hU+WnkDs7XwmBqIoBd5WERmb17/Fr95JzKT10snWQCXveaazgO385PHXiYzv5PzmxzgDeC46D++WKqaWhJm87LP4dPHnyafJXD/1ZRHhExa5YhHTZA0WTJY4L52wAbJ/2yMikGK6FZyVebKDXqcWDG7rU3OVS8idBuv+JC7H3S/Kvr74R/DLk6UUyJm3OjFc0caevX53rJQM09rtiTGA+lit2ZJYbqbpgLO83S+JNTA5Pk6TVw47k8IRGg84CUOBPHkI6uqQ9wI5vYsNbe0uni7HfG+xkq3VYhXXFlKQ+MxNj0r8Vqpagf1BW+TS9HIGxLJe+RbseB5mXei839UlD3xT3ycZ4L6w46pOxn287OtHsobu2gLOfkvXMq2/NB5wjkd9/QvkOmPVonTcXLGwuV2rseaeVunOuO0dCcu5VLtVjj9/yCQ7GAwGFx4P3YZtt5DLJEYOnPiN2u1Q4XIt6qK6IDfvajsTL1lcgd0tIksq9CuvXLzcQi5UJO6V6hQWud0vyg3jkp/Ijdgfgg8/DO895cQMaXzhni26ugP281xjfa/nNoC4VkFu4g37YfYl8ndf3QNy7VpyLVXiztZiZNbFtpBTqUuXpMAz9Qw8q/6N2Wv+GQqncur13+FUXzbsLeO0PMVpHz4NftsOB+CfFnfy4QvOpe5II4WvfJ93Jn+C+pY2st7qorFgPhzZTmtDNY8erGRp5ytUekq46akawLGq5AayyAv6KMnxMyt4G99p/Ed8v7uCvyy7lzn1+1kIvFoZozC/iUlFQfKyXQKh2yLnFnLFzr6Nazdtf4ScbT3TLkJtfQqXipDSViAd/7nnVbmBLv2YuJlDJY5r2X0DjzYmPmToMiH1OyU5R69j3Dx5fWh9YuJH5Rr57fWLkHML/WRyJ8hY3R0Vmiqd80cpEVut1bJuf7h3i5y2dhdNl23oK0Yu2VU54wJASc3AoxVyWmCXzk4v5LTLOLl3cNMBOyZsph1HO6MXi5xt5ZqwGCrfTBRo6ajbCb85HW78K0w6yRFy6Vqm9Zdoox2n2exct9zxn1rk5k6QBxjtHejskNfJrby00PPnOEKuoEKOMRMjZzAYUlIwWWLCUmWtpqM7c3VropBzuyXdlrpUFjmPVywPDfvErbLr74lCLrtAxrb1mZ7fXf+wiDAdywUSyH3yJ3t+1hd0XBIb/1fihPJtAZXgWnWtW4sRsGO9/JK92RlLb3FJRrvMkoXctHNkeaHizFtJdbsMd8K19zldJoKuJALb7eet3cbEgiATq1+GnfdTUT4B5p0Db8GKM8+DJx/n+xdM5PtLLqLzrp/Sbs3ihSvOoqGtnd01reyrj9AUbaexrZ3aljgbm/P4VNd3uafjG/he/jEvWSXM83q44fcb0FmqQZ+XkN9LbnYWN3q7uBH43WbYfngDk4tCnBrzsATYunsPs2ItNHYG8Pu8BGPNqFRxZ8l0W+R0gV57m0tmOxY5T5ZYAUMl8O798v8TzpLfBZNdQs4lNKINicemTuCp2+GUYdEFm8sWSL29M/7R+fyBNTKXC66SrNqOKMx5f+ptyCsXC25rtbyOR+RYc4v5UJHzf6uz9xi5+l2gPBKP5+5IkgrdZ9VNuFjCEvYOQtC/FthlC+TBLBVayNUlxXlp0abjOktmO9nsyej9MeN8ePk/oG67cy1Kx65VMi97XkoUcrGmwcna1cdm3U7bml8s15X2iIg1LWxzxok4j7eKANUPMckPM91CLuR0WsmvkG1vj6QXr5VrZV06838McMwJOVNHzjBiaPfq/jcyF3IFU+QGlpy52nbEcRVpQae8TmB8MvkVcoOdcYEEBLvFVF65WELe+aO4Wv7vn8U9ceatsOUpmH95Zg3SfUHHIvfc/xMRd8mP5W/tHgwWyUW4q8vpRKHxZonVQ9+gMhVy3d0dXK48kAv6pOX9a2M08SSJ9atYnigUQkVyg+zqtNej5MbY1Qn77Gy3LU/L+EFco9B90/e2HMRbcSrT7I4aSyensJwCcCZdT77NFRseJjLjH1C7cnnoxtOpbYlReSRCdVOMSHsnTW3t7KqbSTtZ/LWmlN2HDlPXGucUVc2fA/DDh1Zxr7+dO1dXY+HhG74OTvnB04TDuRSF/RSG/RTbvwtDPrJ9XrKzvCyp2s9MgPYIVTV1FDbX4svOR+WVy3HbUiUC3eMRV+P+1XJDLVsgwy+YLG4tSLTIuWMxo02OK7NupzN/WgDN/QD8/YdOSy2Qm+f4hSIs3n3AXlcvrlUQS1BeubMudy1BbbnMK7czunsTcjvlu1kBOdfcySzJtFSntrrlT0qdfd5fWmrkwapgiojtVH1ctZBr3J9YZFpb6LSVv2SWJO7EW0X4uNFWrpkXiJDb9qyESRRUpI5LBNj/pr1+e/7dJVuaDkHpUQi5znZXtvROOa+KZzriMN4sx6YvJNdWXwiwpISK3pZk12q3kAs7D5T5k5z57WjruV8AXv5POcaNkBs5TB05w4iihVymrlVvlrgwk10gbQ2Oa6nbMleY3v2hb2LTz4E1v3OEXLRBvldmu7TuvkCeXLf+VS7e8WY48UOZjdVvu1a7upzAeO3u0K7VgsliLTmw1o77SxI0pbPEtao/mwnd/VaThFwgD66+O32ZkFT4suGTzyZ2ggDHItdaIxYcu4ctR/bAXtuqUbsVdq4ElMT7ebLkO7rPZ6oWYynwLPwQvH0v4V3PQLCA5SeksLICsBTiN/CIfaNuirZzcFspPArfOi0Ea+GipTOIdgBb4Kr5eeyN51LfEmd/fYR1+xs40hqno8vZP1/wbubrtvf2mp8+wT9lbWaJJ5tXN8e4uvMQW9/bSgG5/P7pzVwVL2UuUFmwjM1bqgn5s5jpLaO04RmaIzHyWqqcAs5uK5YWFMorQk5biHSCwLwPwN//TR4iln9GxMqhdeK+dRcKTi49onELOXCKYbstcvq4y5soYryjLbUosiwRRjqMIFjkFJ1NRWuNk7HqJlQsgfhHS2u1CN6ccYCd7es+rvR4w6Xyv/qdkqQBcg3JzncEs97vtdslQcCN27UaKpFamM9/T9zdH30s9dh04eMql5ALj5MxNx04unZubrdo3a7EGDkQkdZSJftFKUeAxSOOJa4zltjLWQtDX9hJGCo6wVVQO4XABbukTmPP90cxx5yQMxhGlEknS1X/ZPdLb5TMdJ6yNQmuVftGn8qtqjnhffKkOW6e4960LGc542xRaHXBx5+Si/LKH4jbcuoZmY3TFxThEqmVQHJwyp3op/gFV8oNYeX3AcsZu6Z0DvCEvM5UyGnriq4TFW20OxpkpW+l1Bvu2nLd6ygS0at7MU4/R4TcwXfk94KrJZt30+MiJLT1RrdO64xnHKfH5NMkdqupsu994GrplZftI+8EsVLNDohLdNH0ChFMW+DrZ0/s0QnAsixaYh3EOrpoi3eStXIV2KGS3z2rhLnbLLyxYsLhifir2xkX38d2JnPf6n0EukLM9cGv9k7kgV1rAfiIN87tvhgX/OBh7g1sJV+NYyLV/OdTb7I+P5ec7CzOjjzPNcD+vCWUVm1jn28207LCvL6nhZxAlNzAJKYWzkBtfhLPsk+jqjeLq2viyXKjLp0rYj+dkMu1hZy2CHZb5JJcq/o9HUAfb0kMUwA5D2reg1M+K38HC9K7VuMRWUaq9mK6ZEZy0kcmtNaKVT47T17njHOsmC1ViUKuYZ+UpFn4aakFWLs9UciVzHIeULrDNtIIOa9fRM+1f5KHlHf+lL5DTEu1PNRkF8h6Ys0ylrkfkESPo014cFt0a7fJOe4WcjHbIqf3i/Z4xFsSM7ZjTY6Qc1vkJp8P1z8owlUnfaUrKBypleVkEjc4SjBCzmAYTBZeJ+4+bX3IhJLZYp3QT5MdcbGUaRHUnfRQnH4ZSz4iP/pzTZVykevqkJtTTilceZeImNLZIt7GzZOLXKY3Hl8I2g8kBjfruDvtWg3kwrLPiLvGPfbubbWf2sOliX1He8Prk+XoQHB3uZPBIlgkIlcXq512trhY1t0nIu3Eq8UCcfBtR3xpN7IWErmZWeTweGDhNfDKzxxLZqZogaI7H+gWXZAy4UEpRW62j26nVyDW/b8Lp3hgXxSKyrl80Unwv1DWVU3Z0ovZ8oGLie8I0vXnp/ncxz7LDYHxROKdBHa3wkv38N0VISavb2Zf9hwmNldTqFppiMTZfyTCKa1biFtZ/Kl2Jt/yreHgjvUEVJiP3v1m97pvzVrA5+uf5NTvPsTlgTV8G/jE8100vPIqN7XN5nx28JNXmikt3Eleto9wIIuc7CxyAlmEfT7meLOJ1ezG29GFX4vvhBi5Yue9+t3yOpWQW/3fciwtvFb+DhbaWcHRnuEGWqyks8hZXSJIwr2cp6l44Do5pq7+nQim0lkuK3RSwoNuATfvChFy7ji5uh0SN6opmiaxf7UpXL4xVxzvlNPk58DbEruYCu1WXfIReP2XsP05ubZMOV2E3NGWIOm2gCmx5oOd7JDnjLe5yhGn+toRb010qUYbnWQUnZnqD8lDn06u6q24OcgDo9Ulx8to7EObAiPkDIbBRGeL9YfS2XLhqN8p7lSdWahvOsmWub4IFYt7SFsW9PcXXpP4OX1hyxRfSNwV+obmDTiFW93C6pTPycW+I9rTiqgvxJla4zTalQSyfwZbyOlx6lp7JbMk7lBbHCtOgbn/kCTkbIuc7jKQ3C+3N078kC3k+hlX5PXJzU3H+QRyxLICmdWSa2uQ78eaZH/qWCRt6QAp9wL4Z5wF3zrAFLdVImcRvAQfqIjB2iPMW74MXn2NT55UyCfPtC279/8GGmbx9XMugz8/wPuCu4kWzODhS0+jJdpBU7SdrGovWa89zt0THiMcOUBLLJ+skmnkdHRxv3UDf+lawQtrDxOJpxYIT/vHU7/6FT72yjP8xP8G53nyueKnr5IT8JET8HJhu48Pe/L40ap6lkQauRJ45LUtdBR3pBAK+gAAIABJREFUdYvCwo4aFm1+kubFn6Gj3UeQTgLBIslBbzsCVp4IGN0+T7sWy5f0HFDIfnCL1PVfyDVW2jXZLHFTTj3DESM9hNwGEWcTT5LjU7uxo01yXroLWGcFJGklVeZqvKXnsZedn7648/7VUmNPC7nNT8r7ZfPlunS0matR+1pVOscJvQgWuoSc7VrVrnftEm2PJB73blGnEzqS45XdbtlkOmJi8QT7gdEIOYPBkAndsSzb5MKYLMC6LXLpAuiTCBc7vVnd3z9a/CGJkdNCbuYF8N7T8tptWcoplQv+W3f1XHfxDEANUMjZMUhDZZEDif9RXllf6WwJKB83X4TenMvEHe0Wco2VjjWiP0KubJ5kgqZy8/Y51kJHQAfyerXI9SDaIEkMB98RIRexXe9uF7W7vEaya0kXnz6wBrAkKD8rmNRBZCuUL8ZrH9eeeBOhwvEsm+oS9VY57FnCArszBydew2+v6tnZoznWQUu0g9ZYB80x+d0S7SBn9UJOqHmdr54yi5PfjRCNj+fkKUU02599mjN5LHgStVsbqYm1cqUH/vTSZtZZTku1W7MeYqG3i0vfmEPl61Ko+VLPbn7th+t+/gzn+Tfxmchd/Ovk31IXnsVHDz3OzKxC7lyfRe62XeRmiyDMzfYxocXPLKC2+gCB3BMI+7PweDJMwok2iiCpt2PD3K7V5KLAhzeI8PaH5Fyqs4VcXVKig6ZkVs8yJWBnmSaJlGCBHWfWJmEUbirfEvdsyWwRRtvtYsRF08TqmdwyrS8sC9Y/JKI1f6JjkZt4UpKQs8Vma63dRSWVa9V13GsRBo7FzZdk+e+2yKVwrer4ObDHVNG/7RohjJAzGEaa4pmAcop3JgswbS3qzbXqJlQsF2TtchosIeezC2k2HRKrwLzLRcj5c3q6Z8/6htwMdHZn9zKCcNrNTseDTAmXOPXpoo39E02Z4LbI5Y6X7SmdIxm2U+yaaqWz4IN3Srst/Z3DG0TYKk9ql1tvfPzJAY612BFy/hynVVsmFrloo1jcsvNl3DG7/luCRa4s/ff9IRG52jqVO8GOK7MtOe1tEku18FqJcVMesTYnH7tKwWdWidu6vS2li1kpJXGB7tp6mqaTofJJvnhqMWxpgAkz+dm1i3t+DmBvCO75Efd9fD5NE1bQEhVROP+Br1BTcDa3LD2ftvZOIvFOSmqOwCY4u8LLgirJypxy+Hme8RTz7ehqXrTm8/MXdvZYxXxVyV8C8J37XuTZrghKQY4/K0HsLVC7OLl9DdPj23lp8udoK5hNYQButAXHuysfZBGwpSmbpn0tnBzIJ1J3gI7WOKGAl0CWV463ilNkpSUzYd0DIoq6M1aTWsqVzJQEneREj1hzz4Qs3Vs52pgo5Dri4nZd9mkR9mXzZf59ITlW8lK0TOuLDQ/DYzfBWd+Ec77lHD8Tl0ghapCHK20Rq7f3uX7I8Llcq7Ek16rGHSPnptstm8Ii1+pKWBlDCQ9GyBkMI42uc6RjWXRtr2SLXH9cq+DEz2QXpP9sf9AtupoPimiZaguaVNaxnHFw4e2pl3PRv/Z/3eFSaH1ZXkcbpXzKYKL3caRWgu7B6UShi+MCLLo28Ttt9SJsc8p6ZkQOFW53dSBHLGKQuWu1ZLbMn775a8uHnt++EkgKJotFD+Sz2QVOOEDtdsASa2aWXyx2R3anTv5RSkSoFqL9QSfvVG+WBxZd5y4VtvUm3BUhnB+EfORhqa2KsjO+yIeWuawuh1phE3xueRGsPAAR+EjuO3zk2n+CXzfw/suv45LFl9ISF8tgc7SDllg7sbpJ8CR8cmkeJ42bQ7P9P/3/4uatfL/q5u7VPL3hBH4d91BEEzfqbm8bngYv3PHGEZ597Q2e8+ew451NfOFNsRaWeFtZ49vPr1rP4Ymfvcg1nR4+E2/ma/c+x4WtL3MuXv7zzTih4HbCgSzC/ixmR8tY1Blnw6b1eEtmSIxhwEthtBmVO44Em6E+j9saEo+Bw+vlwbBiufxdtkCEXNE0mcO8chF6mdJ0CP76VXmdnIk+8STnc8ECxyKnj1U9rm73aGsvrtU0Qs7ncssm426Rpo/pWIu4XHurGjDCGCFnMIwGSmY7FrmqjYBysvZyJ8iT6/wrMltWspAbNItcELAk0D5vgvwUTnWExFASLhXR1NkxRK5V1z7SWYKzL5GSGDMvTP+d9ogIlcG2EPaG27rVXVML5yZmWXa/0j2yDe4yK9FGuUGGS526Z8Ei+UxOmWxLqibrbgomOwHpueNtQauFnH0M61jI4unphdzRoMvp7HtDEoPye8kYDrjccBqdAOHuYwvOcdB0UNyVeRPl9xt2M/ZpZ+PxpLAUlgfhSThlXBenvG96zzFs2g8PA598Du65mK+fVcat51xK68H34C75yKlZW8GCr155Bh/NX0LxcxUUdUS57eR5tMY7Kah5CzaDr/xEpvlyqG+aDC1A7Q6y27ayn3Hc9Vol8U6n3d1S1c6jAbjjwadZ2eWIpBf8h9lsBfn2bc+K6AtkcYY6yG3Ajx5/g6r8KOGAl7A/i9Nqn+Fs4Mm6crzrDzFDTWE20JA9iT37G5iSVUphpFbETl+i3LLgyS+JlS+nzOldG22UmNvSuUhxbEseWHwhserqa5k+Nrtdq3ayg8cHXe09LXKeLCeGVONOlEimh2sV2PQYPPlF+PJ6KRo9CjFCzmAYDZTMgj0vS8r77pekpIC2vCgl7odM0Td6XbBz0GLk7CfZup1OOYMzvpI+jX8w0VnArTXiShlsIZdd4LgBdXmLcAl84Bfpv6P3a9WmzEu4DAZuy2wgV9zAWdmyX/a+Bk/e4sRMXX2PlIQBOba0CM4pdQod69jL3PG2kOvFtQqu+EYllr1ggbRcA8n6VR6nLlvxDHFPD7aQy50gc6aLS/dW+sWvS1i4hZx9brjbn4Ezp3tekWPhzFvFevT2H0T0pYvt9AXF0pOuT6tOBiiZKeNuO4LXo8jDtgqVzEbZFvmZJ0xjZnEJrK+Ayre4cYU9xrWvwGa46YMXiaBoKIU7vs2/B38PrVvhpBvZdtklxDu6iMQ7aIl10Na0EO65je+cksU105fSEuskEu9g/AvtNBeO48pJk2iNddAa74CmAmiESGMdaxrqicQ6aYl1MEutptpTwC1/rQZqWKIsHgvAgzt9/Gjrq1zjbeTfffC+793PQVWGRykp9ZbloSQnQHHYT3GOn8KQn/Lodm7Z8TwrK77ErJY3CR7ez+r1h1h46BDjsnJ5ZUcjK8LlBFoPsrPJSzgeZbw/F+p2ivWwO0bO7VptluOhcX+im7U9InOSXDDc35tFLoVrVdcH7E8lgmHmmBNyprODYUxSOkuyPGu3idti+U0DX5YWcrXb5Sk3OXB5oOjlNB+EXDvj9aQbB2fZfaGFwJE9coPtb9mOvvB47BtsfcaFfbuFdrRhmC1y9np9ISc2UTcXf+brEnP2/p+K+PjbN6XIa7BALFdYsp1uYRV0CblAft/HixYz4VJxJ2cXQNTV/7NwqmOZ0Z0w+pvJ2RdKSfmc/W/I3+6uDsl0W+RcLrgjtkUuuVadP+z0ewXpNDFlhTxk9ea+BTvJKE1R4KaDYrkOFia2AdPuuxnnO6EVem5yyiTZQbdeq90ugl0nnORNkmOgdpsIzrPlYc+f5cGf5acg5IfCEITHMc06wLQFruP6hTYWTa9g0UWufra1+fBL+MGFk2CR0wfX+uVtdOQv59XLzpNkk5alND/9EKcuupK7y07Gv6cFVt/J55cG2Z87DQvosiyi8U7qWuPUt8bZUxvhnUgDV3VKce3bd8/kS+odlqld3Hz/2/zSt5c5ys+nfr+GP/oKWeBp5PyfSSjFKwEfk1QjXZbitP9aTzB7K7l+xVPAE29u44TO/ZR0+Cn05vDe9n2s9e0iHMji9MPVlHmyeXdXnWQq25bHnKxsgpC6bVtrjdOv2t3OzhdKXTx4lHDMCTnT2cEwJtEN5d/5owSATzt74MvSQq7lsNwM+tPCqjfc2V+Z1kwbLPTNrTvub5AtcmA3TK93LHJ9keCOHQEh5y6rEMiFHSvFKnHZz+Gkj0u80W/Pgf+7DS67w3F/Bgsg7nKfagvf0o/DpMTM0ZTo1lk6Xsmd7FC/07HGgdQZy51gu8wGmbJ5jlWxN4tcVrbcnGNJrtXcCT1vzkrJvLZUOT2K510uQm5aH0LO3Wc4maaD8oCgl68FnBYLM86DN34lY9VxYbnjpSOFbiBfu132rY7T8nik9lywECafmn5cpbMTS5DoJvPJ5Ud0uSM9NoBYC6p2K74FH2RigS3wy3Lhy6/RnVpSvAhWw/VzsuDEOb3tIXjsEdgxjlVf/Rgdz27Du2Ytf/v8GUx6+jd42sfzxGUryNl4Ha01G/ivhYtpjXUSfKkQWmtp8xVw7rxyWmKdtMY6iDYE6Ii10hlv5HCXD8vKZlflAW7fLVmvv/AdZJ7ycO2db/QYxvaAl3tf2MhvXnwej1KEA17ysn18pW0zJ3nyCVhR3tm8i1djW7ls124mZhVgRdvJTZV4Mwo45oScwTAm0TFF7/xJ4jp6uzD3RXa+81Q5WG5VSBRymVqtBgudETqUQk4Lmky3ze3izFT8DQZ6ve6sw0CetLkKFcNCu+Va+WI45fMiEE79glh8QfZdR8y1PPsYmX6OUzOtN7RFTov5YKFYuzrbxe0+xeVmHr8Abn2v/9uYCePsODnl6f3BQinZV/Ek12pyfJxGC7nxJ8p3F39Y9tfs96f+vCZUkhgs76bpoCM2g4WO5U4LuXFz5f/K6zx46e07vF4e7Gq39ezQkEktyJKZsPFRx7KnLZOp6si5x6TXjZW6dp4muWVab1Suke43SpGVWwYdbcwpVGC1Ql4RiyoKoOJLAHTbWDcWQ+t2wkXl/PBKV7men+Ry1bwCqPSIdbIxiyvzc7ngygtpjXWQ9+jdqJZi7rvkFFp06Rr7p/PlICcW+bh04ng6uywi8U6aox3ktDRSZ+US6vJQVV3Fr/fvYFnWftpUNhPinUbIGQyGXggVOU/0Faf0v1CsG6VkWa3VgyzkXC63gbTGOhp0fMpQW+RggBa5YRS2epzuY0S/PvmTifO09KMi5A69C7l2fJE7i1l5+78vu4Vc0vKqt4ilpzhFsP9QoIVOzvi+M4b9uT1j5GZckPqzWijr0jn+MJz+xb7HEyp2EkiSaTrolLEJFjoxjFo0ZefD3MsSY7S0eDrwtmRON+x1RHp/KJklVrbWGkkW0Psh+Rrj9UlMmbsosM5OnpCmtAtIiRB/Tt9Cru2IbPei6+RvnbjQWiPjSyesdQmS5CQcf9iJkQvkQnYeKtbkJKKoOITzWDEjRWzb2lxOnZTNqZefmPj+XZ3gmwKtdVxRlMPl116K9T8/pj00naycAWRXDxOjM5fWYDge0e5Vd+PwgaLdq4Mp5NxuqOG0QIHc6Dw+sfjovweb/lrk3GVAMu2zOhjoufW7bsR6/yz7dOJnC08AlLg83aJBu6qDhf13vfuCsPyz4nIExyV3YI38Lh6m+GRdgqa3jFVNIMexRMVbxeKWnOig0efM+BNT/z8d4ZLUrtWuLqnZ57ZgdsfINYoF3heCS34MV9/tfC9UJPN38G0RnlaXXXOyn+giwdq9qst1JHc8AJnLaJKQy5voiPZ05JWLW783dKbzJLu8T3f3iureM9G14ExOwvHnuIRcnvwkd3ZIF9emS+0kE6mVcyNYANFGlFJ4InUE8sbhzbTA8whghJzBMFootS+4o1XIjaRFTim5wOpsw6EQcqWz5MaZaVCzL+SUNhjOmMFUrtVTvwBX/LrnvPiypUZh3Y7EGDm3kBsIl/5EAvTBschV2jfq4RJywQJJVihMI8jc+HMcS1S60iMancU7vp9dN0JF0i2gvS3x/UitlMZwu1ajjdDV6QiYdGJ64lI48E76gr+ZoIWcthZqF3OqhKHsgkTX6sF3enerasqXwL7XRbSmo3ItoKB8qfytwyVaqpyyOKnoFnLJFrmQUxA4kCv70d3ZIR5J38/ZH0pTELhOXOTZ+SJoLUsshqM4YxWMkDMYRg/TzpEitJOWH/2ytLVosIoBgxMjl5U9uAIxU8IlUpgUBne7NKffAl94PfPPK2VXn89Pf8MYClIlO0xdkd7tVjRdhJzbIqdvism9cAeCPhYOrJFjYzitkx95NH3haTfuGLl0pUc0+RWyj5LbXfWFu9+qm+QWbnp/RRv7rolYvhSaKmHvq/L3QERy3kRxmWoxqEt0pArfcCeuRBvluEmOy0vFtHNku6s2pP9M5VtyfUt2lR7ZDV0dfVvkkh9S/GG7tmS827Xao45cKqsjyP5IbtHVERchGLaFXFujHDOdMWduRylGyBkMo4X5V8DNq8WKcrToJ8ihSHbInTB4mbD9wV0yYyiaWXu8/S/VEiwcXuECTs2yTOMoi2eISzraIIkB/ly7tdcgCXJtSanZKqJxOKvfF0/v2+0HdnkWW8h1lx5JI+ROvwU+92r/O3VoK3hrUgkS3Yc0Wci1HelbyE20rVcbHpHjLLmtViZ4PFAywylvol2rqZalLVEgcZWQmUVu2tnye9ffU//fssS1OsnVuSFULMejFpjpHs4C9v5J5VptPuyMOztftk1bBdtbe/ZZ7f5uuKdFzl0vLjtf5kYnrxiLnMFgGHa6XauDaLnyu4TcSKCFnC/sNIofaSYscmJ+hpP3/4ckNmRC8QyxwtRuF3eaxyNCvHhmevdif+i+AVvDl+jQX/y5iRa5UHH6c0O3zOsv+pzL1CKXiZCbsEjETqR2YG5VTcksl0UuTbIDJLpWtZCbkIGQy7NLzOxclfr/9bvEejbRda54vGLp6hZyfcXIJblWfSGJr9OfCeRJHKGe53hr+jAJ7ZYFuOt8eOk/HAGuXauxJqfzxGAXtB5kTNaqwXAsMiQxcraQG+7SIxr9VDwU8XED5cr/GZn1Lv5w5p/V4urA24ni5canB9bnNBn3MocrPq6/BHIcS1RvpUeOhnA61+pBSWhIjkvUQq6388kfFndk9eaBJTpoSmZLo/pYS9/JDtq1WrdDQgcyLeY8/RxY8ztojyZ6FSwLVv5AMqST439zxjlJGOmEtb6WJVu+/WHAkteBPKe8TqxJrNad8V6SHWzXaqxZXL6ROsfyqC1yWI4bPpThPhghjEXOYDgWGQqLnNcnF//8AVgrBgN9IxwKt+qxjBZyjfsSRXCwYHC6fujjAkavkPPbMXKWJckOmSRI9Jd0Fjmdsaq7cPSwyPVxjurkgP7G7LnR1ry67S7XaiqLXL5dE7BD9lO6OMJUTDtHxNS+pDjTNXfD5sfhvO/1tNiGSx1XbroHtLmXwYcf7vldt0jTyQ4gmava2tarRS7iZMHX73LGHS51llW/03lvFGOEnMFwLDJurmRUDvaN9eNPwoovD+4yM6VbyI0ii9xYIH+ylCaBoUkScS93tLpWAzkSUN92BBorh8Yip/v19oiRO5DY+aM/rlWAibalqOQozmVdc69qswi1rGDq8AQ9j7EmiSXsj+CdukKOs10u9+rul+Fv35KafaenuG64497SHZu+bJh1Yc/33SItO8/Jwo02OqVF0sXI6fIjui4lwLr75Xeo2JkT/f9RHiN3zLlWTa9VgwGpgfWdqsEPPJ94Ut+fGSqMkBsY3iyxrNRuG7p9FyyQ7MpRa5GzrU9r7wEsOOHMwV+HxyOuyFSu1bIFzt96DpoPSwuuvuZk/pViHZt8+sDHVjxdxFvVRrs9V5qkCW3Bb60Rwbvw2szX4Q9LR5o199rbpOCF2+XY++D/pL4W5bgTmPp5bCZb5Do75HXMbZFLs53+sOyH2m0yztLZUPOeuMCzC1xCbqcsY7D6VQ8Rx5xFzrKspyzLuik/31zsDcc5w5k9OByMxhi5sYJuXj+YrnY3wUKZl9EaS6SFy+u/FlE1ZcXQrCe5KLBlJbbnAhHWgTzp1AB9H8+hIrjoX48um93jFSv94Q1OJ4RU6LEc3iCJA/11Qb//p1CxXGLiVn5f3KKfWZU+zi7sSmA4KiGX74RcRBtdQq4XixzA4Y2S2DLvCvk7VCzXTbeQG63HtItjziJnMBiOUYxFbuBol+dQ7bvyxSI4RqIsTSZoy0ykFs6/bejGqdvsabSbLy+pE0qwAI5oITdE4jqZ8SfClifBt6wXIWePRbfm6k+MHEhR7Y88It9v2AdzP9D7vtau1UCeE0OYKT63kMuR3tKQJOTSxcjZ7x96V8Y8+2J48UdOvTi9H9pbITy3f+MaAY6xR3aDwXDM0i3khunGdyyhXZ5Dte8uvB0+9IehWfZgoC1ywSI48eqhW0+o2CmJAU7/0eTM1GChU89uuB5Mxp8ocXm12xLbuyWMSwu5dfJ7oEkh5UukhVtfgjnnKB7OtBjzBiT7WsfIxZpcMXJ9CLmmSskGnrBY2g6mGs8oj48DI+QMBsNYwZcNV90NJ9040iMZexQPsWt1tKNv8id/YmjjncqXSGbo+oflb91/NLl0RrDQsdwNl5DTcXpH9vTtWj30rsTUDXUrPu1aHcgDhhZj2qXqy5YEr2ijU0uut16rmuIZIjivuRcu+IG8F8gDbBE6yrs6gHGtGgyGscRQWlOOZcYvlMzFTKr0H4tMWATnfheWfXpo13P6l2D7c/DULdLaaeUPxPqVXDrEXd9x2ITcfOd1umQHLajizVLgd6hd5dq1ejQWObcozc63y4/YFrm0vVZdAk9nA08+xXnP4xExp1t2jXKMRc5gMBiOdYIF0kd2JLOORxKvD973taHvEez1wdX3iFB44maJzfvUcz172o6EkMvOg8Kp8jqdRc4XFKsWOJ8dSkJFUrJlIJbibiHnqisZyEuKkUvXazXJIpcKPS9GyBkMBoPBcByRNwGuewBOvRluWgVl83p+ZiSEHDju1XRCTinHKtffRIeB4PGK23kgBXfTWeRiTZKkAL30WrXfz8qGvEmpP9Mt5EZ3MWAwrlWDwWAwGAaXimXykw4t5Dy+4a1RNv5EeO/p9MkOIAKmtXpoul+k4voHB2b10okMbiGcnQ9Vm0SgodLvW/3dounpyzTp5Y6BGDljkTMYDAaDYTjRQi47f3hLtvRlkQPHzTkcFjmA8QsGllSRyiJ3+pegq9MWq+H0+1Zb5HrrljGGXKvGImcwGAwGw3DiFnLDycSlUq6jYHL6z2jX6nBZ5AaKdpu6Y+RmnAdfXgdv3ikFjdOhRWBvnUiMkDMYDAaDwZCSkRJyeeXwT1t6Jl+4yc6XBITexN5owOORHq7ubFMQkXbGV3r/bnYBnP99qXWX9jNjx7VqhJzBYDAYDMPJSAk5SN8uSzPlNCmom+UfnvEcDR95ZGDfUwrO+MfePzPrIumFezSt0YYJI+QMBoPBYBhORlLI9cWyTw99vb2xwPRz5GcMYJIdDAaDwWAYTnQc2vHaacMwqBghZzAYDAbDcOLLlvppw1F013DMc8y5VpVSlwGXzZjRSzaKwWAwGAwjyedfTd95wGDoB8ecRc6yrKcsy7opP38Uxh4YDAaDwQASJ+f1jfQoDMcAx5yQMxgMBoPBYDheMELOYDAYDAaDYYxihJzBYDAYDAbDGMUIOYPBYDAYDIYxihFyBoPBYDAYDGMUI+QMBoPBYDAYxihGyBkMBoPBYDCMUYyQMxgMBoPBYBijGCFnMBgMBoPBMEYxQs5gMBgMBoNhjKIsyxrpMQwJSqkaYO8QLb4EqAXygcZefpPBZ4biu8fC+gdrGyYD+8b4NhwP6+9rnsbCNozW9Q/2Ngz0nDL7cHjXn26extI2jMb1DwVaU0yxLKu039+2LMv89PMHWGP/vrO335l8Zii+eyysfxC3oeYY2IbjYf29ztMY2YZRuf4h2IYBnVNjefvH6DaknKcxtg2jbv1D8YOtKQb6Y1yrR8dTffzO5DND8d1jYf2DtQ0Nx8A2HA/r72uexsI2jNb1D/Y2DPScGqmxj5ZlDPf6083TWNqG0bj+Uccx61odSpRSayzLOnmkx2HoGzNXYwMzT2MHM1djAzNPY4ejnStjkRsYd470AAwZY+ZqbGDmaexg5mpsYOZp7HBUc2UscgaDwWAwGAxjFGORMxgMBoPBYBijGCHXD5RSFyultiqldiilvjnS4zEkopTao5TaoJRap5RaY79XpJR6Xim13f5dONLjPB5RSv1OKVWtlNroei/l3Cjh5/Z5tl4ptXTkRn58kWaeblNKHbDPq3VKqUtd//uWPU9blVIXjcyoj0+UUhVKqVVKqS1KqU1KqS/b75vzahTRyzwN2nllhFyGKKW8wK+AS4B5wPVKqXkjOypDCs6xLGuxK3D0m8BKy7JmAivtvw3Dz73AxUnvpZubS4CZ9s9NwG+GaYyG1PME8DP7vFpsWdZfAezr33XAfPs7v7avk4bhoQO41bKsucCpwM32nJjzanSRbp5gkM4rI+QyZzmww7KsXZZlxYEHgctHeEyGvrkc+L39+vfAFSM4luMWy7JeAuqT3k43N5cDf7CEN4ACpdSE4Rnp8U2aeUrH5cCDlmXFLMvaDexArpOGYcCyrEOWZb1tv24GtgATMefVqKKXeUpHv88rI+QyZyKw3/V3Jb1PhmH4sYDnlFJrlVI32e+VWZZ1COSEAsaN2OgMyaSbG3OujT6+aLvjfucKTzDzNEpQSk0FlgCrMefVqCVpnmCQzisj5DJHpXjPpPyOLlZYlrUUcSHcrJR630gPyDAgzLk2uvgNMB1YDBwC/tN+38zTKEAplQP8L/CPlmU19fbRFO+Z+RomUszToJ1XRshlTiVQ4fp7EnBwhMZiSIFlWQft39XAY4g5ukq7D+zf1SM3QkMS6ebGnGujCMuyqizL6rQsqwv4LY6bx8zTCKOU8iHi4D7Lsh613zbn1Sgj1TwN5nllhFzmvAXMVEqdoJTyI8GIT47wmAw2SqmwUipXvwYuBDYic/Rx+2MfB54YmREaUpBubp61mKTBAAADDklEQVQEPmZn2Z0KNGpXkWH4SYqj+iByXoHM03VKqYBS6gQkiP7N4R7f8YpSSgF3A1ssy/qp61/mvBpFpJunwTyvsgZ3yMculmV1KKW+CDwLeIHfWZa1aYSHZXAoAx6Tc4Ys4H7Lsv6mlHoLeEgp9SlgH3DNCI7xuEUp9QBwNlCilKoE/hn4Eann5q/ApUiQbwT4xLAP+DglzTydrZRajLh39gCfBbAsa5NS6iFgM5KZd7NlWZ0jMe7jlBXAR4ENSql19nvfxpxXo41083T9YJ1XprODwWAwGAwGwxjFuFYNBoPBYDAYxihGyBkMBoPBYDCMUYyQMxgMBoPBYBijGCFnMBgMBoPBMEYxQs5gMBgMBoNhjGKEnMFgOC5RSnUqpda5fr7Z97cyXvZUpdTGvj9pMBgMR4epI2cwGI5X2izLWjzSgzAYDIajwVjkDAaDwYVSao9S6sdKqTftnxn2+1OUUivtJtcrlVKT7ffLlFKPKaXetX9OtxflVUr9Vim1SSn1nFIqOGIbZTAYjlmMkDMYDMcrwSTX6rWu/zVZlrUc+CVwh/3eL4E/WJa1ELgP+Ln9/s+BFy3LWgQsBXTHl5nAryzLmg80AFcN8fYYDIbjENPZwWAwHJcopVosy8pJ8f4e4FzLsnbZza4PW5ZVrJSqBSZYltVuv3/IsqwSpVQNMMmyrJhrGVOB5y3Lmmn//Q3AZ1nW7UO/ZQaD4XjCWOQMBoOhJ1aa1+k+k4qY63UnJibZYDAMAUbIGQwGQ0+udf1+3X79GnCd/foG4BX79Urg8wBKKa9SKm+4BmkwGAzmCdFgMByvBJVS61x//82yLF2CJKCUWo087F5vv3cL8Dul1NeAGuAT9vtfBu5USn0Ksbx9Hjg05KM3GAwGTIycwWAwJGDHyJ1sWVbtSI/FYDAY+sK4Vg0Gg8FgMBjGKMYiZzAYDAaDwTBGMRY5g8FgMBgMhjGKEXIGg8FgMBgMYxQj5AwGg8FgMBjGKEbIGQwGg8FgMIxRjJAzGAwGg8FgGKMYIWcwGAwGg8EwRvn/PK+QO7PWk+MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26ff627ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts\n",
    "\n",
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history.history['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \".png\"), dpi = 120, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history, saveFig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(os.path.join(savedModels,  modelName + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file back in \n",
    "wt2 = pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\DataOutput\\\\Opt_rmsprop__Dro_0.0__Num_512_512_512_16__Wei_0.0_wts.pkl'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# END\n",
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0.0, \n",
    "               \"numUnits\": [32, 32, 32, 32],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "wts = model.get_weights().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcolors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 32])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 32])\n",
    "        axs[jj].axes.set_xlim([-1, 32])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0, 5])\n",
    "        axs[jj].axes.set_xlim([-1, 32])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([0, 5])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"95%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices.png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_32_32_32_32__Wei_0_pruned_bias.h5\")\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 25))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "    print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "    if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "        print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "        break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts > len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 32])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 32])\n",
    "        axs[jj].axes.set_xlim([-1, 32])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0, 5])\n",
    "        axs[jj].axes.set_xlim([-1, 32])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([0, 5])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"95%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices.png\"), dpi = 700, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
