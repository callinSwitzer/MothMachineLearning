{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 8 Oct 2019\n",
    "\n",
    "\n",
    "# Make videos of tracking moth"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "** show how well moth can follow trajectory with network\n",
    "** refref: make function to predict with nnet and then evaluate immediately with ODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFREF: Start with initial conditions within the range of the training IC's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
      "last run on 2019-10-08 14:24:57.156556\n",
      "TensorFlow successfully installed.\n",
      "tensorflow using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Arc\n",
    "from collections import OrderedDict\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import pandas as pd\n",
    "import importlib\n",
    "print(sys.version)\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# make sure Keras uses CPU instead of GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "else: \n",
    "    print(\"tensorflow using CPU\")\n",
    "    \n",
    "import numba\n",
    "#numba.__version__\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "dataDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\data'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n",
    "    \n",
    "# import custom file\n",
    "import simUtils_DLVersion as simUtils\n",
    "\n",
    "\n",
    "# import keras stuff\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    phi = np.arctan2(Fy,Fx)\n",
    "    if phi < 0:\n",
    "        phi = 2*np.pi + phi\n",
    "    rho = np.sqrt(Fx**2 + Fy**2)\n",
    "    return(rho, phi)# return radius, angle\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    '''\n",
    "    rho: radius\n",
    "    phi: angle (in radians)\n",
    "    '''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 10,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })\n",
    "\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "# t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "t = np.linspace(0, 0.01, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "alpha = np.pi/2\n",
    "tau0 = 2000000\n",
    "\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>xd</th>\n",
       "      <th>y</th>\n",
       "      <th>yd</th>\n",
       "      <th>theta</th>\n",
       "      <th>thetad</th>\n",
       "      <th>phi</th>\n",
       "      <th>phid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002528</td>\n",
       "      <td>-4.574622</td>\n",
       "      <td>0.082781</td>\n",
       "      <td>74.214379</td>\n",
       "      <td>3.228041</td>\n",
       "      <td>78.261308</td>\n",
       "      <td>-0.070516</td>\n",
       "      <td>-63.803507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.010159</td>\n",
       "      <td>-9.156930</td>\n",
       "      <td>0.164261</td>\n",
       "      <td>72.366294</td>\n",
       "      <td>3.315038</td>\n",
       "      <td>78.343381</td>\n",
       "      <td>-0.141363</td>\n",
       "      <td>-63.711706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.022864</td>\n",
       "      <td>-13.704057</td>\n",
       "      <td>0.243410</td>\n",
       "      <td>70.019064</td>\n",
       "      <td>3.402161</td>\n",
       "      <td>78.487471</td>\n",
       "      <td>-0.212075</td>\n",
       "      <td>-63.558373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040594</td>\n",
       "      <td>-18.199863</td>\n",
       "      <td>0.319676</td>\n",
       "      <td>67.177159</td>\n",
       "      <td>3.489479</td>\n",
       "      <td>78.697276</td>\n",
       "      <td>-0.282580</td>\n",
       "      <td>-63.340036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         xd         y         yd     theta     thetad       phi  \\\n",
       "0  0.000000   0.000100  0.000000   0.000100  3.141593   0.000100  0.000000   \n",
       "1 -0.002528  -4.574622  0.082781  74.214379  3.228041  78.261308 -0.070516   \n",
       "2 -0.010159  -9.156930  0.164261  72.366294  3.315038  78.343381 -0.141363   \n",
       "3 -0.022864 -13.704057  0.243410  70.019064  3.402161  78.487471 -0.212075   \n",
       "4 -0.040594 -18.199863  0.319676  67.177159  3.489479  78.697276 -0.282580   \n",
       "\n",
       "        phid  \n",
       "0   0.000100  \n",
       "1 -63.803507  \n",
       "2 -63.711706  \n",
       "3 -63.558373  \n",
       "4 -63.340036  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tragDF = pd.DataFrame([x, xd, y, yd, theta, thetad, phi, phid]).transpose()\n",
    "tragDF.columns = \"x, xd, y, yd, theta, thetad, phi, phid\".split(\", \")\n",
    "tragDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f350648a20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f35029c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tragDF.plot(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot moth at certain timesteps\n",
    "# plot final positions\n",
    "def plotMoth(x,y,theta, phi, F, alpha, tau0, fig, ax):\n",
    "    # plot moth and force\n",
    "\n",
    "    thoraxLen = 0.908 * 2# cm\n",
    "    abLen = 1.747 *2 #cm\n",
    "    bodyWidth = 1.1\n",
    "\n",
    "\n",
    "    # plot trajectory\n",
    "    #fig, ax = plt.subplots( figsize = [10,10])\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    #ax.plot(x,y, label = 'trajectory x vs y')\n",
    "\n",
    "    center = np.array([x, y])\n",
    "    head = center + np.array(pol2cart(thoraxLen, theta))\n",
    "    abTip = center + np.array(pol2cart(abLen, phi))\n",
    "\n",
    "\n",
    "\n",
    "    xx, yy = zip(*[center, head])\n",
    "    xab,yab = zip(*[center, abTip])\n",
    "\n",
    "    el = Ellipse(midpoint(center, head), width = thoraxLen, height = bodyWidth, facecolor='#907760', alpha=0.9, angle = math.degrees(theta))\n",
    "    el2 = Ellipse(midpoint(center, abTip), width = abLen, height = bodyWidth, facecolor='#DEC9B0', alpha=0.9, angle = math.degrees(phi))\n",
    "    \n",
    "#     torqueArc = Arc([x,y], 1, 1, angle=0.0, theta1= np.degrees(theta), theta2=np.degrees(phi), color = \"#B61212\")\n",
    "    \n",
    "    \n",
    "    ax.add_artist(el)\n",
    "    ax.add_artist(el2)\n",
    "#     ax.add_artist(torqueArc)\n",
    "    \n",
    "#     # add torque arrow\n",
    "#     ax.arrow(x = x + 1, y = forceCenter[1], \n",
    "#              dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "#             head_width = 0.2, color = \"#B61212\")\n",
    "\n",
    "\n",
    "\n",
    "    ax.plot(xx, yy, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xx, yy, s= 10, c = 'k', alpha = 0.2)\n",
    "    ax.plot(xab,yab, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xab,yab, s = 10, c = 'k', alpha = 0.2)\n",
    "\n",
    "    # plot force \n",
    "    forceAlpha = alpha\n",
    "    forceCenter = midpoint(center, head)\n",
    "    forceMagnitude = F / 15000 # scale \n",
    "    forceAngle = theta + forceAlpha\n",
    "    forceTip = np.add(pol2cart(forceMagnitude, forceAngle), forceCenter)\n",
    "    ax.arrow(x = forceCenter[0], y = forceCenter[1], \n",
    "             dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "            head_width = 0.2, color = \"#B61212\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tmp dir for images\n",
    "tmpDir2 = os.path.join(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\", \"Vids\")\n",
    "if not os.path.exists(tmpDir2):\n",
    "    os.mkdir(tmpDir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    final_loss = (50*losses.mean_squared_error(y_true[:, 0], y_pred[:, 0]) + \n",
    "                  500*losses.mean_squared_error(y_true[:, 1], y_pred[:, 1])  + \n",
    "                 1*losses.mean_squared_error(y_true[:, 2], y_pred[:, 2]) +\n",
    "                  20*losses.mean_squared_error(y_true[:, 3], y_pred[:, 3])  + \n",
    "                  20*losses.mean_squared_error(y_true[:, 4], y_pred[:, 4])  + \n",
    "                  1*losses.mean_squared_error(y_true[:, 5], y_pred[:, 5])  + \n",
    "                  1*losses.mean_squared_error(y_true[:, 6], y_pred[:, 6]) \n",
    "                 )/7\n",
    "    return final_loss\n",
    "\n",
    "# workaround for custom loss function\n",
    "losses.my_loss = my_loss\n",
    "\n",
    "\n",
    "# import model and predict\n",
    "model_name = \"Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0_2019_10_08__16_15_15.h5\"\n",
    "modelPath = os.path.join(savedModels, model_name)\n",
    "\n",
    "model = load_model(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               4400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                6416      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 331,735\n",
      "Trainable params: 331,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)\n",
    "\n",
    "\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerfileX = os.path.splitext(model_name)[0] + '_scalerX.pkl'\n",
    "scalerX = pickle.load( open(os.path.join(dataOutput, scalerfileX), 'rb'))\n",
    "\n",
    "scalerfileY = os.path.splitext(model_name)[0] + '_scalerY.pkl'\n",
    "scalerY = pickle.load(open(os.path.join(dataOutput, scalerfileY), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 3s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4587433757352829, 0.0043001190478354689]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xtest_scaled[:100000,:], Ytest_scaled[:100000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcols = [ \"phi_0\", \"theta_0\", \n",
    "        \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "       \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalPositions = {\"x_0\": [0], \n",
    "                 \"x_dot_0\":[-0.0001], \n",
    "                 \"y_0\":[0], \n",
    "                 \"y_dot_0\": [0.0001]  ,\n",
    "                 \"theta_0\": [np.pi]  ,\n",
    "                 \"theta_dot_0\": [0.0001]  , \n",
    "                 \"phi_0\": [0]   ,\n",
    "                 \"phi_dot_0\":[0.0001] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phi_0   theta_0  x_99  y_99  phi_99  theta_99  x_dot_0  y_dot_0  phi_dot_0  \\\n",
       "0      0  3.141593     0     0       0       0.0  -0.0001   0.0001     0.0001   \n",
       "\n",
       "   theta_dot_0  \n",
       "0       0.0001  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goalDF = pd.DataFrame(goalPositions)\n",
    "\n",
    "\n",
    "goalDF[\"x_99\"] = np.hstack([goalDF.loc[1:, \"x_0\"], 0])\n",
    "goalDF[\"y_99\"] = np.hstack([goalDF.loc[1:, \"y_0\"], 0])\n",
    "goalDF[\"phi_99\"] = np.hstack([goalDF.loc[1:, \"phi_0\"], 0])\n",
    "goalDF[\"theta_99\"] = np.hstack([goalDF.loc[1:, \"theta_0\"], 0])\n",
    "goalDF_ordered = goalDF.loc[ :, Xcols]\n",
    "goalDF_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scalerX.transform(goalDF_ordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "# inverse transform\n",
    "pred_trans = scalerY.inverse_transform(pred)\n",
    "Fx, Fy, tau0, x_dot_99, y_dot_99, phi_dot_99, theta_dot_99  = pred_trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref calculate new x and y from error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video with pred\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = goalDF_ordered.iloc[0, ]\n",
    "state0_ICs\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert FX, Fy, back to F, alpha\n",
    "F, alpha = cart2pol(Fx, Fy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36702.287008048617, 4.7371341625796717, -1162895.1]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "FAlphaTau_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f3183da940>]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f3e5016588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepnum = 1\n",
    "\n",
    "newICs = x , xd, y, yd, theta, thetad, phi, phid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "overallCtr = 1\n",
    "\n",
    "\n",
    "# refref: maybe the derivatives should be in the input, so it doesn't go too fast\n",
    "\n",
    "# define initial position and goal position\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "where_I_am = OrderedDict({\n",
    "                        \"x_0\": [0], \n",
    "                        \"x_dot_0\":[-0.0001], \n",
    "                        \"y_0\":[0], \n",
    "                        \"y_dot_0\": [0.0001]  ,\n",
    "                        \"theta_0\": [np.pi/2]  ,\n",
    "                        \"theta_dot_0\": [0.0001]  , \n",
    "                        \"phi_0\": [3*np.pi/2]   ,\n",
    "                        \"phi_dot_0\":[0.0001] })\n",
    "\n",
    "\n",
    "where_I_want2b = OrderedDict({\"x_99\": [0],\n",
    "                              \"y_99\": [0],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2]})\n",
    "\n",
    "xList = []\n",
    "yList = []\n",
    "\n",
    "prevXY = [where_I_am[\"x_0\"][0], where_I_am[\"y_0\"][0]]\n",
    "\n",
    "goalXY = [where_I_want2b[\"x_99\"][0], where_I_want2b[\"y_99\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f324cf1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax, ax1) = plt.subplots(1, 2)\n",
    "\n",
    "plotMoth(where_I_am[\"x_0\"][0], where_I_am[\"y_0\"][0], where_I_am[\"theta_0\"][0], where_I_am[\"phi_0\"][0], 1,0,0, fig, ax)\n",
    "plotMoth(where_I_want2b[\"x_99\"][0], where_I_want2b[\"y_99\"][0], where_I_want2b[\"theta_99\"][0], where_I_want2b[\"phi_99\"][0], 1,0,0, fig, ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### start of loop\n",
    "for jj in range(500):\n",
    "    \n",
    "    print(where_I_am[\"x_0\"], where_I_am[\"y_0\"], where_I_want2b[\"x_99\"], where_I_want2b[\"y_99\"])\n",
    "\n",
    "    inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "    inputData = inputData.loc[:, Xcols]\n",
    "\n",
    "\n",
    "    # predict force needed to attain \n",
    "    ## scale data and transform\n",
    "    X_scaled = scalerX.transform(inputData)\n",
    "    \n",
    "    \n",
    "    ## predict with nnet\n",
    "    pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "    # inverse transform\n",
    "    pred_trans = scalerY.inverse_transform(pred)\n",
    "    Fx, Fy, tau0, x_dot_99, y_dot_99, phi_dot_99, theta_dot_99  = pred_trans[0]\n",
    "\n",
    "    # convert FX, Fy, back to F, alpha\n",
    "    F, alpha = cart2pol(Fx, Fy)\n",
    "    \n",
    "    # refref: make sure F isn't too large!\n",
    "#     print(F)\n",
    "#     if F > 2000:\n",
    "#         F = 2000\n",
    "#         print(\"F constrained\")\n",
    "\n",
    "    # plug predictions into simulation\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    state0_ICs = [v[0] for v in where_I_am.values() ]\n",
    "\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    # add previous position to x and y\n",
    "    x = x + prevXY[0]\n",
    "    y = y + prevXY[1]\n",
    "    \n",
    "    # plot actual position\n",
    "    xList.extend(x.tolist())\n",
    "    yList.extend(y.tolist())\n",
    "\n",
    "\n",
    "\n",
    "    maxFrms = len(x)\n",
    "\n",
    "\n",
    "\n",
    "    # refref: add x's to each plot\n",
    "    for ii in np.arange(0, maxFrms, 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.plot(xList[:-(maxFrms-ii)], yList[:-(maxFrms-ii)], c= 'orange', label = \"moth trajectory\", alpha = 0.3)\n",
    "        #plt.plot(where_I_want2b[\"x_99\"], where_I_want2b[\"y_99\"], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plt.plot(goalXY[0], goalXY[1], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "        ax.set_ylim([-30, 30])\n",
    "        ax.set_xlim([-30, 30])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir2, str(overallCtr).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        overallCtr += 1\n",
    "\n",
    "\n",
    "        plt.close()\n",
    "        if np.mod(ii, 3) == 0:\n",
    "            print(ii)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate error and compute new initial position, but keep goal position the same\n",
    "\n",
    "    ### REFREF: may be calculating this incorrectly\n",
    "    ### where I am should always start at x_0, y_0 == (0, 0)\n",
    "    ### where I want to be should be the error....\n",
    "    \n",
    "    # update prevXY\n",
    "    prevXY = [x[-1], y[-1]]\n",
    "    \n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    where_I_am2 = OrderedDict({\n",
    "                            \"x_0\": [0], \n",
    "                            \"x_dot_0\":[xd[-1]], \n",
    "                            \"y_0\":[0], \n",
    "                            \"y_dot_0\": [yd[-1]]  ,\n",
    "                            \"theta_0\": [theta[-1]]  ,\n",
    "                            \"theta_dot_0\": [thetad[-1]] , \n",
    "                            \"phi_0\": [phi[-1]]   ,\n",
    "                            \"phi_dot_0\":[phid[-1]] })\n",
    "\n",
    "\n",
    "    # calculate true position\n",
    "    actual_whereIam = OrderedDict({\n",
    "                            \"x\": [where_I_want2b[\"x_99\"] + x],\n",
    "                            \"y\":[where_I_want2b[\"x_99\"] + y]})\n",
    "\n",
    "    where_I_want2b2 = OrderedDict({\"x_99\": [ goalXY[0] - prevXY[0] ],\n",
    "                              \"y_99\": [goalXY[1] - prevXY[1]],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2]})\n",
    "\n",
    "    \n",
    "    print(where_I_am2[\"x_0\"], where_I_am2[\"y_0\"], where_I_want2b2[\"x_99\"], where_I_want2b2[\"y_99\"])\n",
    "    \n",
    "    # update whereIam\n",
    "    where_I_am = where_I_am2\n",
    "    where_I_want2b = where_I_want2b2\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"loop\", jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_output_mothPath.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"explorer .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_want2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: do the same thing with a smaller, pruned network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vid of multiple moth trajectoies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 40,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.1, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug predictions into simulation\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, alpha, tau0 = (np.random.rand(3)* 1000).tolist()\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/2 - 0.3,0.0001, -np.pi/2 - 0.3,0.0001]\n",
    "state0_ICs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDir3 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019', \"MPC_Example\")\n",
    "if not os.path.exists(tmpDir3):\n",
    "    os.mkdir(tmpDir3)\n",
    "\n",
    "overallCtr2 = 1\n",
    "\n",
    "\n",
    "xlist = []\n",
    "ylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathNum in range(20):\n",
    "    F, alpha, tau0 = (np.random.rand(3)* 10000).tolist()\n",
    "    tau0 = tau0*10\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    xlist.extend(x)\n",
    "    ylist.extend(y)\n",
    "\n",
    "\n",
    "    for ii in np.arange(0, globalDict[\"nstep\"], 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.scatter(xlist[:-(globalDict[\"nstep\"]-ii-1)], ylist[:-(globalDict[\"nstep\"]-ii-1)], c= 'orange', label = \"moth trajectory\", s = 2)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "        ax.set_ylim([-30, 30])\n",
    "        ax.set_xlim([-30, 30])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir3, str(overallCtr2).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        overallCtr2 += 1\n",
    "\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir3)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2, setpts=0.2*PTS\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_MPCVID.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "xlist[:-(globalDict[\"nstep\"]-ii-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])   \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "              \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RondomWTS_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(100):\n",
    "    \n",
    "        # # fit model without regularization\n",
    "    stt = time.time()\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                            batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "    winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "    endd = time.time() - stt\n",
    "    print(endd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "    ctr += 1\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model):\n",
    "    \n",
    "     wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_and_ODE",
   "language": "python",
   "name": "dl_and_ode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
