{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "___\n",
    "\n",
    "### 24 Sept 2019\n",
    "### - Train and prune a Dense, Feedforward Neural Network with Keras\n",
    "### - Use data that was generated in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-09-25 10:39:27.174612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "dataDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\data'\n",
    "if not os.path.exists(figDir):\n",
    "    os.mkdir(figDir)\n",
    "\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 19)\n"
     ]
    }
   ],
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(dataDir, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>xf</th>\n",
       "      <th>xd0</th>\n",
       "      <th>xdf</th>\n",
       "      <th>y0</th>\n",
       "      <th>yf</th>\n",
       "      <th>yd0</th>\n",
       "      <th>ydf</th>\n",
       "      <th>theta0</th>\n",
       "      <th>thetaf</th>\n",
       "      <th>thetad0</th>\n",
       "      <th>thetadf</th>\n",
       "      <th>phi0</th>\n",
       "      <th>phif</th>\n",
       "      <th>phid0</th>\n",
       "      <th>phidf</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tau0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-860.538764</td>\n",
       "      <td>-50122.042406</td>\n",
       "      <td>-37099.512049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1864.077658</td>\n",
       "      <td>112333.095649</td>\n",
       "      <td>78407.466199</td>\n",
       "      <td>1.124204</td>\n",
       "      <td>1.775187</td>\n",
       "      <td>-240.317688</td>\n",
       "      <td>-398.977940</td>\n",
       "      <td>1.676109</td>\n",
       "      <td>1.137340</td>\n",
       "      <td>223.908457</td>\n",
       "      <td>-460.120574</td>\n",
       "      <td>365925.417230</td>\n",
       "      <td>4.308596</td>\n",
       "      <td>905969.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1663.999327</td>\n",
       "      <td>98162.039550</td>\n",
       "      <td>70772.904894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1578.437127</td>\n",
       "      <td>-91951.892590</td>\n",
       "      <td>-68471.287625</td>\n",
       "      <td>2.693406</td>\n",
       "      <td>4.812711</td>\n",
       "      <td>-200.894863</td>\n",
       "      <td>1400.049194</td>\n",
       "      <td>5.327012</td>\n",
       "      <td>8.650992</td>\n",
       "      <td>-22.632197</td>\n",
       "      <td>1415.053045</td>\n",
       "      <td>301963.993342</td>\n",
       "      <td>1.157471</td>\n",
       "      <td>-836862.125114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2112.906211</td>\n",
       "      <td>-128322.658782</td>\n",
       "      <td>-88483.199912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.677469</td>\n",
       "      <td>108010.493730</td>\n",
       "      <td>78786.893601</td>\n",
       "      <td>0.268087</td>\n",
       "      <td>1.672884</td>\n",
       "      <td>-76.923640</td>\n",
       "      <td>463.565758</td>\n",
       "      <td>5.398761</td>\n",
       "      <td>6.408854</td>\n",
       "      <td>233.275667</td>\n",
       "      <td>427.271735</td>\n",
       "      <td>442563.311276</td>\n",
       "      <td>6.082598</td>\n",
       "      <td>-128736.343362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1111.053471</td>\n",
       "      <td>-61945.461511</td>\n",
       "      <td>-51111.250941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2178.117332</td>\n",
       "      <td>-134603.694224</td>\n",
       "      <td>-90142.071404</td>\n",
       "      <td>1.454196</td>\n",
       "      <td>5.328020</td>\n",
       "      <td>-143.582522</td>\n",
       "      <td>1517.591974</td>\n",
       "      <td>3.281781</td>\n",
       "      <td>7.010763</td>\n",
       "      <td>-243.190037</td>\n",
       "      <td>1546.588052</td>\n",
       "      <td>179536.991219</td>\n",
       "      <td>4.832508</td>\n",
       "      <td>567528.919560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-729.739726</td>\n",
       "      <td>-39285.280174</td>\n",
       "      <td>-34179.352246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1031.910887</td>\n",
       "      <td>-56601.382912</td>\n",
       "      <td>-46818.328690</td>\n",
       "      <td>0.353609</td>\n",
       "      <td>-3.623116</td>\n",
       "      <td>-228.575046</td>\n",
       "      <td>389.104159</td>\n",
       "      <td>4.769991</td>\n",
       "      <td>-0.295224</td>\n",
       "      <td>-76.699950</td>\n",
       "      <td>321.156438</td>\n",
       "      <td>130307.280323</td>\n",
       "      <td>0.590567</td>\n",
       "      <td>684706.884762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0           xf            xd0           xdf   y0           yf  \\\n",
       "0  0.0  -860.538764  -50122.042406 -37099.512049  0.0  1864.077658   \n",
       "1  0.0  1663.999327   98162.039550  70772.904894  0.0 -1578.437127   \n",
       "2  0.0 -2112.906211 -128322.658782 -88483.199912  0.0  1827.677469   \n",
       "3  0.0 -1111.053471  -61945.461511 -51111.250941  0.0 -2178.117332   \n",
       "4  0.0  -729.739726  -39285.280174 -34179.352246  0.0 -1031.910887   \n",
       "\n",
       "             yd0           ydf    theta0    thetaf     thetad0      thetadf  \\\n",
       "0  112333.095649  78407.466199  1.124204  1.775187 -240.317688  -398.977940   \n",
       "1  -91951.892590 -68471.287625  2.693406  4.812711 -200.894863  1400.049194   \n",
       "2  108010.493730  78786.893601  0.268087  1.672884  -76.923640   463.565758   \n",
       "3 -134603.694224 -90142.071404  1.454196  5.328020 -143.582522  1517.591974   \n",
       "4  -56601.382912 -46818.328690  0.353609 -3.623116 -228.575046   389.104159   \n",
       "\n",
       "       phi0      phif       phid0        phidf              F     alpha  \\\n",
       "0  1.676109  1.137340  223.908457  -460.120574  365925.417230  4.308596   \n",
       "1  5.327012  8.650992  -22.632197  1415.053045  301963.993342  1.157471   \n",
       "2  5.398761  6.408854  233.275667   427.271735  442563.311276  6.082598   \n",
       "3  3.281781  7.010763 -243.190037  1546.588052  179536.991219  4.832508   \n",
       "4  4.769991 -0.295224  -76.699950   321.156438  130307.280323  0.590567   \n",
       "\n",
       "            tau0  \n",
       "0  905969.160686  \n",
       "1 -836862.125114  \n",
       "2 -128736.343362  \n",
       "3  567528.919560  \n",
       "4  684706.884762  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert angles to sine and cosine\n",
    "# cosx = np.cos(angle)\n",
    "# sinx = np.sin(angle)\n",
    "\n",
    "# # print(angle, np.arctan2(sinx, cosx))\n",
    "\n",
    "# trainDF[\"cos_phi_0\"] = np.cos(trainDF.phi_0)\n",
    "# trainDF[\"sin_phi_0\"] = np.sin(trainDF.phi_0)\n",
    "# trainDF[\"cos_phi_99\"] = np.cos(trainDF.phi_99)\n",
    "# trainDF[\"sin_phi_99\"] = np.sin(trainDF.phi_99)\n",
    "\n",
    "# trainDF[\"sin_theta_0\"] = np.sin(trainDF.theta_0)\n",
    "# trainDF[\"cos_theta_0\"] = np.cos(trainDF.theta_0)\n",
    "# trainDF[\"sin_theta_99\"] = np.sin(trainDF.theta_99)\n",
    "# trainDF[\"cos_theta_99\"] = np.cos(trainDF.theta_99)\n",
    "\n",
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.676109</td>\n",
       "      <td>1.124204</td>\n",
       "      <td>-860.538764</td>\n",
       "      <td>1864.077658</td>\n",
       "      <td>1.137340</td>\n",
       "      <td>1.775187</td>\n",
       "      <td>-50122.042406</td>\n",
       "      <td>112333.095649</td>\n",
       "      <td>223.908457</td>\n",
       "      <td>-240.317688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.327012</td>\n",
       "      <td>2.693406</td>\n",
       "      <td>1663.999327</td>\n",
       "      <td>-1578.437127</td>\n",
       "      <td>8.650992</td>\n",
       "      <td>4.812711</td>\n",
       "      <td>98162.039550</td>\n",
       "      <td>-91951.892590</td>\n",
       "      <td>-22.632197</td>\n",
       "      <td>-200.894863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.398761</td>\n",
       "      <td>0.268087</td>\n",
       "      <td>-2112.906211</td>\n",
       "      <td>1827.677469</td>\n",
       "      <td>6.408854</td>\n",
       "      <td>1.672884</td>\n",
       "      <td>-128322.658782</td>\n",
       "      <td>108010.493730</td>\n",
       "      <td>233.275667</td>\n",
       "      <td>-76.923640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.281781</td>\n",
       "      <td>1.454196</td>\n",
       "      <td>-1111.053471</td>\n",
       "      <td>-2178.117332</td>\n",
       "      <td>7.010763</td>\n",
       "      <td>5.328020</td>\n",
       "      <td>-61945.461511</td>\n",
       "      <td>-134603.694224</td>\n",
       "      <td>-243.190037</td>\n",
       "      <td>-143.582522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.769991</td>\n",
       "      <td>0.353609</td>\n",
       "      <td>-729.739726</td>\n",
       "      <td>-1031.910887</td>\n",
       "      <td>-0.295224</td>\n",
       "      <td>-3.623116</td>\n",
       "      <td>-39285.280174</td>\n",
       "      <td>-56601.382912</td>\n",
       "      <td>-76.699950</td>\n",
       "      <td>-228.575046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0         x_99         y_99    phi_99  theta_99  \\\n",
       "0  1.676109  1.124204  -860.538764  1864.077658  1.137340  1.775187   \n",
       "1  5.327012  2.693406  1663.999327 -1578.437127  8.650992  4.812711   \n",
       "2  5.398761  0.268087 -2112.906211  1827.677469  6.408854  1.672884   \n",
       "3  3.281781  1.454196 -1111.053471 -2178.117332  7.010763  5.328020   \n",
       "4  4.769991  0.353609  -729.739726 -1031.910887 -0.295224 -3.623116   \n",
       "\n",
       "         x_dot_0        y_dot_0   phi_dot_0  theta_dot_0  \n",
       "0  -50122.042406  112333.095649  223.908457  -240.317688  \n",
       "1   98162.039550  -91951.892590  -22.632197  -200.894863  \n",
       "2 -128322.658782  108010.493730  233.275667   -76.923640  \n",
       "3  -61945.461511 -134603.694224 -243.190037  -143.582522  \n",
       "4  -39285.280174  -56601.382912  -76.699950  -228.575046  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-143775.519045</td>\n",
       "      <td>-336496.673235</td>\n",
       "      <td>905969.160686</td>\n",
       "      <td>-37099.512049</td>\n",
       "      <td>78407.466199</td>\n",
       "      <td>-460.120574</td>\n",
       "      <td>-398.977940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121285.802738</td>\n",
       "      <td>276535.725231</td>\n",
       "      <td>-836862.125114</td>\n",
       "      <td>70772.904894</td>\n",
       "      <td>-68471.287625</td>\n",
       "      <td>1415.053045</td>\n",
       "      <td>1400.049194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433689.765168</td>\n",
       "      <td>-88178.637303</td>\n",
       "      <td>-128736.343362</td>\n",
       "      <td>-88483.199912</td>\n",
       "      <td>78786.893601</td>\n",
       "      <td>427.271735</td>\n",
       "      <td>463.565758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21514.002933</td>\n",
       "      <td>-178243.313742</td>\n",
       "      <td>567528.919560</td>\n",
       "      <td>-51111.250941</td>\n",
       "      <td>-90142.071404</td>\n",
       "      <td>1546.588052</td>\n",
       "      <td>1517.591974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108236.510499</td>\n",
       "      <td>72559.252341</td>\n",
       "      <td>684706.884762</td>\n",
       "      <td>-34179.352246</td>\n",
       "      <td>-46818.328690</td>\n",
       "      <td>321.156438</td>\n",
       "      <td>389.104159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fx             Fy            tau      x_dot_99      y_dot_99  \\\n",
       "0 -143775.519045 -336496.673235  905969.160686 -37099.512049  78407.466199   \n",
       "1  121285.802738  276535.725231 -836862.125114  70772.904894 -68471.287625   \n",
       "2  433689.765168  -88178.637303 -128736.343362 -88483.199912  78786.893601   \n",
       "3   21514.002933 -178243.313742  567528.919560 -51111.250941 -90142.071404   \n",
       "4  108236.510499   72559.252341  684706.884762 -34179.352246 -46818.328690   \n",
       "\n",
       "    phi_dot_99  theta_dot_99  \n",
       "0  -460.120574   -398.977940  \n",
       "1  1415.053045   1400.049194  \n",
       "2   427.271735    463.565758  \n",
       "3  1546.588052   1517.591974  \n",
       "4   321.156438    389.104159  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# scale data \n",
    "scalerX = StandardScaler()  \n",
    "scalerY = StandardScaler()  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044459</td>\n",
       "      <td>-0.077471</td>\n",
       "      <td>-0.378135</td>\n",
       "      <td>-0.276599</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>-0.363804</td>\n",
       "      <td>-0.246997</td>\n",
       "      <td>0.166977</td>\n",
       "      <td>0.463921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.296392</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.229830</td>\n",
       "      <td>-0.288629</td>\n",
       "      <td>-0.011401</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.209107</td>\n",
       "      <td>-0.268205</td>\n",
       "      <td>0.290953</td>\n",
       "      <td>0.184129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462941</td>\n",
       "      <td>-0.375731</td>\n",
       "      <td>0.171034</td>\n",
       "      <td>0.140524</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>0.151930</td>\n",
       "      <td>0.117742</td>\n",
       "      <td>0.232862</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131530</td>\n",
       "      <td>0.404820</td>\n",
       "      <td>0.036584</td>\n",
       "      <td>-0.332834</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.019010</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>-0.323603</td>\n",
       "      <td>-0.453282</td>\n",
       "      <td>0.353115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137024</td>\n",
       "      <td>0.151784</td>\n",
       "      <td>0.430877</td>\n",
       "      <td>0.107266</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>0.039668</td>\n",
       "      <td>0.429445</td>\n",
       "      <td>0.087003</td>\n",
       "      <td>-0.308493</td>\n",
       "      <td>0.173367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_99      y_99    phi_99  theta_99   x_dot_0  \\\n",
       "0 -0.044459 -0.077471 -0.378135 -0.276599  0.011725  0.012436 -0.363804   \n",
       "1 -0.296392  0.033915  0.229830 -0.288629 -0.011401  0.013935  0.209107   \n",
       "2  0.462941 -0.375731  0.171034  0.140524  0.026247 -0.011535  0.151930   \n",
       "3  0.131530  0.404820  0.036584 -0.332834  0.002561  0.019010  0.026978   \n",
       "4  0.137024  0.151784  0.430877  0.107266  0.045268  0.039668  0.429445   \n",
       "\n",
       "    y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -0.246997   0.166977     0.463921  \n",
       "1 -0.268205   0.290953     0.184129  \n",
       "2  0.117742   0.232862     0.146800  \n",
       "3 -0.323603  -0.453282     0.353115  \n",
       "4  0.087003  -0.308493     0.173367  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [400, 16], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history.history['val_mean_squared_error'][-1])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \".png\"), dpi = 120, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0.0__Num_200_200_200_16__Wei_0_2019_09_25__10_39_33\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                3216      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 85,935\n",
      "Trainable params: 85,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0.0, \n",
    "               \"numUnits\": [200, 200, 200, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]\n",
    "modelName  = modelName +  \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with pruning\n",
    "numCuts = 1\n",
    "\n",
    "wts = model.get_weights()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "72300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "72300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "72300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "72300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "72300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "72300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "72300 of 85935 weights retained\n",
      "change in log loss: -0.053691366188552525\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "59342 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "59342 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "59342 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "59342 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "59342 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "59342 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "59342 of 85935 weights retained\n",
      "change in log loss: -0.008817041095307343\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "47592 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "47592 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "47592 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "47592 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "47592 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "47592 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "47592 of 85935 weights retained\n",
      "change in log loss: -0.0039979332736571616\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "37396 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "37396 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "37396 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "37396 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "37396 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "37396 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "37396 of 85935 weights retained\n",
      "change in log loss: -0.002594676163810705\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "28880 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "28880 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "28880 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "28880 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "28880 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "28880 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "28880 of 85935 weights retained\n",
      "change in log loss: -0.0031047029994186737\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "21984 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "21984 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "21984 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "21984 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "21984 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "21984 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "21984 of 85935 weights retained\n",
      "change in log loss: -0.0038038595381547635\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "16546 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "16546 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "16546 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "16546 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "16546 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "16546 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.01874261217008344\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.015038518765255415\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.012675579318931485\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.00969094592660924\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.006968554847209374\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.005402423657334232\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.004173763351323023\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "16546 of 85935 weights retained\n",
      "change in log loss: -0.003311187269991356\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "12344 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "12344 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.002949312163945894\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.002767673640531765\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.004314341215550743\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.004300560870956094\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0056982466871451365\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.004045867378447254\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0025746027667341576\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.00318336710463607\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0031721134179066857\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0024256648251252955\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.002602987500229137\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0006095409523777517\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0010550799588732174\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.003169833484125917\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.002077658675957994\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.00201887206147755\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0007108001111556517\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0001718025182269045\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.002001234057128043\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0033542726890752883\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.004332907159136701\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.003089655673728098\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.001382990986735444\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.000994918241843168\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.001471262929040873\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.003003782032393598\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0005119718424950737\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0010820633234617238\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0007383403857942339\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0009593624301539316\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0011520648855996019\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.001630269063290779\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.00016379296892510276\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.00019836472052336962\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0009313310692347088\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0003048816059038062\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0002405499682156531\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0016678136963015344\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.003194412754035647\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0019597448875535717\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0008048732653979096\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0016262304404232042\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0009105490920097159\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0001969763629856569\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0001616854652282118\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.001098571251606284\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0004653186567640244\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.001229541570835102\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.00039435626861950013\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0015088711837611957\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0009890469838172988\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.00027124640221420915\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.00025444281096054233\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0002376842022052683\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0006424196670696825\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: 0.0011321036057131417\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -0.0007720804010380444\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "12344 of 85935 weights retained\n",
      "change in log loss: -3.97242704033296e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "9142 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "9142 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "9142 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "9142 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "9142 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "9142 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "9142 of 85935 weights retained\n",
      "change in log loss: -0.004535042629975283\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "9142 of 85935 weights retained\n",
      "change in log loss: -0.003466399299821732\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "9142 of 85935 weights retained\n",
      "change in log loss: -0.0018536615014361768\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "9142 of 85935 weights retained\n",
      "change in log loss: 6.102566636001505e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "6740 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "6740 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "6740 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "6740 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "6740 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "6740 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "6740 of 85935 weights retained\n",
      "change in log loss: -0.0016308415767757323\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "6740 of 85935 weights retained\n",
      "change in log loss: -0.00038122687160191404\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "6740 of 85935 weights retained\n",
      "change in log loss: 0.0006321369886037598\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "6740 of 85935 weights retained\n",
      "change in log loss: -0.0001897730312292456\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "6740 of 85935 weights retained\n",
      "change in log loss: -0.0005757283096264887\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "6740 of 85935 weights retained\n",
      "change in log loss: 4.6782150085911134e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "4948 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "4948 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "4948 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "4948 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "4948 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.010022419622098044\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.007172206181826457\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.00487949656978004\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.002773728202225101\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.001899180759377117\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0006861102456837687\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0008949933913754426\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.002538193046365711\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0009063880553640269\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0015029124246132008\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0002144825345082868\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.00022430029628905945\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0013481986430354809\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.00015165837594399711\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0010760212282805437\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0004946548644302329\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.00036323741190957826\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0013646362541119839\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.00047397561201034666\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0004031222321185801\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0004862825954949912\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0010539659841294347\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0004707152872480691\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0009634893295129565\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.002231416533719499\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0009038193921857562\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0005700406285940041\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0008352008987662085\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0003428528696891586\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0020196524720292874\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0013347634009535092\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0010127149675743796\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.00010903657207028683\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.001037136290725993\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0007425613903806472\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: 0.0009834295586637065\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0001928591203290697\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -0.0005042301756904566\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "4948 of 85935 weights retained\n",
      "change in log loss: -5.576857525591006e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "3630 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "3630 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "3630 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "3630 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "3630 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "3630 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -0.007068202365487886\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -0.003393125402589403\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -0.002158676041842833\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -0.0017178498954040222\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -0.0018504199527105136\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -0.00016493689419772029\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "3630 of 85935 weights retained\n",
      "change in log loss: -2.8592282676820346e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "2654 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "2654 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "2654 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "2654 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "2654 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "2654 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "2654 of 85935 weights retained\n",
      "change in log loss: -0.0052988688211875745\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "2654 of 85935 weights retained\n",
      "change in log loss: -0.0036676742563779285\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "2654 of 85935 weights retained\n",
      "change in log loss: -0.0021870314064575958\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "2654 of 85935 weights retained\n",
      "change in log loss: -0.0015466176549212562\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "2654 of 85935 weights retained\n",
      "change in log loss: -7.743853996045047e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "1940 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "1940 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1940 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1940 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1940 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1940 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.016441853623299307\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.012720397523350413\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.009824300384980944\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.007610488314466202\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.005108720075542639\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.0025280679646346726\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.0012186052217193488\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.0007575899096183836\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.0014258483201095018\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.000753639236878767\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.00018810237928512663\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: -0.00012149816350448539\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: 0.00045794260821840904\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "1940 of 85935 weights retained\n",
      "change in log loss: 8.448228545232528e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "1414 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "1414 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1414 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1414 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.029923697334663046\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.020163067400926216\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.012546143566989243\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.009860063993442858\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.011950046093812117\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.016389831661110965\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.012129667990861348\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.006680375774687497\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0036904888409831083\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.002516995170671499\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.006556228070050407\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0041960575348529705\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.001028622434103843\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0017177753136844442\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0013082516918470066\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0007465101598396195\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.00750147826594405\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.009706521463959339\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.004542487345150503\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.006750738913484211\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.003951638791155676\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0008428699212679192\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.003069933545718828\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.004773934979221517\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.010148622182533429\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0009782830276676702\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.00032190227118855663\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0009725444541976991\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.003511217175773962\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.003930706493904257\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0009360738345802755\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0006576844619463618\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0011546972593637905\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.002711599720697677\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.002433031862428825\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.001625750402959314\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0013876600614308732\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0044771484625593105\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.00045203221740519606\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.007500722193252929\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -0.0049010414533470215\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: 0.0009075811218682839\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1414 of 85935 weights retained\n",
      "change in log loss: -7.325670253599537e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1034 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "1034 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "1034 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.01868867479910785\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.021429608481393525\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.015511792208760977\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.007657969191041114\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.002426178035259019\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.003711443701729711\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.009037783372307207\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.011237105689238969\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.004499186924753817\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0020592692748667707\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0002453931545332022\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0017280614832001495\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0031001829020830263\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.00323746555720672\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0008681114631982068\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.003925733672801357\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.00904826022467975\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.003845968281254053\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.004489849374343269\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0029909449890410666\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.004796680004497733\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0015102188655300441\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.00013951144779411617\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0022123238421885016\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.009840986853710376\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.006987452911689673\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0007488126351101743\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.006686710647152205\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.011805767974395254\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.002344631231371741\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.00025626196696171277\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.000961897472425588\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0021270842234615284\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.001229313750103267\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0014813695416571182\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.005881523674964084\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.005369669043345904\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0007659920161132705\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0011826423969060196\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.005264748199250047\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.005872666861011955\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0019994867464482313\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0009486056752529004\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0029832400839232553\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.006236023129735813\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0010903922161923374\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0014885374411316432\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0005227324305219216\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0032422198407587866\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.002348959344043222\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0004815515486900068\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0020602779111289493\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.002122498645557247\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0015496411740061333\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0002708985743118397\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0016622747340493405\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.00047796985693004945\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.001531830939200285\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.003580404048739827\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0026800184673072547\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0014196036256794997\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0004253430434196792\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0021736360164297253\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0021317037526352722\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.002279597288845636\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0020640092195159943\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0023226855789321155\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.000245678675869887\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0027025984654585056\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0009197894653604211\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0013011129054221193\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0023974756825939636\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0031558883929302395\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0017740980895080138\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0012285635910822545\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0004303575764346146\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0007319775110554705\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0007232740664174786\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.004584078134747038\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0008962272961713369\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0004470464024018961\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.00430682831504603\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0018587775568481568\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0015112672598490695\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.006152251976429324\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0007440174037036673\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.003510252109543921\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.00037365748246620534\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.005009244164016158\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.007366212858932353\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: -0.0015121276796754568\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.001771709578262337\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.0057405715599428975\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "1034 of 85935 weights retained\n",
      "change in log loss: 0.005335421518438355\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "750 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "750 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "750 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.015580768353404939\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.016392227130573533\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0057338325334466145\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.007603251103373232\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.007085854613460896\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.004323277224569377\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.001417345400774872\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.005819758048422052\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.006289011727731664\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.004786644082135472\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.002778684093341699\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.004483101881501028\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0010889725731575428\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0021715226294041212\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.005923721256153369\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0013345405340863259\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0029188983349585085\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0009886723994144697\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0021316849951393824\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.002702546686308427\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0019749452700799086\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0007552919045492601\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0007064503064956318\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0007180565559955499\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0019967309990466253\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.004594370965737893\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0007941809917622056\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0032700863907108024\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.005252285633053688\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.005845663464117967\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0013009858932313545\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0014219526210541567\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.004890333217033693\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.004821895894353223\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0003491705854155036\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.001958550783361046\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.003734280507064369\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.004967629205518964\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0035452988855235734\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0017016867073015307\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.002891873013152968\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.008115784486752431\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.005325528783566957\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0002628808204431232\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.00260933687099163\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.003151262883000383\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.00032468310522781874\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0027369599042237347\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0001515622107732817\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0027502379509816155\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0020281910996182706\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.005675221433534605\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0018173847306419688\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.001300662361947591\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0002234504720002306\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.005238271016027807\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0003147234133662469\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.002748429144421194\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.004122685566547601\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0015615727737083862\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.001619622986699043\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.001682001692791757\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0023253946701914385\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0004813676003811995\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0010638896002790332\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.000709326625401463\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.00015925204945144156\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.003047267013444266\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.001688093186436812\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0004855496019262606\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0005203442550286708\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0014933817443537611\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0012721352234243977\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0014097821798489951\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0020748280433623423\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.004796764373791174\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.004252616712159596\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.006623459682140176\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0026784526730055935\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.005272626451067075\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.00301692909907314\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0026940806307218512\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.00626126399717597\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.005094401922710823\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.001045517926247852\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.00213456476068008\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0062644348516414095\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.002983494756727545\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.00014510093160990944\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0006668277803245637\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "750 of 85935 weights retained\n",
      "change in log loss: 0.0008737854849166782\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0017709348154518745\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.00038417808820456756\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "750 of 85935 weights retained\n",
      "change in log loss: -0.0025471626888073917\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "552 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "552 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "552 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "552 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "552 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
      "552 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0010808300324072206\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0014310197261375723\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.006121739460255182\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.004290825533347253\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.004834531586789592\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.00660906920017057\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.006486348294790445\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.009264351286525252\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005109575570191982\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005982674178945935\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.009103862695651888\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.009232686620581743\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.006907306187140416\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005780155679636634\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.00323203201400335\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005731859505162307\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0049577015641947275\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0028202959030219077\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0030996954073508887\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0044239349846183496\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005703396609490707\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.004265125846476425\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.00421988844227239\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.00025128684530539847\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005767081038659305\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0012667896399545242\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "552 of 85935 weights retained\n",
      "change in log loss: 0.0006486786824172475\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.003144431188948915\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "552 of 85935 weights retained\n",
      "change in log loss: 0.00010160365039535435\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.004594753597534806\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.003994170571186673\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.003226903430143757\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005176143386738996\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.004045996024787946\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "552 of 85935 weights retained\n",
      "change in log loss: 0.0018213287743357176\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.002636728313722969\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.003470924107352391\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0023983419802803274\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.005238016395812561\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "552 of 85935 weights retained\n",
      "change in log loss: 0.0021719035049354574\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "552 of 85935 weights retained\n",
      "change in log loss: 0.0020058248152983182\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0003939278571328808\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.00026946572280517334\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0015733700303361964\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0028452157100943287\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.00039288477868770766\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0029658696347500957\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "552 of 85935 weights retained\n",
      "change in log loss: -0.0014427328667681039\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "552 of 85935 weights retained\n",
      "change in log loss: 7.216592070768968e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "406 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "406 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "406 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0008980958094874092\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.007111700368546581\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.015287934789666058\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.014153515253158444\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.004920448863933391\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0008187920479697519\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.003615390012568276\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0010444308562261861\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0031505692091842175\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0036146466981326064\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0014488713713340928\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.004850182720781082\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.00234772486443402\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0027433527541099734\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.009094928567768279\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0053900584707855526\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0005714400694498689\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0011229669549347454\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0010637961540066465\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.005545439935032426\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.004062541215358539\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0012661767845860705\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0009061572168368448\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00022652888823071482\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0003814883956239079\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0039522276779311305\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0010492006155680134\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00658024198907825\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0078207131570317\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.004682057231710224\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.004823810234999337\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0065534926883485944\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.001271029868486262\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.000732124038716031\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0031657925997332637\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.00502916002982956\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0010916718164344363\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.003625309378600061\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.007079731844260695\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.006001076271813344\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.007091105485564686\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.006050785558062266\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0007294692570725125\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.005300364761928189\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.008122030500132604\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00037652353125217086\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.000911551943570954\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0024450374687935428\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.005318727825879277\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0029908288209609113\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.004227322896379393\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0025594084663823624\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.006241875661704199\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.003953983974603559\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0010202840866320173\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.004770751203020729\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.003807571337439586\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.004192495839474453\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0006965818979940419\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00245855610181156\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0021558457902729478\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0005591357450939194\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0017982137499017448\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.007491763809821084\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.004135761461120158\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0009234727847532431\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.005953865349022203\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.005912946507799277\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0017575084723524537\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0009534703270153155\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0029470733222365375\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00033759228025298516\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0024682352921339135\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0030263305370432647\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.005198977712213337\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0022934210401845956\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0008179187878699645\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0008807565849141552\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0036448994991828965\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.001980600179234848\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.0021434036662930644\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0006613379824931265\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.000991208934586596\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.001227969238375759\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00337058822731362\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0019514602014871762\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.00036618189218518005\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.002147532830757415\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.005577604374316314\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "406 of 85935 weights retained\n",
      "change in log loss: 0.001801291796354354\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.00011095062115695775\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0023202071867295393\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.006478700848297714\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "406 of 85935 weights retained\n",
      "change in log loss: -0.0020739410407312198\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "300 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.001989433624738024\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.0008212055682115249\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.000272597367119487\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.0018363963462105781\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.0010818691062913777\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.006094965421895582\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.008005290098196283\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.007290588151560362\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.0020518590369669187\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.004247705536212565\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.0030787473923128417\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.004237283154148952\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.002822638571035485\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.006335115473381059\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.005735048118327812\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "300 of 85935 weights retained\n",
      "change in log loss: -0.005894234362353923\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.003265730498096975\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.0032867403022197594\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 0.00037292215721718147\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "300 of 85935 weights retained\n",
      "change in log loss: 6.681617771708837e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "222 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "222 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "222 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "222 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0235 - val_mean_squared_error: 0.0235\n",
      "222 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "222 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0005733485270305039\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0066256241203334065\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0023370431488960453\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.001033539323951671\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0026198821464192834\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.006288056669644826\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0008755477769785136\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0003450682411021422\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0017082836558366399\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0008923285647792767\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0036897305287507676\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0252 - val_mean_squared_error: 0.0252\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0006844234413262429\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.004683157370021562\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0022567440560887775\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.007806307466546092\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.00018848463289811157\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0073275699074064615\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.004483330474774672\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0048681268391259636\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0015653295009175894\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.011785965698098755\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.007019116534537018\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.006355220525333216\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0030401221737069717\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0036956017136591246\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0011260278170232008\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.009088479492428636\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.00044644993328657456\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0023354490321794152\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.001626196216135134\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.009753094364820414\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.00041817609326499916\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0016580708258492338\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.006563644118844136\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.014248051352036883\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "221 of 85935 weights retained\n",
      "change in log loss: -0.01372950209637358\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.009800772134911595\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0027471313873587144\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.008677425794630267\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0012652368068390984\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.003347494624944325\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.003999184748729512\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.00347105439210027\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0058883707792626305\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.002446156528172483\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.005949373029176974\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0034878465287523364\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.002180939389709202\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.010951333366195026\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.012776086775242557\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0006646119286798369\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0064287889444111235\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.018248315175218632\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0007276190860165954\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0035480467892234913\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.004412491258274476\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0012069811143158304\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.005446407677759724\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.005228697323178544\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0006400172505205415\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0034501232305576\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0017217936493358899\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.004867449099985155\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0016470810822611925\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0010636265560584057\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.00271308838107287\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.001047724764196345\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.001690784616281582\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "221 of 85935 weights retained\n",
      "change in log loss: -0.004155183039892596\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.004956788544155599\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0005510405462407775\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.007161300419825323\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.005624470937511061\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.011278740215173833\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0075942517080705985\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.0010903687875434276\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.002115253552301133\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.014517105534926245\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.01650439301060269\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.006922566545663478\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.011090810860741152\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.003393433759838027\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.004592562289793323\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.004701537062842043\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.00605401979237008\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.002991505595709154\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.001264755624731606\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.007376801197564342\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.007935569641550178\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.0039632347059260775\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "222 of 85935 weights retained\n",
      "change in log loss: -0.002329237611347734\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.008021377177659383\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.002307235630561122\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
      "222 of 85935 weights retained\n",
      "change in log loss: 0.000433437713988849\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "166 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "166 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0235 - val_mean_squared_error: 0.0235\n",
      "166 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
      "166 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "166 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
      "166 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.011527093379574693\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.014994971834914606\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.010452637069590653\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.007039117726829747\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.002670456357864892\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.003597920474912586\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0028375178289758995\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.00479898451211469\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.007995467320383476\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.006502480773767139\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.003067197069873462\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0027779038577919746\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0013812035337691375\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0006459630307922293\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.010471105579157314\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.008187963232537676\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0240 - val_mean_squared_error: 0.0240\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0010785087896556522\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0009531126120013722\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.0018359118168094213\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.009900791041635104\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.006308629707850066\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.009053391321572346\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.009938244757517811\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.010664142837856216\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0018662182483157874\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.007895888349931268\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.0032551883829968764\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.002470232787215698\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.006762811535447999\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0006962270519326186\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.000836319428225929\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.004732030713000102\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.010340952177402163\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.005930781589948975\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.009916481834421287\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.012688927585672194\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.007445881516121133\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.0010429210751897733\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.00136546300043916\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -0.001476170593530557\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.0003778723872984724\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.004805853719941688\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.014360410556024661\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "166 of 85935 weights retained\n",
      "change in log loss: 0.011619642094977234\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "166 of 85935 weights retained\n",
      "change in log loss: -8.505524294288858e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "126 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0330 - val_mean_squared_error: 0.0330\n",
      "126 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "126 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
      "126 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
      "126 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0341 - val_mean_squared_error: 0.0341\n",
      "126 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0023578537254024257\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0338 - val_mean_squared_error: 0.0338\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0008495196441649089\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.005891740770923359\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0346 - val_mean_squared_error: 0.0346\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0038589132942749016\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.00901629014746197\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.004126783222017538\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0302 - val_mean_squared_error: 0.0302\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.001210388350268654\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0036745766074425257\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.006126164615701368\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0005508178016688792\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0308 - val_mean_squared_error: 0.0308\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0011049892171715037\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0024178209701902764\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.002715568225339582\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0006541347714211776\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0021348974701909107\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0010552531567292744\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0021189117407598435\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.00360533183379097\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
      "125 of 85935 weights retained\n",
      "change in log loss: 0.008192958741436884\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0336 - val_mean_squared_error: 0.0336\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.003887536041935702\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
      "125 of 85935 weights retained\n",
      "change in log loss: 0.002230312711662963\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0022588156320336727\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0342 - val_mean_squared_error: 0.0342\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0002570101142962411\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.0005864749039904416\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.000507646608884027\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0330 - val_mean_squared_error: 0.0330\n",
      "126 of 85935 weights retained\n",
      "change in log loss: 0.0015308090277700304\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "126 of 85935 weights retained\n",
      "change in log loss: -0.000453347777449431\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0338 - val_mean_squared_error: 0.0338\n",
      "125 of 85935 weights retained\n",
      "change in log loss: -7.913703901785141e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
      "94 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0389 - val_mean_squared_error: 0.0389\n",
      "94 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0429 - mean_squared_error: 0.0429 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "93 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "93 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "94 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0429 - mean_squared_error: 0.0429 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "93 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.0028904464486073644\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0433 - mean_squared_error: 0.0433 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
      "93 of 85935 weights retained\n",
      "change in log loss: 0.0019136471720182513\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.0037604801215619377\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0430 - mean_squared_error: 0.0430 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.0008500293624578159\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.0011183965407896013\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0432 - mean_squared_error: 0.0432 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.00034920373810831684\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
      "92 of 85935 weights retained\n",
      "change in log loss: 0.0005430404496233887\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.001437947598732281\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.0014184154586343034\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0429 - mean_squared_error: 0.0429 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0011867825980125257\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.002504635055867843\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0430 - mean_squared_error: 0.0430 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "93 of 85935 weights retained\n",
      "change in log loss: 0.0022762173151470444\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0430 - mean_squared_error: 0.0430 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.001831661013603214\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.0014602629694278058\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.004030933604774356\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.003233186505229413\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0425 - mean_squared_error: 0.0425 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.0023187877413552993\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.0004012259690387987\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0011639510470030645\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0008760079367453599\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "92 of 85935 weights retained\n",
      "change in log loss: -0.0019421504252068456\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.001438052138229673\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0007368042507337469\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "93 of 85935 weights retained\n",
      "change in log loss: 0.0009652268093165439\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
      "92 of 85935 weights retained\n",
      "change in log loss: 0.0005888766040894611\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0425 - mean_squared_error: 0.0425 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "92 of 85935 weights retained\n",
      "change in log loss: 0.0005701480357110933\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0008151610992405134\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0423 - mean_squared_error: 0.0423 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0021535225696271976\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "93 of 85935 weights retained\n",
      "change in log loss: -0.0008823209234115614\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.0019902904516229114\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0418 - mean_squared_error: 0.0418 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "94 of 85935 weights retained\n",
      "change in log loss: -0.0016549202915711048\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0425 - mean_squared_error: 0.0425 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "93 of 85935 weights retained\n",
      "change in log loss: 0.0003769731383614916\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
      "94 of 85935 weights retained\n",
      "change in log loss: 0.001737788440123178\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "92 of 85935 weights retained\n",
      "change in log loss: -7.364507320684055e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0417 - mean_squared_error: 0.0417 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
      "72 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "74 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "73 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "74 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "73 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0423 - mean_squared_error: 0.0423 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "73 of 85935 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
      "73 of 85935 weights retained\n",
      "change in log loss: 0.00047482672910104107\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -0.0005856495832123887\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "74 of 85935 weights retained\n",
      "change in log loss: 0.0017011255661942837\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -0.0006085905070626341\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -0.001709674159823038\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "74 of 85935 weights retained\n",
      "change in log loss: -0.0020711849177770247\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0410 - mean_squared_error: 0.0410 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -0.004201099136918907\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "74 of 85935 weights retained\n",
      "change in log loss: 0.0006458809183919056\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0410 - mean_squared_error: 0.0410 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -0.0003236157254710159\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0422 - mean_squared_error: 0.0422 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "72 of 85935 weights retained\n",
      "change in log loss: 0.0012256841021184295\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "73 of 85935 weights retained\n",
      "change in log loss: 0.0005644647492349941\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0418 - mean_squared_error: 0.0418 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -0.0013466438413818338\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0412 - mean_squared_error: 0.0412 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
      "73 of 85935 weights retained\n",
      "change in log loss: -1.6689827972315996e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n"
     ]
    }
   ],
   "source": [
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**12, epochs = 1)\n",
    "\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85935 total weights\n",
      "73 of 85935 weights retained\n",
      "D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs\\ModelTraining_Opt_rmsprop__Dro_0.0__Num_200_200_200_16__Wei_0_2019_09_25__10_39_33_pruned.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13983a59d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "    \n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x139dd4dceb8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x139dd4dcbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyDict[\"mean_squared_error\"])\n",
    "plt.plot(historyDict[\"val_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(os.path.join(savedModels,  modelName + '.h5'))\n",
    "\n",
    "# save scaler with same name as model\n",
    "scalerfileX = modelName + '_scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = modelName + '_scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels,  modelName + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c5b7e87f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
