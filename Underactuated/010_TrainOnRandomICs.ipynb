{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 12 Dec 2018 -- Initial commit\n",
    "___\n",
    "### - Train Dense, Feedforward Neural Network with Keras\n",
    "### - Use data that was generated in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-09-23 15:55:28.161433\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "dataDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\data'\n",
    "if not os.path.exists(figDir):\n",
    "    os.mkdir(figDir)\n",
    "\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 19)\n"
     ]
    }
   ],
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(dataDir, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>xf</th>\n",
       "      <th>xd0</th>\n",
       "      <th>xdf</th>\n",
       "      <th>y0</th>\n",
       "      <th>yf</th>\n",
       "      <th>yd0</th>\n",
       "      <th>ydf</th>\n",
       "      <th>theta0</th>\n",
       "      <th>thetaf</th>\n",
       "      <th>thetad0</th>\n",
       "      <th>thetadf</th>\n",
       "      <th>phi0</th>\n",
       "      <th>phif</th>\n",
       "      <th>phid0</th>\n",
       "      <th>phidf</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tau0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-860.538764</td>\n",
       "      <td>-50122.042406</td>\n",
       "      <td>-37099.512049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1864.077658</td>\n",
       "      <td>112333.095649</td>\n",
       "      <td>78407.466199</td>\n",
       "      <td>1.124204</td>\n",
       "      <td>1.775187</td>\n",
       "      <td>-240.317688</td>\n",
       "      <td>-398.977940</td>\n",
       "      <td>1.676109</td>\n",
       "      <td>1.137340</td>\n",
       "      <td>223.908457</td>\n",
       "      <td>-460.120574</td>\n",
       "      <td>365925.417230</td>\n",
       "      <td>4.308596</td>\n",
       "      <td>905969.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1663.999327</td>\n",
       "      <td>98162.039550</td>\n",
       "      <td>70772.904894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1578.437127</td>\n",
       "      <td>-91951.892590</td>\n",
       "      <td>-68471.287625</td>\n",
       "      <td>2.693406</td>\n",
       "      <td>4.812711</td>\n",
       "      <td>-200.894863</td>\n",
       "      <td>1400.049194</td>\n",
       "      <td>5.327012</td>\n",
       "      <td>8.650992</td>\n",
       "      <td>-22.632197</td>\n",
       "      <td>1415.053045</td>\n",
       "      <td>301963.993342</td>\n",
       "      <td>1.157471</td>\n",
       "      <td>-836862.125114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2112.906211</td>\n",
       "      <td>-128322.658782</td>\n",
       "      <td>-88483.199912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.677469</td>\n",
       "      <td>108010.493730</td>\n",
       "      <td>78786.893601</td>\n",
       "      <td>0.268087</td>\n",
       "      <td>1.672884</td>\n",
       "      <td>-76.923640</td>\n",
       "      <td>463.565758</td>\n",
       "      <td>5.398761</td>\n",
       "      <td>6.408854</td>\n",
       "      <td>233.275667</td>\n",
       "      <td>427.271735</td>\n",
       "      <td>442563.311276</td>\n",
       "      <td>6.082598</td>\n",
       "      <td>-128736.343362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1111.053471</td>\n",
       "      <td>-61945.461511</td>\n",
       "      <td>-51111.250941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2178.117332</td>\n",
       "      <td>-134603.694224</td>\n",
       "      <td>-90142.071404</td>\n",
       "      <td>1.454196</td>\n",
       "      <td>5.328020</td>\n",
       "      <td>-143.582522</td>\n",
       "      <td>1517.591974</td>\n",
       "      <td>3.281781</td>\n",
       "      <td>7.010763</td>\n",
       "      <td>-243.190037</td>\n",
       "      <td>1546.588052</td>\n",
       "      <td>179536.991219</td>\n",
       "      <td>4.832508</td>\n",
       "      <td>567528.919560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-729.739726</td>\n",
       "      <td>-39285.280174</td>\n",
       "      <td>-34179.352246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1031.910887</td>\n",
       "      <td>-56601.382912</td>\n",
       "      <td>-46818.328690</td>\n",
       "      <td>0.353609</td>\n",
       "      <td>-3.623116</td>\n",
       "      <td>-228.575046</td>\n",
       "      <td>389.104159</td>\n",
       "      <td>4.769991</td>\n",
       "      <td>-0.295224</td>\n",
       "      <td>-76.699950</td>\n",
       "      <td>321.156438</td>\n",
       "      <td>130307.280323</td>\n",
       "      <td>0.590567</td>\n",
       "      <td>684706.884762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0           xf            xd0           xdf   y0           yf  \\\n",
       "0  0.0  -860.538764  -50122.042406 -37099.512049  0.0  1864.077658   \n",
       "1  0.0  1663.999327   98162.039550  70772.904894  0.0 -1578.437127   \n",
       "2  0.0 -2112.906211 -128322.658782 -88483.199912  0.0  1827.677469   \n",
       "3  0.0 -1111.053471  -61945.461511 -51111.250941  0.0 -2178.117332   \n",
       "4  0.0  -729.739726  -39285.280174 -34179.352246  0.0 -1031.910887   \n",
       "\n",
       "             yd0           ydf    theta0    thetaf     thetad0      thetadf  \\\n",
       "0  112333.095649  78407.466199  1.124204  1.775187 -240.317688  -398.977940   \n",
       "1  -91951.892590 -68471.287625  2.693406  4.812711 -200.894863  1400.049194   \n",
       "2  108010.493730  78786.893601  0.268087  1.672884  -76.923640   463.565758   \n",
       "3 -134603.694224 -90142.071404  1.454196  5.328020 -143.582522  1517.591974   \n",
       "4  -56601.382912 -46818.328690  0.353609 -3.623116 -228.575046   389.104159   \n",
       "\n",
       "       phi0      phif       phid0        phidf              F     alpha  \\\n",
       "0  1.676109  1.137340  223.908457  -460.120574  365925.417230  4.308596   \n",
       "1  5.327012  8.650992  -22.632197  1415.053045  301963.993342  1.157471   \n",
       "2  5.398761  6.408854  233.275667   427.271735  442563.311276  6.082598   \n",
       "3  3.281781  7.010763 -243.190037  1546.588052  179536.991219  4.832508   \n",
       "4  4.769991 -0.295224  -76.699950   321.156438  130307.280323  0.590567   \n",
       "\n",
       "            tau0  \n",
       "0  905969.160686  \n",
       "1 -836862.125114  \n",
       "2 -128736.343362  \n",
       "3  567528.919560  \n",
       "4  684706.884762  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert angles to sine and cosine\n",
    "# cosx = np.cos(angle)\n",
    "# sinx = np.sin(angle)\n",
    "\n",
    "# # print(angle, np.arctan2(sinx, cosx))\n",
    "\n",
    "# trainDF[\"cos_phi_0\"] = np.cos(trainDF.phi_0)\n",
    "# trainDF[\"sin_phi_0\"] = np.sin(trainDF.phi_0)\n",
    "# trainDF[\"cos_phi_99\"] = np.cos(trainDF.phi_99)\n",
    "# trainDF[\"sin_phi_99\"] = np.sin(trainDF.phi_99)\n",
    "\n",
    "# trainDF[\"sin_theta_0\"] = np.sin(trainDF.theta_0)\n",
    "# trainDF[\"cos_theta_0\"] = np.cos(trainDF.theta_0)\n",
    "# trainDF[\"sin_theta_99\"] = np.sin(trainDF.theta_99)\n",
    "# trainDF[\"cos_theta_99\"] = np.cos(trainDF.theta_99)\n",
    "\n",
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.676109</td>\n",
       "      <td>1.124204</td>\n",
       "      <td>-860.538764</td>\n",
       "      <td>1864.077658</td>\n",
       "      <td>1.137340</td>\n",
       "      <td>1.775187</td>\n",
       "      <td>-50122.042406</td>\n",
       "      <td>112333.095649</td>\n",
       "      <td>223.908457</td>\n",
       "      <td>-240.317688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.327012</td>\n",
       "      <td>2.693406</td>\n",
       "      <td>1663.999327</td>\n",
       "      <td>-1578.437127</td>\n",
       "      <td>8.650992</td>\n",
       "      <td>4.812711</td>\n",
       "      <td>98162.039550</td>\n",
       "      <td>-91951.892590</td>\n",
       "      <td>-22.632197</td>\n",
       "      <td>-200.894863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.398761</td>\n",
       "      <td>0.268087</td>\n",
       "      <td>-2112.906211</td>\n",
       "      <td>1827.677469</td>\n",
       "      <td>6.408854</td>\n",
       "      <td>1.672884</td>\n",
       "      <td>-128322.658782</td>\n",
       "      <td>108010.493730</td>\n",
       "      <td>233.275667</td>\n",
       "      <td>-76.923640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.281781</td>\n",
       "      <td>1.454196</td>\n",
       "      <td>-1111.053471</td>\n",
       "      <td>-2178.117332</td>\n",
       "      <td>7.010763</td>\n",
       "      <td>5.328020</td>\n",
       "      <td>-61945.461511</td>\n",
       "      <td>-134603.694224</td>\n",
       "      <td>-243.190037</td>\n",
       "      <td>-143.582522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.769991</td>\n",
       "      <td>0.353609</td>\n",
       "      <td>-729.739726</td>\n",
       "      <td>-1031.910887</td>\n",
       "      <td>-0.295224</td>\n",
       "      <td>-3.623116</td>\n",
       "      <td>-39285.280174</td>\n",
       "      <td>-56601.382912</td>\n",
       "      <td>-76.699950</td>\n",
       "      <td>-228.575046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0         x_99         y_99    phi_99  theta_99  \\\n",
       "0  1.676109  1.124204  -860.538764  1864.077658  1.137340  1.775187   \n",
       "1  5.327012  2.693406  1663.999327 -1578.437127  8.650992  4.812711   \n",
       "2  5.398761  0.268087 -2112.906211  1827.677469  6.408854  1.672884   \n",
       "3  3.281781  1.454196 -1111.053471 -2178.117332  7.010763  5.328020   \n",
       "4  4.769991  0.353609  -729.739726 -1031.910887 -0.295224 -3.623116   \n",
       "\n",
       "         x_dot_0        y_dot_0   phi_dot_0  theta_dot_0  \n",
       "0  -50122.042406  112333.095649  223.908457  -240.317688  \n",
       "1   98162.039550  -91951.892590  -22.632197  -200.894863  \n",
       "2 -128322.658782  108010.493730  233.275667   -76.923640  \n",
       "3  -61945.461511 -134603.694224 -243.190037  -143.582522  \n",
       "4  -39285.280174  -56601.382912  -76.699950  -228.575046  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-143775.519045</td>\n",
       "      <td>-336496.673235</td>\n",
       "      <td>905969.160686</td>\n",
       "      <td>-37099.512049</td>\n",
       "      <td>78407.466199</td>\n",
       "      <td>-460.120574</td>\n",
       "      <td>-398.977940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121285.802738</td>\n",
       "      <td>276535.725231</td>\n",
       "      <td>-836862.125114</td>\n",
       "      <td>70772.904894</td>\n",
       "      <td>-68471.287625</td>\n",
       "      <td>1415.053045</td>\n",
       "      <td>1400.049194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433689.765168</td>\n",
       "      <td>-88178.637303</td>\n",
       "      <td>-128736.343362</td>\n",
       "      <td>-88483.199912</td>\n",
       "      <td>78786.893601</td>\n",
       "      <td>427.271735</td>\n",
       "      <td>463.565758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21514.002933</td>\n",
       "      <td>-178243.313742</td>\n",
       "      <td>567528.919560</td>\n",
       "      <td>-51111.250941</td>\n",
       "      <td>-90142.071404</td>\n",
       "      <td>1546.588052</td>\n",
       "      <td>1517.591974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108236.510499</td>\n",
       "      <td>72559.252341</td>\n",
       "      <td>684706.884762</td>\n",
       "      <td>-34179.352246</td>\n",
       "      <td>-46818.328690</td>\n",
       "      <td>321.156438</td>\n",
       "      <td>389.104159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fx             Fy            tau      x_dot_99      y_dot_99  \\\n",
       "0 -143775.519045 -336496.673235  905969.160686 -37099.512049  78407.466199   \n",
       "1  121285.802738  276535.725231 -836862.125114  70772.904894 -68471.287625   \n",
       "2  433689.765168  -88178.637303 -128736.343362 -88483.199912  78786.893601   \n",
       "3   21514.002933 -178243.313742  567528.919560 -51111.250941 -90142.071404   \n",
       "4  108236.510499   72559.252341  684706.884762 -34179.352246 -46818.328690   \n",
       "\n",
       "    phi_dot_99  theta_dot_99  \n",
       "0  -460.120574   -398.977940  \n",
       "1  1415.053045   1400.049194  \n",
       "2   427.271735    463.565758  \n",
       "3  1546.588052   1517.591974  \n",
       "4   321.156438    389.104159  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# scale data \n",
    "scalerX = StandardScaler()  \n",
    "scalerY = StandardScaler()  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044459</td>\n",
       "      <td>-0.077471</td>\n",
       "      <td>-0.378135</td>\n",
       "      <td>-0.276599</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>-0.363804</td>\n",
       "      <td>-0.246997</td>\n",
       "      <td>0.166977</td>\n",
       "      <td>0.463921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.296392</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.229830</td>\n",
       "      <td>-0.288629</td>\n",
       "      <td>-0.011401</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.209107</td>\n",
       "      <td>-0.268205</td>\n",
       "      <td>0.290953</td>\n",
       "      <td>0.184129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462941</td>\n",
       "      <td>-0.375731</td>\n",
       "      <td>0.171034</td>\n",
       "      <td>0.140524</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>0.151930</td>\n",
       "      <td>0.117742</td>\n",
       "      <td>0.232862</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131530</td>\n",
       "      <td>0.404820</td>\n",
       "      <td>0.036584</td>\n",
       "      <td>-0.332834</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.019010</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>-0.323603</td>\n",
       "      <td>-0.453282</td>\n",
       "      <td>0.353115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137024</td>\n",
       "      <td>0.151784</td>\n",
       "      <td>0.430877</td>\n",
       "      <td>0.107266</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>0.039668</td>\n",
       "      <td>0.429445</td>\n",
       "      <td>0.087003</td>\n",
       "      <td>-0.308493</td>\n",
       "      <td>0.173367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_99      y_99    phi_99  theta_99   x_dot_0  \\\n",
       "0 -0.044459 -0.077471 -0.378135 -0.276599  0.011725  0.012436 -0.363804   \n",
       "1 -0.296392  0.033915  0.229830 -0.288629 -0.011401  0.013935  0.209107   \n",
       "2  0.462941 -0.375731  0.171034  0.140524  0.026247 -0.011535  0.151930   \n",
       "3  0.131530  0.404820  0.036584 -0.332834  0.002561  0.019010  0.026978   \n",
       "4  0.137024  0.151784  0.430877  0.107266  0.045268  0.039668  0.429445   \n",
       "\n",
       "    y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -0.246997   0.166977     0.463921  \n",
       "1 -0.268205   0.290953     0.184129  \n",
       "2  0.117742   0.232862     0.146800  \n",
       "3 -0.323603  -0.453282     0.353115  \n",
       "4  0.087003  -0.308493     0.173367  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [400, 16], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               4400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                6416      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 331,735\n",
      "Trainable params: 331,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0.0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0.0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/150\n",
      " - 9s - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/150\n",
      " - 1s - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 3/150\n",
      " - 1s - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 4/150\n",
      " - 1s - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 5/150\n",
      " - 1s - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 6/150\n",
      " - 1s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 7/150\n",
      " - 1s - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/150\n",
      " - 1s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 9/150\n",
      " - 1s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 10/150\n",
      " - 1s - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 11/150\n",
      " - 1s - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 12/150\n",
      " - 1s - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 13/150\n",
      " - 1s - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 14/150\n",
      " - 1s - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 15/150\n",
      " - 1s - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 16/150\n",
      " - 1s - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 17/150\n",
      " - 1s - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 18/150\n",
      " - 1s - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 19/150\n",
      " - 1s - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 20/150\n",
      " - 1s - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 21/150\n",
      " - 1s - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 22/150\n",
      " - 1s - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 23/150\n",
      " - 1s - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 24/150\n",
      " - 1s - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 25/150\n",
      " - 1s - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 26/150\n",
      " - 1s - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 27/150\n",
      " - 1s - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 28/150\n",
      " - 1s - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 29/150\n",
      " - 1s - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 30/150\n",
      " - 1s - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 31/150\n",
      " - 1s - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 32/150\n",
      " - 1s - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 33/150\n",
      " - 1s - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 34/150\n",
      " - 1s - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
      "Epoch 35/150\n",
      " - 1s - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
      "Epoch 36/150\n",
      " - 1s - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 37/150\n",
      " - 1s - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 38/150\n",
      " - 1s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
      "Epoch 39/150\n",
      " - 1s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
      "Epoch 40/150\n",
      " - 1s - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
      "Epoch 41/150\n",
      " - 1s - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
      "Epoch 42/150\n",
      " - 1s - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
      "Epoch 43/150\n",
      " - 1s - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
      "Epoch 44/150\n",
      " - 1s - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
      "Epoch 45/150\n",
      " - 1s - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 46/150\n",
      " - 1s - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
      "Epoch 47/150\n",
      " - 1s - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
      "Epoch 48/150\n",
      " - 1s - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 49/150\n",
      " - 1s - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
      "Epoch 50/150\n",
      " - 1s - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Epoch 51/150\n",
      " - 1s - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 52/150\n",
      " - 1s - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 53/150\n",
      " - 1s - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 54/150\n",
      " - 1s - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 55/150\n",
      " - 1s - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
      "Epoch 56/150\n",
      " - 1s - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 57/150\n",
      " - 1s - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 58/150\n",
      " - 1s - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 59/150\n",
      " - 1s - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 60/150\n",
      " - 1s - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 61/150\n",
      " - 1s - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "Epoch 62/150\n",
      " - 1s - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 63/150\n",
      " - 1s - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 64/150\n",
      " - 1s - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 65/150\n",
      " - 1s - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 66/150\n",
      " - 1s - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 67/150\n",
      " - 1s - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 68/150\n",
      " - 1s - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 69/150\n",
      " - 1s - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 70/150\n",
      " - 1s - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 71/150\n",
      " - 1s - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "Epoch 72/150\n",
      " - 1s - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Epoch 73/150\n",
      " - 1s - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "Epoch 74/150\n",
      " - 1s - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 75/150\n",
      " - 1s - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 76/150\n",
      " - 1s - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Epoch 77/150\n",
      " - 1s - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "Epoch 78/150\n",
      " - 1s - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 79/150\n",
      " - 1s - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "Epoch 80/150\n",
      " - 1s - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 81/150\n",
      " - 1s - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
      "Epoch 82/150\n",
      " - 1s - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
      "Epoch 83/150\n",
      " - 1s - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 84/150\n",
      " - 1s - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 85/150\n",
      " - 1s - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 86/150\n",
      " - 1s - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 87/150\n",
      " - 1s - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
      "Epoch 88/150\n",
      " - 1s - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 89/150\n",
      " - 1s - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
      "Epoch 90/150\n",
      " - 1s - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 91/150\n",
      " - 1s - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 92/150\n",
      " - 1s - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 93/150\n",
      " - 1s - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 94/150\n",
      " - 1s - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
      "Epoch 95/150\n",
      " - 1s - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 96/150\n",
      " - 1s - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
      "Epoch 97/150\n",
      " - 1s - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 98/150\n",
      " - 1s - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Epoch 99/150\n",
      " - 1s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
      "Epoch 100/150\n",
      " - 1s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 101/150\n",
      " - 1s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 102/150\n",
      " - 1s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 103/150\n",
      " - 1s - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 104/150\n",
      " - 1s - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 105/150\n",
      " - 1s - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 106/150\n",
      " - 1s - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 107/150\n",
      " - 1s - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 108/150\n",
      " - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
      "Epoch 109/150\n",
      " - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
      "Epoch 110/150\n",
      " - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
      "Epoch 111/150\n",
      " - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 112/150\n",
      " - 1s - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 113/150\n",
      " - 1s - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 114/150\n",
      " - 1s - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 115/150\n",
      " - 1s - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Epoch 00115: early stopping\n",
      "146.5276370048523\n"
     ]
    }
   ],
   "source": [
    "# fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 150, verbose = 2, \n",
    "                        batch_size=2**10, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00965961221208175"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_loss'][-1]# MSE for final epoch testing\n",
    "# why are val MSE vs. loss different????  answer : I think loss incorporates regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00965961221208175"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_mean_squared_error'][-1] # it is the same when there is no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00897613024839333"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]# MSE for final epoch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a85cd9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history.history['val_mean_squared_error'][-1])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \".png\"), dpi = 120, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history, saveFig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(os.path.join(savedModels,  modelName + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file back in \n",
    "wt2 = pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\DataOutput\\\\Opt_rmsprop__Dro_0.0__Num_20_20_16__Wei_0_wts.pkl'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# END\n",
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0.0__Num_20_20_16__Wei_0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 1,095\n",
      "Trainable params: 1,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0.0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\DataOutput\\\\Opt_rmsprop__Dro_0.0__Num_20_20_16__Wei_0_wts.pkl'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_wts_file = os.path.join(dataOutput, wtsFile)\n",
    "path_to_wts_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 20)\n",
      "(20,)\n",
      "(20, 16)\n",
      "(16,)\n",
      "(16, 7)\n",
      "(7,)\n",
      "1095 total weights\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "wts =  pickle.load(open(path_to_wts_file, 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 20)\n",
      "(20,)\n",
      "(20, 16)\n",
      "(16,)\n",
      "(16, 7)\n",
      "(7,)\n",
      "1095 total weights\n"
     ]
    }
   ],
   "source": [
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0818 - mean_squared_error: 0.0818 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0482 - mean_squared_error: 0.0482 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0261 - val_mean_squared_error: 0.0261\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0252 - val_mean_squared_error: 0.0252\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0251 - val_mean_squared_error: 0.0251\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0251 - val_mean_squared_error: 0.0251\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0250 - val_mean_squared_error: 0.0250\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0240 - val_mean_squared_error: 0.0240\n",
      "373 of 1095 weights retained\n",
      "Train on 280000 samples, validate on 120000 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
      "373 of 1095 weights retained\n"
     ]
    }
   ],
   "source": [
    "for numEpocs in range(40):\n",
    "\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])\n",
    "    # save history\n",
    "    historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "    historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "    \n",
    "    # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "    # get nonzero weights\n",
    "    wts = model.get_weights().copy()\n",
    "    \n",
    "    # set weights close to 0 to 0 (but ignore biases)\n",
    "    for ii in np.arange(0, len(wts), 2):\n",
    "        qants = np.percentile(np.reshape(wts[ii], -1), q = (15, 85), )\n",
    "        wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "        \n",
    "    # print nonzero weights\n",
    "    # calculate number of nonzero weights\n",
    "    nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "    print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "    # set new weights and calculate new loss\n",
    "    model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs\\ModelTraining_Opt_rmsprop__Dro_0.0__Num_20_20_16__Wei_0_pruned.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a85cd160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
